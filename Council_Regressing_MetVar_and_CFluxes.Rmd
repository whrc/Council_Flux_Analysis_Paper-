---
title: "Regressing_MetVar_and_C_Fluxes"
output: html_document
date: "2025-10-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#load packages
```{r, include=FALSE}
rm(list = ls())

library(data.table)
library(ggplot2)
library(cowplot)
library(openair)
library(plotrix)
library(signal)
library(svMisc)
library(zoo)
library(stringr)
library(plyr)
library(viridis)
library(lubridate)
library(tidyverse)
library(gridExtra)
library(plotly)
library(RColorBrewer)
library(pracma)
library(dplyr)

#install.packages("modifiedmk") #needed for modified mann-kendall, timeseries analyses when there is autocorr 

library(modifiedmk)  # For modified Mann-Kendall when autocorrelation detected
library(Kendall)
library(trend)
library(nlme)  # For GLS models with autocorrelation
library(lmtest)  # For Durbin-Watson test
library(grid)

Sys.setenv(TZ='UTC')

#set working directory
#setwd("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures")
```

```{r}
#with gapfilled soil and air temp columns 

# #half-hourly dataframe --> gapfilled - doesn't have winteryear 
df = fread('C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_gapfilled_clean_2017_2023_for analysis.2.csv',na.strings = c('-9999','NA','NaN','NAN','-7999'))


#daily avg dataframe --> gapfilled - updated seasons, SWC-nf, winteryear 
df_avg = fread('C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_AVG_gapfilled_clean_2017_2023_for analysis.5.csv',na.strings = c('-9999','NA','NaN','NAN','-7999'))


```


#Remove NAs and used complete cases of season, FC, FCH4

```{r}
#Since there are some days where there are FC measurements but not FCH4 measurements, and vice versa, make separate datasets for FC and FCH4 with complete cases 
#make complete cases for FC and FCH4

df_avg_FC <- df_avg %>% filter(complete.cases(FC, season))
df_avg_FCH4 <- df_avg %>% filter(complete.cases(FCH4, season))

#double checking NAs
sum(is.na(df_avg_FCH4$season))

df_2017 <- df_avg_FC %>%
  filter(season == "Fall Senescence")


```


#Seasonal averages for each year, facetwrapped by season 

##prepare seasonal summary dataset by year, set color for each year for consistency across figures 
```{r}
# Seasonal Trends Faceted by Season - All Variables

library(ggplot2)
library(dplyr)

# Prepare seasonal summaries for all variables (2017-2022) - with complete cases FC 
seasonal_means_FC <- df_avg_FC %>%
  # filter(year %in% 2017:2022) %>%
  group_by(winter_year, season) %>%
  summarise(
    # ERA5 GF Air temperature (gap-filled)
    TA_gapfilled_mean = mean(TA_gapfilled, na.rm = TRUE),
    TA_gapfilled_se = sd(TA_gapfilled, na.rm = TRUE) / sqrt(sum(!is.na(TA_gapfilled))),
    
    # measured Air temperature 
    TA_mean = mean(TA, na.rm = TRUE),
    TA_se = sd(TA, na.rm = TRUE) / sqrt(sum(!is.na(TA))),
    
    # ERA5 GF Soil temperature (gap-filled only)
    TS_3_gapfilled_mean = mean(TS_3_gapfilled, na.rm = TRUE),
    TS_3_gapfilled_se = sd(TS_3_gapfilled, na.rm = TRUE) / sqrt(sum(!is.na(TS_3_gapfilled))),
    
    # Measured Soil temperature 
    TS_3_mean = mean(TS_3_1_1, na.rm = TRUE),
    TS_3_se = sd(TS_3_1_1, na.rm = TRUE) / sqrt(sum(!is.na(TS_3_1_1))),
    
    # Soil moisture
    SWC_3_mean = mean(SWC_3_1_1, na.rm = TRUE),
    SWC_3_se = sd(SWC_3_1_1, na.rm = TRUE) / sqrt(sum(!is.na(SWC_3_1_1))),
    
    # VPD
    VPD_mean = mean(VPD, na.rm = TRUE),
    VPD_se = sd(VPD, na.rm = TRUE) / sqrt(sum(!is.na(VPD))),
    
    # RH - relative humidity 
    RH_mean = mean(RH, na.rm = TRUE),
    RH_se = sd(RH, na.rm = TRUE) / sqrt(sum(!is.na(RH))),
    
    # Sensible heat
    H_mean = mean(H, na.rm = TRUE),
    H_se = sd(H, na.rm = TRUE) / sqrt(sum(!is.na(H))),
    
    # Latent heat
    LE_mean = mean(LE, na.rm = TRUE),
    LE_se = sd(LE, na.rm = TRUE) / sqrt(sum(!is.na(LE))),
    
    # Ground heat
    G_mean = mean(G_1_1_1, na.rm = TRUE),
    G_se = sd(G_1_1_1, na.rm = TRUE) / sqrt(sum(!is.na(G_1_1_1))),
    
    #Daily avg of HH flux - FC not gf
    FC_daily_mean = mean(FC), #in units umol/m2/s
    FC_se = sd(FC) / sqrt(sum(!is.na(FC))),
    
     #Daily avg of HH flux - FC_GF
    FC_GF_mean = mean(FC_F), #in units umol/m2/s
    FC_GF_se = sd(FC_F) / sqrt(sum(!is.na(FC_F))),
    
       #Budgets - not winter proportion adjusted 
    CO2_budget = sum(FC_F * (60*60*24*(1/1000000)*12)), #g/m2
 
    
    
    .groups = 'drop'
  )

# Define consistent year colors
year_colors <- c("2017" = "#E41A1C",  # Red
                 "2018" = "#377EB8",  # Blue
                 "2019" = "#4DAF4A",  # Green
                 "2020" = "#984EA3",  # Purple
                 "2021" = "#FF7F00",  # Orange
                 "2022" = "#A65628")  # Brown

# Convert year to factor for consistent color mapping
#seasonal_means_FC$year_factor <- as.factor(seasonal_means_FC$year)
seasonal_means_FC$winteryear_factor <- as.factor(seasonal_means_FC$winter_year)

#================= FCH4 ========================

# Prepare seasonal summaries for all variables (2017-2022) - with complete cases FCH4
seasonal_means_FCH4 <- df_avg_FCH4 %>%
  # filter(year %in% 2017:2022) %>%
  group_by(winter_year, season) %>%
  summarise(
    # ERA5 GF Air temperature (gap-filled)
    TA_gapfilled_mean = mean(TA_gapfilled, na.rm = TRUE),
    TA_gapfilled_se = sd(TA_gapfilled, na.rm = TRUE) / sqrt(sum(!is.na(TA_gapfilled))),
    
    # measured Air temperature 
    TA_mean = mean(TA, na.rm = TRUE),
    TA_se = sd(TA, na.rm = TRUE) / sqrt(sum(!is.na(TA))),
    
    # ERA5 GF Soil temperature (gap-filled only)
    TS_3_gapfilled_mean = mean(TS_3_gapfilled, na.rm = TRUE),
    TS_3_gapfilled_se = sd(TS_3_gapfilled, na.rm = TRUE) / sqrt(sum(!is.na(TS_3_gapfilled))),
    
    # Measured Soil temperature 
    TS_3_mean = mean(TS_3_1_1, na.rm = TRUE),
    TS_3_se = sd(TS_3_1_1, na.rm = TRUE) / sqrt(sum(!is.na(TS_3_1_1))),
    
    # Soil moisture
    SWC_3_mean = mean(SWC_3_1_1, na.rm = TRUE),
    SWC_3_se = sd(SWC_3_1_1, na.rm = TRUE) / sqrt(sum(!is.na(SWC_3_1_1))),
    
    # VPD
    VPD_mean = mean(VPD, na.rm = TRUE),
    VPD_se = sd(VPD, na.rm = TRUE) / sqrt(sum(!is.na(VPD))),
    
    # RH - relative humidity 
    RH_mean = mean(RH, na.rm = TRUE),
    RH_se = sd(RH, na.rm = TRUE) / sqrt(sum(!is.na(RH))),
    
    # Sensible heat
    H_mean = mean(H, na.rm = TRUE),
    H_se = sd(H, na.rm = TRUE) / sqrt(sum(!is.na(H))),
    
    # Latent heat
    LE_mean = mean(LE, na.rm = TRUE),
    LE_se = sd(LE, na.rm = TRUE) / sqrt(sum(!is.na(LE))),
    
    # Ground heat
    G_mean = mean(G_1_1_1, na.rm = TRUE),
    G_se = sd(G_1_1_1, na.rm = TRUE) / sqrt(sum(!is.na(G_1_1_1))),
    
    #Daily avg of HH flux - FCH4 not gf
    FCH4_daily_mean = mean(FCH4 * 1/1000), #in units umol/m2/s
    FCH4_se = sd(FCH4 * 1/1000) / sqrt(sum(!is.na(FCH4))),
    
    #Daily avg of HH flux - FCH4 GF
    FCH4_GF_mean = mean(FCH4_F * 1/1000), #in units umol/m2/s
    FCH4_GF_se = sd(FCH4_F * 1/1000) / sqrt(sum(!is.na(FCH4_F))),
   
    
       #Budgets - not winter proportion adjusted 
    CH4_budget = sum(FCH4_F * (60*60*24*(1/1000000000)*12)), #g/m2
 
    
    
    .groups = 'drop'
  )

# Define consistent year colors
year_colors <- c("2017" = "#E41A1C",  # Red
                 "2018" = "#377EB8",  # Blue
                 "2019" = "#4DAF4A",  # Green
                 "2020" = "#984EA3",  # Purple
                 "2021" = "#FF7F00",  # Orange
                 "2022" = "#A65628")  # Brown

# Convert year to factor for consistent color mapping
#seasonal_means_FCH4$year_factor <- as.factor(seasonal_means_FCH4$year)
seasonal_means_FCH4$winteryear_factor <- as.factor(seasonal_means_FCH4$winter_year)
```




#Temporal co-trends (do years with higher VPD also have higher fluxes, for example - year-to-year relationship) - coding help from Claude
```{r}
# TEMPORAL CO-TREND ANALYSIS
# Testing if years with higher/lower met variables also have higher/lower fluxes
# Uses seasonal means (n=6 years per season)

library(dplyr)
library(ggplot2)
library(broom)

# ============================================================================
# PREPARE SEASONAL MEAN DATA
# ============================================================================

# # Calculate seasonal means for FCH4 and all met variables
fch4_seasonal_means <- df_avg_FCH4 %>%
  #filter(year %in% 2017:2022) %>%
  group_by(winter_year, season) %>%
  summarise(
    FCH4_mean = mean(FCH4, na.rm = TRUE),
    TA_gf_mean = mean(TA_gapfilled, na.rm = TRUE),
    TS_gf_mean = mean(TS_3_gapfilled, na.rm = TRUE),
    SWC_mean = mean(SWC_3_1_1, na.rm = TRUE),
    VPD_mean = mean(VPD, na.rm = TRUE),
    RH_mean = mean(RH, na.rm = TRUE),
    H_mean = mean(H, na.rm = TRUE),
    LE_mean = mean(LE, na.rm = TRUE),
    G_mean = mean(G_1_1_1, na.rm = TRUE),
    .groups = 'drop'
  )
# 
# # Calculate seasonal means for FC and all met variables
fc_seasonal_means <- df_avg_FC %>%
 # filter(year %in% 2017:2022) %>%
  group_by(winter_year, season) %>%
  summarise(
    FC_mean = mean(FC, na.rm = TRUE),
    TA_gf_mean = mean(TA_gapfilled, na.rm = TRUE),
    TS_gf_mean = mean(TS_3_gapfilled, na.rm = TRUE),
    SWC_mean = mean(SWC_3_1_1, na.rm = TRUE),
    VPD_mean = mean(VPD, na.rm = TRUE),
    RH_mean = mean(RH, na.rm = TRUE),
    H_mean = mean(H, na.rm = TRUE),
    LE_mean = mean(LE, na.rm = TRUE),
    G_mean = mean(G_1_1_1, na.rm = TRUE),
    .groups = 'drop'
  )

# ============================================================================
# FUNCTION: Analyze temporal co-trends
# ============================================================================

analyze_cotrend <- function(data, flux_var, met_var, flux_label, met_label, season_name) {
  
  # Filter to specific season
  season_data <- data %>%
    filter(season == season_name) %>%
    select(winter_year, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.))
  
  if(nrow(season_data) < 4) {
    return(NULL)
  }
  
  # Linear model
  lm_model <- lm(flux ~ met, data = season_data)
  lm_summary <- summary(lm_model)
  
  # Test residuals normality
  residuals_vals <- residuals(lm_model)
  shapiro_p <- if(nrow(season_data) >= 3) shapiro.test(residuals_vals)$p.value else NA
  
  # Extract statistics
  slope <- coef(lm_model)[2]
  slope_p <- lm_summary$coefficients[2, 4]
  r_squared <- lm_summary$r.squared
  adj_r_squared <- lm_summary$adj.r.squared
  
  # Spearman correlation
  spearman_test <- cor.test(season_data$met, season_data$flux, method = "spearman")
  spearman_rho <- spearman_test$estimate
  spearman_p <- spearman_test$p.value
  
  # Kendall's tau
  kendall_test <- cor.test(season_data$met, season_data$flux, method = "kendall")
  kendall_tau <- kendall_test$estimate
  kendall_p <- kendall_test$p.value
  
  list(
    season = season_name,
    flux_var = flux_label,
    met_var = met_label,
    n = nrow(season_data),
    slope = slope,
    slope_p = slope_p,
    r_squared = r_squared,
    adj_r_squared = adj_r_squared,
    shapiro_p = shapiro_p,
    spearman_rho = spearman_rho,
    spearman_p = spearman_p,
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    model = lm_model,
    data = season_data
  )
}

# ============================================================================
# RUN CO-TREND ANALYSES
# ============================================================================

cat("============================================================\n")
cat("TEMPORAL CO-TREND ANALYSIS (2017-2022)\n")
cat("Testing if inter-annual trends in fluxes correspond to\n")
cat("inter-annual trends in meteorological variables\n")
cat("Using seasonal means (n=6 years per season)\n")
cat("============================================================\n\n")

# Define met variables
met_vars <- list(
  list(var = "TA_gf_mean", label = "Air Temp GF"),
  list(var = "TS_gf_mean", label = "Soil Temp GF"),
  list(var = "SWC_mean", label = "Soil Moisture"),
  list(var = "VPD_mean", label = "VPD"),
  list(var = "RH_mean", label = "RH"),
  list(var = "H_mean", label = "Sensible Heat"),
  list(var = "LE_mean", label = "Latent Heat"),
  list(var = "G_mean", label = "Soil Heat Flux")
)

seasons <- c("Winter", "Growing Season", "Fall Senescence")

# FCH4 co-trends
fch4_cotrend_results <- list()
for(season in seasons) {
  for(met in met_vars) {
    result <- analyze_cotrend(
      fch4_seasonal_means, "FCH4_mean", met$var,
      "FCH4", met$label, season
    )
    if(!is.null(result)) {
      fch4_cotrend_results[[paste(season, met$label, sep = "_")]] <- result
    }
  }
}

# FC co-trends
fc_cotrend_results <- list()
for(season in seasons) {
  for(met in met_vars) {
    result <- analyze_cotrend(
      fc_seasonal_means, "FC_mean", met$var,
      "FC", met$label, season
    )
    if(!is.null(result)) {
      fc_cotrend_results[[paste(season, met$label, sep = "_")]] <- result
    }
  }
}

# ============================================================================
# CREATE SUMMARY TABLE
# ============================================================================

create_cotrend_summary <- function(results_list, flux_name) {
  
  summary_df <- data.frame()
  
  for(result in results_list) {
    if(!is.null(result)) {
      summary_df <- rbind(summary_df, data.frame(
        flux = flux_name,
        season = result$season,
        met_variable = result$met_var,
        n = result$n,
        slope = round(result$slope, 4),
        slope_p = round(result$slope_p, 4),
        adj_r2 = round(result$adj_r_squared, 3),
        kendall_tau = round(result$kendall_tau, 3),
        kendall_p = round(result$kendall_p, 4),
        spearman_rho = round(result$spearman_rho, 3),
        spearman_p = round(result$spearman_p, 4),
        residuals_normal = ifelse(!is.na(result$shapiro_p) && result$shapiro_p > 0.05, "Yes", "No"),
        significant = case_when(
          !is.na(result$shapiro_p) && result$shapiro_p > 0.05 && result$slope_p < 0.05 ~ "Yes (LM)",
          result$kendall_p < 0.05 ~ "Yes (Kendall)",
          TRUE ~ "No"
        )
      ))
    }
  }
  
  return(summary_df)
}

# Create summary tables
fch4_cotrend_summary <- create_cotrend_summary(fch4_cotrend_results, "FCH4")
fc_cotrend_summary <- create_cotrend_summary(fc_cotrend_results, "FC")

# Combine
all_cotrend_summary <- rbind(fch4_cotrend_summary, fc_cotrend_summary)

# Print all results
cat("\n============================================================\n")
cat("SUMMARY: ALL TEMPORAL CO-TRENDS\n")
cat("============================================================\n\n")

print(all_cotrend_summary)

# Significant co-trends
cat("\n\n============================================================\n")
cat("SIGNIFICANT TEMPORAL CO-TRENDS (p < 0.05)\n")
cat("============================================================\n\n")

significant_cotrends <- all_cotrend_summary %>%
  filter(significant != "No") %>%
  arrange(flux, season, met_variable)

if(nrow(significant_cotrends) > 0) {
  print(significant_cotrends)
  
  cat("\n\nInterpretation:\n")
  cat("- These relationships show inter-annual co-variation\n")
  cat("- Positive slope: Years with higher met variable had higher flux\n")
  cat("- Negative slope: Years with higher met variable had lower flux\n")

  
} else {
  cat("No significant temporal co-trends detected at p < 0.05\n")
}

# Export
# write.csv(all_cotrend_summary, "flux_meteorology_cotrends_summary.csv", row.names = FALSE)
# 

# ============================================================================
# CROSS-REFERENCE WITH KNOWN MET TRENDS
# ============================================================================

cat("\n\n============================================================\n")
cat("CROSS-REFERENCE: MET VARIABLES WITH KNOWN TEMPORAL TRENDS from previous Met Analysis\n")
cat("============================================================\n\n")

cat("Variables with significant temporal trends (2017-2022):\n")
cat("  - VPD: INCREASING in all seasons\n")
cat("  - RH: DECREASING in all seasons\n")


#If fluxes show significant co-trends with these variables,it suggests the changing climate conditions are driving or influencing flux changes.

#Nearly all tests found no sig slopes 


#NOTE: since n is very low (n = 6, or 5), tests assessing assumptions of normality, homog of var are very weak. Better to side with the non-parametric approach. If both agree, great - if they disagree, go with the kendall test or spearman corr. So in this case, two relationships came out sig in lm, but were not sig in kendall's test or spearman corr, so I'm considering them not sig * 
```


#Within-season relationships (on days when x var is higher, are fluxes also higher?) -coding help from Claude


```{r}
# REGRESSION ANALYSIS: Carbon Fluxes vs Meteorological Variables
# Testing if temporal trends in met variables correspond to trends in C fluxes
# Analysis by season for 2017-2022

library(dplyr)
library(ggplot2)
library(broom)

# ============================================================================
# FUNCTION: Analyze flux-meteorology relationships by season
# ============================================================================

analyze_flux_met_relationship <- function(data, flux_var, met_var, 
                                         flux_label, met_label, 
                                         season_name, met_units) {
  
  # Filter to specific season and years
  season_data <- data %>%
    #filter(year %in% 2017:2022, season == season_name) %>%
    select(winter_year, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.))
  
  if(nrow(season_data) < 10) {
    cat("\nInsufficient data for", season_name, "-", met_label, "\n")
    return(NULL)
  }
  
  # Fit linear model: flux ~ meteorological variable
  lm_model <- lm(flux ~ met, data = season_data)
  lm_summary <- summary(lm_model)
  
  # Test residuals for normality
  residuals_vals <- residuals(lm_model)
  shapiro_p <- shapiro.test(residuals_vals)$p.value
  
  # Extract statistics
  slope <- coef(lm_model)[2]
  slope_se <- lm_summary$coefficients[2, 2]
  slope_p <- lm_summary$coefficients[2, 4]
  r_squared <- lm_summary$r.squared
  adj_r_squared <- lm_summary$adj.r.squared
  
  # Spearman correlation as non-parametric alternative
  spearman_test <- cor.test(season_data$met, season_data$flux, method = "spearman")
  spearman_rho <- spearman_test$estimate
  spearman_p <- spearman_test$p.value
  
    # Kendall's tau
  kendall_test <- cor.test(season_data$met, season_data$flux, method = "kendall")
  kendall_tau <- kendall_test$estimate
  kendall_p <- kendall_test$p.value
  
  #Results
  list(
    season = season_name,
    flux_var = flux_label,
    met_var = met_label,
    n = nrow(season_data),
    slope = slope,
    slope_p = slope_p,
    r_squared = r_squared,
    adj_r_squared = adj_r_squared,
    shapiro_p = shapiro_p,
    spearman_rho = spearman_rho,
    spearman_p = spearman_p,
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    model = lm_model,
    data = season_data
  )
}

# ============================================================================
# FUNCTION: Run analysis for all met variables
# ============================================================================

run_comprehensive_analysis <- function(data, flux_var, flux_label, flux_units) {
  
  # Define meteorological variables to test
  met_vars <- list(
    list(var = "TA_gapfilled", label = "Air Temp GF", units = "°C"),
    list(var = "TS_3_gapfilled", label = "Soil Temp GF", units = "°C"),
    list(var = "SWC_3_1_1", label = "Soil Moisture", units = "%"),
    list(var = "VPD", label = "VPD", units = "hPa"),
    list(var = "RH", label = "Relative Humidity", units = "%"),
    list(var = "H", label = "Sensible Heat", units = "W/m²"),
    list(var = "LE", label = "Latent Heat", units = "W/m²"),
    list(var = "G_1_1_1", label = "Soil Heat Flux", units = "W/m²")
  )
  
  seasons <- c("Winter", "Growing Season", "Fall Senescence")
  
  results_list <- list()
  
  for(season in seasons) {
    for(met in met_vars) {
      result <- analyze_flux_met_relationship(
        data, flux_var, met$var, 
        flux_label, met$label, 
        season, met$units
      )
      
      if(!is.null(result)) {
        results_list[[paste(season, met$label, sep = "_")]] <- result
      }
    }
  }
  
  return(results_list)
}

# ============================================================================
# RUN ANALYSES
# ============================================================================

cat("============================================================\n")
cat("CARBON FLUX vs METEOROLOGICAL VARIABLE REGRESSIONS\n")
cat("Testing relationships within each season (2017-2022)\n")
cat("============================================================\n\n")

# Analyze FCH4
cat("\n--- ANALYZING CH4 FLUX ---\n")
fch4_results <- run_comprehensive_analysis(
  df_avg_FCH4, "FCH4", "CH₄ Flux", "nmol/m²/s"
)

# Analyze FC (NEE)
cat("\n--- ANALYZING CO2 FLUX (NEE) ---\n")
fc_results <- run_comprehensive_analysis(
  df_avg_FC, "FC", "CO₂ Flux", "µmol/m²/s"
)

# ============================================================================
# CREATE SUMMARY TABLE
# ============================================================================

create_summary_table <- function(results_list, flux_name) {
  
  summary_df <- data.frame()
  
  for(result in results_list) {
    if(!is.null(result)) {
      summary_df <- rbind(summary_df, data.frame(
        flux = flux_name,
        season = result$season,
        met_variable = result$met_var,
        n = result$n,
        slope = round(result$slope, 4),
        slope_p = round(result$slope_p, 4),
        adj_r2 = round(result$adj_r_squared, 3),
        kendall_tau = round(result$kendall_tau, 3),
        kendall_p = round(result$kendall_p, 4),
        spearman_rho = round(result$spearman_rho, 3),
        spearman_p = round(result$spearman_p, 4),
        residuals_normal = ifelse(!is.na(result$shapiro_p) && result$shapiro_p > 0.05, "Yes", "No"),
        significant = case_when(
          !is.na(result$shapiro_p) && result$shapiro_p > 0.05 && result$slope_p < 0.05 ~ "Yes (LM)",
          result$kendall_p < 0.05 ~ "Yes (Kendall)",
          TRUE ~ "No"
        )
      ))
    }
  }
  
  return(summary_df)
}

# Create summary tables
fch4_summary <- create_summary_table(fch4_results, "FCH4")
fc_summary <- create_summary_table(fc_results, "FC")

# Combine
all_summary <- rbind(fch4_summary, fc_summary)

# Print results
cat("\n\n============================================================\n")
cat("SUMMARY: ALL FLUX-METEOROLOGY RELATIONSHIPS\n")
cat("============================================================\n\n")

print(all_summary)

# Highlight significant relationships
cat("\n\n============================================================\n")
cat("SIGNIFICANT RELATIONSHIPS (p < 0.05)\n")
cat("============================================================\n\n")

significant_results <- all_summary %>%
  filter(significant != "No") %>%
  arrange(flux, season, met_variable)

if(nrow(significant_results) > 0) {
  print(significant_results)
  
  cat("\n\nInterpretation:\n")
  cat("- Positive slope: Flux increases as met variable increases\n")
  cat("- Negative slope: Flux decreases as met variable increases\n")
  cat("- Strong relationships (|rho| or R² > 0.5) indicate important drivers\n")
  
} else {
  cat("No significant relationships detected at p < 0.05\n")
}

# Export summary table
 # write.csv(all_summary, "C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/flux_meteorology_regression_summary.csv", row.names = FALSE)



#many relationships significant - this points to autocorrelation. Can try to avg by week, or month, to reduce autocorr...

 #checking / testing 
print(all_summary)
lm_test <- lm(FC ~ RH, data = df_avg_FC %>% filter(season == "Winter"))
summary(lm_test)
```

#Autocorr checks - make a df for each season, then test the relationship you're planning to analyze. Within winter months, is FCH4 related to VPD? --> 
Within winter data, are the residuals from FCH4 ~ VPD autocorrelated?
```{r}
#test by flux and season - yep, all autocorr
df_avg_FCH4_winter <- df_avg_FCH4 %>%
  filter(season == "Winter")
#autocorrelation - want everything below the blue dotted line 
acf(df_avg_FCH4_winter$FCH4, na.action = na.omit, main = "Autocorrelation of variable")
#partial autocorr - removes effect of intermediate lags, still want everything below blue dotted line 
pacf(df_avg_FCH4_winter$FCH4, na.action = na.omit, main = "Partial Autocorrelation")



#Results: yep severely autocorrelated 


#Ljung-Box test for timeseries models / data -- if p<0.05, there is autocorr and residuals are not independent 
Box.test(df_avg_FC$FC, lag = 20, type = "Ljung-Box") #p<0.001
Box.test(df_avg_FCH4$FCH4, lag = 20, type = "Ljung-Box") #p<0.001

#Durbin watson test for when a model has been fitted - checks if residuals are autocorrelated - DW = 2 = no autocorr, DW < 2 = pos autocorr, DW > 2 = neg autocorr
#install.packages("lmtest")   
library(lmtest)

lm_test<- lm(FCH4 ~ VPD, data = df_avg_FCH4_winter)
dwtest(lm_test)
acf(residuals(lm_test), main = "ACF of model residuals")

#FCH4
#VPD - autocorr 

```
*weekly still heavily autocorrelated; in monthly some variables were autocorrelated 

# ========= coding help from claude ===============

#within each season, Are FCH4 and FC increasing across the years
```{r}
library(dplyr)
library(Kendall)
library(trend)
library(ggplot2)
library(nlme)  # For GLS models with autocorrelation
library(lmtest)  # For Durbin-Watson test

# ============================================================================
# DATA CHECK
# ============================================================================

cat("============================================================\n")
cat("DATA AVAILABILITY CHECK\n")
cat("============================================================\n\n")

cat("Seasonal means:\n")
cat("- FC: n =", nrow(seasonal_means_FC), "season-years\n")
if("season" %in% names(seasonal_means_FC)) {
  cat("  Seasons:", paste(unique(seasonal_means_FC$season), collapse = ", "), "\n")
}
cat("- FCH4: n =", nrow(seasonal_means_FCH4), "season-years\n")
if("season" %in% names(seasonal_means_FCH4)) {
  cat("  Seasons:", paste(unique(seasonal_means_FCH4$season), collapse = ", "), "\n")
}

cat("\nMonthly means:\n")
cat("- FC: n =", nrow(df_monthly_FC), "months\n")
if("season" %in% names(df_monthly_FC)) {
  cat("  Seasons:", paste(unique(df_monthly_FC$season), collapse = ", "), "\n")
}
cat("- FCH4: n =", nrow(df_monthly_FCH4), "months\n")
if("season" %in% names(df_monthly_FCH4)) {
  cat("  Seasons:", paste(unique(df_monthly_FCH4$season), collapse = ", "), "\n")
}
cat("\n")

#Results:
# Seasonal means:
# - FC: n = 17 season-years
#   Seasons: Fall Senescence, Growing Season, Winter 
# - FCH4: n = 17 season-years
#   Seasons: Fall Senescence, Growing Season, Winter 
# 
# Monthly means:
# - FC: n = 37 months
# - FCH4: n = 33 months

```


#checking autocorr within season - streamlined function by Claude 
```{r}
# AUTOCORRELATION CHECK FOR FLUX TEMPORAL TRENDS
# Testing if FC and FCH4 show temporal autocorrelation across years (by season)

library(dplyr)
library(lmtest)  # For Durbin-Watson test

cat("============================================================\n")
cat("AUTOCORRELATION CHECK: FLUX TEMPORAL TRENDS BY SEASON\n")
cat("============================================================\n\n")

# ============================================================================
# FUNCTION: Check autocorrelation for flux temporal trend
# ============================================================================

check_flux_autocorrelation <- function(data, flux_var, flux_label) {
  
  results_list <- list()
  seasons <- unique(data$season)
  
  for(s in seasons) {
    # Filter by season and arrange by year
    season_data <- data %>%
      filter(season == s) %>%
      arrange(winter_year)
    
    flux_vals <- season_data[[flux_var]]
    years <- season_data$winter_year
    
    # Need at least 4 observations
    if(length(flux_vals) < 4 || sum(!is.na(flux_vals)) < 4) {
      cat("Skipping", flux_label, "-", s, ": insufficient data\n")
      next
    }
    
    # Fit linear model: flux ~ year
    lm_model <- lm(flux_vals ~ years)
    
    # Durbin-Watson test on residuals
    dw_test <- dwtest(lm_model)
    
    # ACF lag-1 autocorrelation
    acf_result <- acf(flux_vals, lag.max = 1, plot = FALSE)
    lag1_acf <- acf_result$acf[2]
    
    # Also check residuals autocorrelation
    residuals_vals <- residuals(lm_model)
    acf_resid <- acf(residuals_vals, lag.max = 1, plot = FALSE)
    lag1_resid_acf <- acf_resid$acf[2]
    
    # Interpretation
    autocorr_detected_dw <- dw_test$p.value < 0.05
    autocorr_detected_acf <- abs(lag1_acf) > 0.3
    
    results_list[[s]] <- data.frame(
      flux = flux_label,
      season = s,
      n = length(flux_vals),
      
      # Durbin-Watson test
      dw_statistic = as.numeric(dw_test$statistic),
      dw_p_value = as.numeric(dw_test$p.value),
      dw_autocorr = ifelse(autocorr_detected_dw, "Yes", "No"),
      
      # ACF on raw data
      lag1_acf = lag1_acf,
      acf_autocorr = ifelse(autocorr_detected_acf, "Yes", "No"),
      
      # ACF on residuals
      lag1_resid_acf = lag1_resid_acf,
      
      # Overall assessment
      autocorrelation_present = ifelse(autocorr_detected_dw | autocorr_detected_acf, 
                                      "YES", "NO"),
      
      stringsAsFactors = FALSE
    )
  }
  
  return(do.call(rbind, results_list))
}

# ============================================================================
# RUN AUTOCORRELATION CHECKS
# ============================================================================

cat("\n--- FC (CO₂ Flux) AUTOCORRELATION BY SEASON ---\n\n")
fc_autocorr <- check_flux_autocorrelation(seasonal_means_FC, "FC_daily_mean", "CO₂ Flux")
print(fc_autocorr)

cat("\n\n--- FCH4 (CH₄ Flux) AUTOCORRELATION BY SEASON ---\n\n")
fch4_autocorr <- check_flux_autocorrelation(seasonal_means_FCH4, "FCH4_daily_mean", "CH₄ Flux")
print(fch4_autocorr)

# ============================================================================
# VISUAL CHECK: Plot ACF for each season
# ============================================================================

cat("\n\n--- GENERATING ACF PLOTS ---\n")

library(ggplot2)
library(gridExtra)

plot_acf_by_season <- function(data, flux_var, flux_label) {
  
  seasons <- unique(data$season)
  plot_list <- list()
  
  for(s in seasons) {
    season_data <- data %>%
      filter(season == s) %>%
      arrange(winter_year) %>%
      pull(!!sym(flux_var))
    
    if(length(season_data) < 4) next
    
    # Calculate ACF
    acf_result <- acf(season_data, lag.max = 3, plot = FALSE)
    
    # Create data frame for plotting
    acf_df <- data.frame(
      lag = 1:length(acf_result$acf[-1]),
      acf = acf_result$acf[-1]
    )
    
    # Create plot
    p <- ggplot(acf_df, aes(x = lag, y = acf)) +
      geom_hline(yintercept = 0, color = "black") +
      geom_hline(yintercept = c(-0.3, 0.3), linetype = "dashed", color = "blue", alpha = 0.5) +
      geom_hline(yintercept = c(-1.96/sqrt(length(season_data)), 
                                1.96/sqrt(length(season_data))), 
                linetype = "dashed", color = "red") +
      geom_segment(aes(xend = lag, yend = 0), linewidth = 2, color = "#2166ac") +
      geom_point(size = 3, color = "#2166ac") +
      labs(
        title = paste0(flux_label, " - ", s),
        subtitle = paste0("n = ", length(season_data), " years"),
        x = "Lag (years)",
        y = "Autocorrelation"
      ) +
      theme_bw() +
      theme(
        plot.title = element_text(face = "bold", size = 11),
        plot.subtitle = element_text(size = 9)
      ) +
      annotate("text", x = max(acf_df$lag), y = 0.3, 
               label = "Threshold (|r| > 0.3)", 
               hjust = 1, vjust = -0.5, size = 3, color = "blue") +
      annotate("text", x = max(acf_df$lag), y = 1.96/sqrt(length(season_data)), 
               label = "95% CI", 
               hjust = 1, vjust = -0.5, size = 3, color = "red")
    
    plot_list[[s]] <- p
  }
  
  return(plot_list)
}

# Generate ACF plots for FC
fc_acf_plots <- plot_acf_by_season(seasonal_means_FC, "FC_daily_mean", "CO₂ Flux")
if(length(fc_acf_plots) > 0) {
  fc_combined <- grid.arrange(grobs = fc_acf_plots, ncol = 2)
  cat("Displaying CO₂ flux ACF plots\n")
}

# Generate ACF plots for FCH4
fch4_acf_plots <- plot_acf_by_season(seasonal_means_FCH4, "FCH4_daily_mean", "CH₄ Flux")
if(length(fch4_acf_plots) > 0) {
  fch4_combined <- grid.arrange(grobs = fch4_acf_plots, ncol = 2)
  cat("Displaying CH₄ flux ACF plots\n")
}

# ============================================================================
# SUMMARY
# ============================================================================

cat("\n\n============================================================\n")
cat("SUMMARY\n")
cat("============================================================\n\n")

cat("INTERPRETATION:\n")
cat("- Durbin-Watson test: Tests for autocorrelation in residuals\n")
cat("  * DW p < 0.05 = significant autocorrelation detected\n")
cat("- Lag-1 ACF: Direct autocorrelation coefficient\n")
cat("  * |ACF| > 0.3 = moderate to strong autocorrelation\n")
cat("- Blue dashed lines in plots = |r| = 0.3 threshold\n")
cat("- Red dashed lines in plots = 95% confidence interval\n\n")

cat("COMBINED RESULTS:\n\n")

cat("CO₂ Flux Autocorrelation:\n")
if(exists("fc_autocorr")) {
  print(fc_autocorr[, c("season", "n", "dw_p_value", "lag1_acf", "autocorrelation_present")])
}

cat("\n\nCH₄ Flux Autocorrelation:\n")
if(exists("fch4_autocorr")) {
  print(fch4_autocorr[, c("season", "n", "dw_p_value", "lag1_acf", "autocorrelation_present")])
}

cat("\n\nRECOMMENDATION:\n")
cat("If autocorrelation is present (YES), you should:\n")
cat("1. Use modified Mann-Kendall for trend tests (if n is large enough)\n")
cat("2. Report results with caution if n < 10\n")
cat("3. Consider that p-values may be too optimistic\n")
```

** Seems the FC and FCH4 data are autocorrelated but n=6 is too small to use the modified mann-kendall test....will have to discuss other options with team / when paper goes into review with collaborators?



#Overall flux-met relationships (all data) - using GLS here for autocorrelated data. First check for autocorr, normality, and homogeneity of var - if all ok, use linear reg. If not, use gls. This streamlined code from Claude uses a decision tree: if assumptions are met and there is no autocorr, use linear reg; if assumptions are met and there is autocorr, use gls; if assumptions are not met, use kendall-tau rank corr 

-this code uses a logic hierarchy I asked Claude to build in: FIRST check assumptions (normality,homog of var), SECOND test for autocorr 
**Monthly avg data 
```{r}
analyze_overall_relationship <- function(data, flux_var, met_var, 
                                        flux_label, met_label, 
                                        flux_units, met_units) {
  
  # Prepare data
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month)
  
  if(nrow(plot_data) < 10) {
    return(NULL)
  }
  
  # Standard linear model
  lm_model <- lm(flux ~ met, data = plot_data)
  lm_slope <- coef(lm_model)[2]
  lm_p <- summary(lm_model)$coefficients[2, 4]
  lm_r2 <- summary(lm_model)$r.squared
  
  # Get residuals for diagnostic tests
  residuals_vals <- residuals(lm_model)
  
  # Check assumptions
  # 1. Normality of residuals (Shapiro-Wilk)
  shapiro_test <- shapiro.test(residuals_vals)
  shapiro_p <- shapiro_test$p.value
  normal <- shapiro_p > 0.05
  
  # 2. Homogeneity of variance (Breusch-Pagan test)
  library(lmtest)
  bp_test <- bptest(lm_model)
  bp_p <- bp_test$p.value
  homoscedastic <- bp_p > 0.05
  
  # 3. Autocorrelation (Durbin-Watson)
  dw_test <- dwtest(lm_model)
  dw_stat <- dw_test$statistic
  dw_p <- dw_test$p.value
  autocorr_detected <- dw_p < 0.05
  
  # Determine if linear regression assumptions are met
  lm_assumptions_met <- normal && homoscedastic && !autocorr_detected
  
  # GLS model with AR(1) autocorrelation structure (if autocorrelation detected)
  gls_slope <- NA
  gls_p <- NA
  gls_success <- FALSE
  
  if(autocorr_detected) {
    tryCatch({
      gls_model <- gls(flux ~ met, 
                       data = plot_data,
                       correlation = corAR1(form = ~ 1))
      gls_slope <- coef(gls_model)[2]
      gls_p <- summary(gls_model)$tTable[2, 4]
      gls_success <- TRUE
    }, error = function(e) {
      cat("GLS failed for", flux_label, "~", met_label, "\n")
    })
  }
  
  # Kendall's tau (non-parametric, robust alternative)
  kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
  kendall_tau <- kendall_test$estimate
  kendall_p <- kendall_test$p.value
  
  # Spearman's rho (another non-parametric option)
  spearman_test <- cor.test(plot_data$met, plot_data$flux, method = "spearman")
  spearman_rho <- spearman_test$estimate
  spearman_p <- spearman_test$p.value
  
  # Determine recommended method - PROPER HIERARCHY
  # Step 1: Check distributional assumptions FIRST
  if(!normal || !homoscedastic) {
    # Distributional assumptions violated → Non-parametric
    recommended_method <- "Kendall's tau"
    recommended_slope <- NA  # Kendall gives correlation, not slope
    recommended_p <- kendall_p
    
  } else if(autocorr_detected) {
    # Step 2: Normal & homoscedastic, but autocorrelated → GLS
    if(gls_success) {
      recommended_method <- "GLS with AR(1)"
      recommended_slope <- gls_slope
      recommended_p <- gls_p
    } else {
      # GLS failed, fall back to Kendall
      recommended_method <- "Kendall's tau (GLS failed)"
      recommended_slope <- NA
      recommended_p <- kendall_p
    }
    
  } else {
    # Step 3: All assumptions met → Standard Linear Regression
    recommended_method <- "Linear Regression"
    recommended_slope <- lm_slope
    recommended_p <- lm_p
  }
  
  result <- data.frame(
    flux = flux_label,
    met_variable = met_label,
    n_obs = nrow(plot_data),
    
    # Assumption checks
    shapiro_p = shapiro_p,
    residuals_normal = normal,
    bp_p = bp_p,
    homoscedastic = homoscedastic,
    dw_statistic = dw_stat,
    dw_p = dw_p,
    autocorr_detected = autocorr_detected,
    lm_assumptions_met = lm_assumptions_met,
    
    # Standard LM results
    lm_slope = lm_slope,
    lm_p = lm_p,
    lm_r2 = lm_r2,
    
    # GLS results (if autocorrelation)
    gls_slope = gls_slope,
    gls_p = gls_p,
    gls_used = gls_success,
    
    # Non-parametric alternatives
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    spearman_rho = spearman_rho,
    spearman_p = spearman_p,
    
    # Recommendation
    recommended_method = recommended_method,
    recommended_slope = recommended_slope,
    recommended_p = recommended_p,
    significant = ifelse(recommended_p < 0.05, 
                        paste0("Yes (", recommended_method, ")"), 
                        "No")
  )
  
  return(result)
}

# List of meteorological variables to test
met_vars <- list(
  list(var = "TA_gapfilled", label = "Air Temp", units = "°C"),
  list(var = "TS_3_gapfilled", label = "Soil Temp", units = "°C"),
  list(var = "SWC_3_1_1", label = "Soil Moisture", units = "%"),
  list(var = "VPD", label = "VPD", units = "hPa"),
  list(var = "RH", label = "RH", units = "%"),
  list(var = "LE", label = "Latent Heat", units = "W/m²"),
  list(var = "H", label = "Sensible Heat", units = "W/m²"),
  list(var = "G_1_1_1", label = "Soil Heat Flux", units = "W/m²")
)

# Run for FC
cat("\n--- FC (CO₂) OVERALL RELATIONSHIPS ---\n")
fc_overall_results <- list()

for(met in met_vars) {
  result <- analyze_overall_relationship(
    df_monthly_FC, "FC", met$var,
    "CO₂ Flux", met$label, "µmol/m²/s", met$units
  )
  if(!is.null(result)) {
    fc_overall_results[[met$label]] <- result
  }
}

fc_overall_df <- do.call(rbind, fc_overall_results)
print(fc_overall_df[, c("met_variable", "n_obs", "residuals_normal", "homoscedastic", 
                        "autocorr_detected", "lm_assumptions_met", "recommended_method",
                        "lm_slope", "lm_p", "gls_slope", "gls_p", 
                        "kendall_tau", "kendall_p", "significant")])

# Run for FCH4
cat("\n--- FCH4 (CH₄) OVERALL RELATIONSHIPS ---\n")
fch4_overall_results <- list()

for(met in met_vars) {
  result <- analyze_overall_relationship(
    df_monthly_FCH4, "FCH4", met$var,
    "CH₄ Flux", met$label, "nmol/m²/s", met$units
  )
  if(!is.null(result)) {
    fch4_overall_results[[met$label]] <- result
  }
}

fch4_overall_df <- do.call(rbind, fch4_overall_results)
print(fch4_overall_df[, c("met_variable", "n_obs", "residuals_normal", "homoscedastic",
                          "autocorr_detected", "lm_assumptions_met", "recommended_method",
                          "lm_slope", "lm_p", "gls_slope", "gls_p",
                          "kendall_tau", "kendall_p", "significant")])



```
#Save results 
```{r}
all_summary <- rbind(fch4_overall_df, fc_overall_df)
all_summary

all_summary2 <- all_summary %>%
  select(flux, met_variable, n_obs, shapiro_p, residuals_normal, bp_p, homoscedastic, lm_assumptions_met, dw_statistic, dw_p, autocorr_detected,  recommended_method,
                          lm_r2, lm_slope, lm_p, gls_slope, gls_p, gls_used, 
                          kendall_tau, kendall_p, significant)
all_summary2

write_xlsx(all_summary, "C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/monthly_mean_C_Met_relationship_fullsummary.xlsx")

write_xlsx(all_summary2, "C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/monthly_mean_C_Met_relationship_summary.xlsx")
```

#testing linearity of relationship between FCH4 and SWC - this was the only relationship where GLS with AR1 found it non-sig but kendall-tau found the relationship sig * GLS operates on linear assumption so it's not good at catching non-linear relationships despite being better for autocorr, and therefore maybe trust the kendall on this one? 
```{r}
library(ggplot2)

ggplot(df_monthly_FCH4, aes(x = SWC_3_1_1, y = FCH4)) +
  geom_point() +
  geom_smooth(method = "lm", color = "red", se = TRUE) +  # Linear (GLS assumes this)
  geom_smooth(method = "loess", color = "blue", se = TRUE) +  # Non-linear smoother
  labs(title = "FCH4 vs Soil Moisture",
       subtitle = "Red = Linear | Blue = Loess (flexible)")
```
#Threshold test for FCH4 vs SWC
```{r}
# THRESHOLD ANALYSIS FOR FLUX-METEOROLOGY RELATIONSHIPS
# Tests for breakpoints/thresholds where relationships change

library(dplyr)
library(ggplot2)
library(segmented)
library(nlme)

cat("============================================================\n")
cat("THRESHOLD ANALYSIS: FLUX-METEOROLOGY RELATIONSHIPS\n")
cat("============================================================\n\n")

# ============================================================================
# FUNCTION: Test for threshold effects
# ============================================================================

test_threshold <- function(data, flux_var, met_var, flux_label, met_label, 
                          autocorr_detected = FALSE) {
  
  # Prepare data
  plot_data <- data %>%
    dplyr::select(flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.))
  
  if(nrow(plot_data) < 20) {
    cat("Insufficient data for", flux_label, "~", met_label, "\n")
    return(NULL)
  }
  
  cat("\n--- Testing:", flux_label, "~", met_label, "---\n")
  
  # Fit initial linear model
  lm_initial <- lm(flux ~ met, data = plot_data)
  
  # Try to detect breakpoint using segmented package
  threshold_detected <- FALSE
  breakpoint_value <- NA
  breakpoint_se <- NA
  
  tryCatch({
    # Segmented regression - automatically finds breakpoint
    seg_model <- segmented(lm_initial, seg.Z = ~ met, npsi = 1)
    
    # Extract breakpoint
    breakpoint_value <- seg_model$psi[, "Est."]
    breakpoint_se <- seg_model$psi[, "St.Err"]
    threshold_detected <- TRUE
    
    cat("  Breakpoint detected at", met_label, "=", round(breakpoint_value, 2), 
        "±", round(breakpoint_se, 2), "\n")
    
    # Get slopes before and after breakpoint
    slopes <- slope(seg_model)
    slope_before <- slopes$met[1, 1]
    slope_after <- slopes$met[2, 1]
    
    cat("  Slope before breakpoint:", round(slope_before, 4), "\n")
    cat("  Slope after breakpoint:", round(slope_after, 4), "\n")
    
    # Test if slopes are significantly different
    davies_test <- davies.test(lm_initial, seg.Z = ~ met)
    davies_p <- davies_test$p.value
    
    cat("  Davies test p-value:", round(davies_p, 4), 
        ifelse(davies_p < 0.05, "(significant threshold)", "(no threshold)"), "\n")
    
  }, error = function(e) {
    cat("  No clear breakpoint detected\n")
    threshold_detected <- FALSE
  })
  
  # Alternative approach: Test specific thresholds
  # Split data at quartiles and test for different slopes
  quartiles <- quantile(plot_data$met, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)
  
  cat("\n  Testing potential thresholds at quartiles:\n")
  
  threshold_results <- list()
  
  for(q_name in names(quartiles)) {
    q_val <- quartiles[[q_name]]
    
    # Create indicator variable
    plot_data_temp <- plot_data %>%
      mutate(above_threshold = ifelse(met > q_val, 1, 0))
    
    # Fit model with interaction (different slopes above/below threshold)
    if(autocorr_detected) {
      # Use GLS if autocorrelation
      tryCatch({
        threshold_model <- gls(flux ~ met * above_threshold,
                              correlation = corAR1(form = ~ 1),
                              data = plot_data_temp)
        
        interaction_p <- summary(threshold_model)$tTable["met:above_threshold", "p-value"]
        
        cat("    At", q_name, "(", round(q_val, 2), "):", 
            "Interaction p =", round(interaction_p, 4),
            ifelse(interaction_p < 0.05, "✓ Different slopes", ""), "\n")
        
        threshold_results[[q_name]] <- list(
          threshold = q_val,
          interaction_p = interaction_p,
          significant = interaction_p < 0.05
        )
      }, error = function(e) {
        cat("    At", q_name, ": Model failed\n")
      })
      
    } else {
      # Use standard LM
      threshold_model <- lm(flux ~ met * above_threshold, data = plot_data_temp)
      interaction_p <- summary(threshold_model)$coefficients["met:above_threshold", "Pr(>|t|)"]
      
      cat("    At", q_name, "(", round(q_val, 2), "):", 
          "Interaction p =", round(interaction_p, 4),
          ifelse(interaction_p < 0.05, "✓ Different slopes", ""), "\n")
      
      threshold_results[[q_name]] <- list(
        threshold = q_val,
        interaction_p = interaction_p,
        significant = interaction_p < 0.05
      )
    }
  }
  
  # Return results
  result <- list(
    flux = flux_label,
    met = met_label,
    n = nrow(plot_data),
    threshold_detected = threshold_detected,
    breakpoint = breakpoint_value,
    breakpoint_se = breakpoint_se,
    quartile_tests = threshold_results,
    data = plot_data
  )
  
  return(result)
}

# ============================================================================
# FUNCTION: Visualize threshold relationship
# ============================================================================

plot_threshold <- function(threshold_result, original_data = NULL) {
  
  if(is.null(threshold_result)) return(NULL)
  
  plot_data <- threshold_result$data
  
  # If original data provided with year column, merge it
  if(!is.null(original_data) && "year" %in% names(original_data)) {
    # Merge year back into plot_data
    original_subset <- original_data %>%
      dplyr::select(year, matches(paste0("^", threshold_result$met, "$")), 
                    matches(paste0("^", threshold_result$flux, "$"))) %>%
      dplyr::filter(complete.cases(.))
    
    # Match by met and flux values to get year
    plot_data <- plot_data %>%
      mutate(row_id = row_number())
    
    original_subset <- original_subset %>%
      mutate(row_id = row_number())
    
    plot_data <- plot_data %>%
      left_join(original_subset %>% dplyr::select(row_id, year), by = "row_id")
  }
  
  # Create base plot
  if("year" %in% names(plot_data)) {
    p <- ggplot(plot_data, aes(x = met, y = flux, color = as.factor(year))) +
      geom_point(size = 3, alpha = 0.7) +
      scale_color_manual(
        name = "Year",
        values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                   "2019" = "#4DAF4A", "2020" = "#984EA3", 
                   "2021" = "#FF7F00", "2022" = "#A65628")
      )
  } else {
    p <- ggplot(plot_data, aes(x = met, y = flux)) +
      geom_point(alpha = 0.6, size = 2)
  }
  
  p <- p +
    theme_bw() +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      axis.title = element_text(face = "bold", size = 11),
      legend.position = "right"
    ) +
    labs(
      title = paste(threshold_result$flux, "vs", threshold_result$met),
      x = threshold_result$met,
      y = threshold_result$flux
    )
  
  # Add breakpoint if detected
  if(threshold_result$threshold_detected && !is.na(threshold_result$breakpoint)) {
    # Add vertical line at breakpoint
    p <- p + 
      geom_vline(xintercept = threshold_result$breakpoint, 
                 linetype = "dashed", color = "red", linewidth = 1.2) +
      annotate("text", x = threshold_result$breakpoint, y = max(plot_data$flux),
               label = paste0("Threshold: ", round(threshold_result$breakpoint, 1)),
               hjust = -0.1, color = "red", fontface = "bold", size = 4)
    
    # Fit separate lines before and after breakpoint
    data_before <- plot_data %>% dplyr::filter(met <= threshold_result$breakpoint)
    data_after <- plot_data %>% dplyr::filter(met > threshold_result$breakpoint)
    
    if(nrow(data_before) > 2 && nrow(data_after) > 2) {
      p <- p +
        geom_smooth(data = data_before, aes(x = met, y = flux), 
                   method = "lm", se = TRUE, 
                   color = "blue", fill = "blue", alpha = 0.2,
                   inherit.aes = FALSE, linewidth = 1.2) +
        geom_smooth(data = data_after, aes(x = met, y = flux),
                   method = "lm", se = TRUE, 
                   color = "darkgreen", fill = "darkgreen", alpha = 0.2,
                   inherit.aes = FALSE, linewidth = 1.2)
    }
  } else {
    # No clear breakpoint - just add overall smoother
    p <- p + 
      geom_smooth(aes(x = met, y = flux), method = "loess", 
                 color = "blue", fill = "blue", alpha = 0.2,
                 inherit.aes = FALSE)
  }
  
  return(p)
}

# ============================================================================
# RUN THRESHOLD ANALYSIS
# ============================================================================

# Test FCH4 vs Soil Moisture (the case we discussed)
cat("\n=== FCH4 vs Soil Moisture ===\n")
fch4_swc_threshold <- test_threshold(
  df_monthly_FCH4, "FCH4", "SWC_3_1_1",
  "FCH4", "Soil Moisture (%)",
  autocorr_detected = TRUE  # Set based on your Part 2 results
)

# Visualize (pass original data to get year info)
if(!is.null(fch4_swc_threshold)) {
  p1 <- plot_threshold(fch4_swc_threshold, original_data = df_monthly_FCH4)
  print(p1)
}

# ============================================================================
# Test other relationships where GLS and Kendall disagreed
# ============================================================================

# You can add more relationships here
# Example format:

# cat("\n=== FC vs Air Temperature ===\n")
# fc_ta_threshold <- test_threshold(
#   df_monthly_FC, "FC", "TA_gapfilled",
#   "CO2 Flux", "Air Temperature (°C)",
#   autocorr_detected = FALSE
# )
# 
# if(!is.null(fc_ta_threshold)) {
#   p2 <- plot_threshold(fc_ta_threshold)
#   print(p2)
# }

# ============================================================================
# SUMMARY FUNCTION: Test all relationships at once
# ============================================================================

# test_all_thresholds <- function(flux_data, flux_var, flux_label, met_vars_list, 
#                                autocorr_results = NULL) {
#   
#   all_results <- list()
#   all_plots <- list()
#   
#   for(met in met_vars_list) {
#     # Check if this relationship had autocorrelation
#     has_autocorr <- FALSE
#     if(!is.null(autocorr_results)) {
#       result_row <- autocorr_results %>% filter(met_variable == met$label)
#       if(nrow(result_row) > 0) {
#         has_autocorr <- result_row$autocorr_detected
#       }
#     }
#     
#     # Test for threshold
#     result <- test_threshold(
#       flux_data, flux_var, met$var,
#       flux_label, met$label,
#       autocorr_detected = has_autocorr
#     )
#     
#     if(!is.null(result)) {
#       all_results[[met$label]] <- result
#       all_plots[[met$label]] <- plot_threshold(result)
#     }
#   }
#   
#   return(list(results = all_results, plots = all_plots))
# }
# 
# # Example: Test all met variables for FCH4
# met_vars <- list(
#   list(var = "TA_gapfilled", label = "Air Temp"),
#   list(var = "TS_3_gapfilled", label = "Soil Temp"),
#   list(var = "SWC_3_1_1", label = "Soil Moisture"),
#   list(var = "VPD", label = "VPD"),
#   list(var = "RH", label = "RH")
# )
# 
# cat("\n\n============================================================\n")
# cat("COMPREHENSIVE THRESHOLD TESTING: FCH4\n")
# cat("============================================================\n")

# Run comprehensive test (comment out if you just want specific relationships)
# fch4_all_thresholds <- test_all_thresholds(
#   df_monthly_FCH4, "FCH4", "FCH4",
#   met_vars,
#   autocorr_results = fch4_overall_df  # From Part 2
# )

cat("\n\n============================================================\n")
cat("THRESHOLD ANALYSIS COMPLETE\n")
cat("============================================================\n\n")

cat("INTERPRETATION:\n")
cat("- Breakpoint: The value where relationship changes slope\n")
cat("- Davies test: Tests if a threshold exists (p < 0.05 = yes)\n")
cat("- Quartile tests: Tests if slopes differ above/below 25th, 50th, 75th percentiles\n")
cat("- Interaction p < 0.05: Slopes are significantly different across threshold\n\n")

cat("NEXT STEPS:\n")
cat("1. If threshold detected → Report piecewise relationship\n")
cat("2. If no threshold → Relationship may be continuously non-linear (use GAM)\n")
cat("3. Compare threshold model fit to linear model using AIC/BIC\n")
```


#Data exploration for SWC - FCH4 threshold, code by claude to streamline 
```{r}
# THRESHOLD ANALYSIS FOR FLUX-METEOROLOGY RELATIONSHIPS
# Tests for breakpoints/thresholds where relationships change

library(dplyr)
library(ggplot2)
library(segmented)
library(nlme)

cat("============================================================\n")
cat("THRESHOLD ANALYSIS: FLUX-METEOROLOGY RELATIONSHIPS\n")
cat("============================================================\n\n")

# ============================================================================
# FUNCTION: Test for threshold effects
# ============================================================================

test_threshold <- function(data, flux_var, met_var, flux_label, met_label, 
                          autocorr_detected = FALSE) {
  
  # Prepare data
  plot_data <- data %>%
    dplyr::select(flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.))
  
  if(nrow(plot_data) < 20) {
    cat("Insufficient data for", flux_label, "~", met_label, "\n")
    return(NULL)
  }
  
  cat("\n--- Testing:", flux_label, "~", met_label, "---\n")
  
  # Fit initial linear model
  lm_initial <- lm(flux ~ met, data = plot_data)
  
  # Try to detect breakpoint using segmented package
  threshold_detected <- FALSE
  breakpoint_value <- NA
  breakpoint_se <- NA
  
  tryCatch({
    # Segmented regression - automatically finds breakpoint
    seg_model <- segmented(lm_initial, seg.Z = ~ met, npsi = 1)
    
    # Extract breakpoint
    breakpoint_value <- seg_model$psi[, "Est."]
    breakpoint_se <- seg_model$psi[, "St.Err"]
    threshold_detected <- TRUE
    
    cat("  Breakpoint detected at", met_label, "=", round(breakpoint_value, 2), 
        "±", round(breakpoint_se, 2), "\n")
    
    # Get slopes before and after breakpoint
    slopes <- slope(seg_model)
    slope_before <- slopes$met[1, 1]
    slope_after <- slopes$met[2, 1]
    
    cat("  Slope before breakpoint:", round(slope_before, 4), "\n")
    cat("  Slope after breakpoint:", round(slope_after, 4), "\n")
    
    # Test if slopes are significantly different
    davies_test <- davies.test(lm_initial, seg.Z = ~ met)
    davies_p <- davies_test$p.value
    
    cat("  Davies test p-value:", round(davies_p, 4), 
        ifelse(davies_p < 0.05, "(significant threshold)", "(no threshold)"), "\n")
    
  }, error = function(e) {
    cat("  No clear breakpoint detected\n")
    threshold_detected <- FALSE
  })
  
  # Alternative approach: Test specific thresholds
  # Split data at quartiles and test for different slopes
  quartiles <- quantile(plot_data$met, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)
  
  cat("\n  Testing potential thresholds at quartiles:\n")
  
  threshold_results <- list()
  
  for(q_name in names(quartiles)) {
    q_val <- quartiles[[q_name]]
    
    # Create indicator variable
    plot_data_temp <- plot_data %>%
      mutate(above_threshold = ifelse(met > q_val, 1, 0))
    
    # Fit model with interaction (different slopes above/below threshold)
    if(autocorr_detected) {
      # Use GLS if autocorrelation
      tryCatch({
        threshold_model <- gls(flux ~ met * above_threshold,
                              correlation = corAR1(form = ~ 1),
                              data = plot_data_temp)
        
        interaction_p <- summary(threshold_model)$tTable["met:above_threshold", "p-value"]
        
        cat("    At", q_name, "(", round(q_val, 2), "):", 
            "Interaction p =", round(interaction_p, 4),
            ifelse(interaction_p < 0.05, "✓ Different slopes", ""), "\n")
        
        threshold_results[[q_name]] <- list(
          threshold = q_val,
          interaction_p = interaction_p,
          significant = interaction_p < 0.05
        )
      }, error = function(e) {
        cat("    At", q_name, ": Model failed\n")
      })
      
    } else {
      # Use standard LM
      threshold_model <- lm(flux ~ met * above_threshold, data = plot_data_temp)
      interaction_p <- summary(threshold_model)$coefficients["met:above_threshold", "Pr(>|t|)"]
      
      cat("    At", q_name, "(", round(q_val, 2), "):", 
          "Interaction p =", round(interaction_p, 4),
          ifelse(interaction_p < 0.05, "✓ Different slopes", ""), "\n")
      
      threshold_results[[q_name]] <- list(
        threshold = q_val,
        interaction_p = interaction_p,
        significant = interaction_p < 0.05
      )
    }
  }
  
  # Return results
  result <- list(
    flux = flux_label,
    met = met_label,
    n = nrow(plot_data),
    threshold_detected = threshold_detected,
    breakpoint = breakpoint_value,
    breakpoint_se = breakpoint_se,
    quartile_tests = threshold_results,
    data = plot_data
  )
  
  return(result)
}

# ============================================================================
# FUNCTION: Visualize threshold relationship
# ============================================================================

plot_threshold <- function(threshold_result, original_data = NULL) {
  
  if(is.null(threshold_result)) return(NULL)
  
  plot_data <- threshold_result$data
  
  # If original data provided with year column, merge it
  if(!is.null(original_data) && "year" %in% names(original_data)) {
    # Merge year back into plot_data
    original_subset <- original_data %>%
      dplyr::select(year, matches(paste0("^", threshold_result$met, "$")), 
                    matches(paste0("^", threshold_result$flux, "$"))) %>%
      dplyr::filter(complete.cases(.))
    
    # Match by met and flux values to get year
    plot_data <- plot_data %>%
      mutate(row_id = row_number())
    
    original_subset <- original_subset %>%
      mutate(row_id = row_number())
    
    plot_data <- plot_data %>%
      left_join(original_subset %>% dplyr::select(row_id, year), by = "row_id")
  }
  
  # Create base plot
  if("year" %in% names(plot_data)) {
    p <- ggplot(plot_data, aes(x = met, y = flux, color = as.factor(year))) +
      geom_point(size = 3, alpha = 0.7) +
      scale_color_manual(
        name = "Year",
        values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                   "2019" = "#4DAF4A", "2020" = "#984EA3", 
                   "2021" = "#FF7F00", "2022" = "#A65628")
      )
  } else {
    p <- ggplot(plot_data, aes(x = met, y = flux)) +
      geom_point(alpha = 0.6, size = 2)
  }
  
  p <- p +
    theme_bw() +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      axis.title = element_text(face = "bold", size = 11),
      legend.position = "right"
    ) +
    labs(
      title = paste(threshold_result$flux, "vs", threshold_result$met),
      x = threshold_result$met,
      y = threshold_result$flux
    )
  
  # Add breakpoint if detected
  if(threshold_result$threshold_detected && !is.na(threshold_result$breakpoint)) {
    # Add vertical line at breakpoint
    p <- p + 
      geom_vline(xintercept = threshold_result$breakpoint, 
                 linetype = "dashed", color = "red", linewidth = 1.2) +
      annotate("text", x = threshold_result$breakpoint, y = max(plot_data$flux),
               label = paste0("Threshold: ", round(threshold_result$breakpoint, 1)),
               hjust = -0.1, color = "red", fontface = "bold", size = 4)
    
    # Fit separate lines before and after breakpoint
    data_before <- plot_data %>% dplyr::filter(met <= threshold_result$breakpoint)
    data_after <- plot_data %>% dplyr::filter(met > threshold_result$breakpoint)
    
    if(nrow(data_before) > 2 && nrow(data_after) > 2) {
      p <- p +
        geom_smooth(data = data_before, aes(x = met, y = flux), 
                   method = "lm", se = TRUE, 
                   color = "blue", fill = "blue", alpha = 0.2,
                   inherit.aes = FALSE, linewidth = 1.2) +
        geom_smooth(data = data_after, aes(x = met, y = flux),
                   method = "lm", se = TRUE, 
                   color = "darkgreen", fill = "darkgreen", alpha = 0.2,
                   inherit.aes = FALSE, linewidth = 1.2)
    }
  } else {
    # No clear breakpoint - just add overall smoother
    p <- p + 
      geom_smooth(aes(x = met, y = flux), method = "loess", 
                 color = "blue", fill = "blue", alpha = 0.2,
                 inherit.aes = FALSE)
  }
  
  return(p)
}

# ============================================================================
# RUN THRESHOLD ANALYSIS
# ============================================================================

# Test FCH4 vs Soil Moisture (the case we discussed)
cat("\n=== FCH4 vs Soil Moisture ===\n")
fch4_swc_threshold <- test_threshold(
  df_monthly_FCH4, "FCH4", "SWC_3_1_1",
  "FCH4", "Soil Moisture (%)",
  autocorr_detected = TRUE  # Set based on your Part 2 results
)

# Visualize (pass original data to get year info)
if(!is.null(fch4_swc_threshold)) {
  p1 <- plot_threshold(fch4_swc_threshold, original_data = df_monthly_FCH4)
  print(p1)
}

# ============================================================================
# DIAGNOSTIC CHECKS: Is the threshold real or a data artifact?
# ============================================================================

cat("\n\n============================================================\n")
cat("THRESHOLD DIAGNOSTICS: FCH4 vs Soil Moisture\n")
cat("============================================================\n\n")

if(!is.null(fch4_swc_threshold) && fch4_swc_threshold$threshold_detected) {
  
  threshold_val <- fch4_swc_threshold$breakpoint
  
  # 1. DATA DISTRIBUTION CHECK
  cat("--- 1. DATA DISTRIBUTION ACROSS MOISTURE RANGES ---\n\n")
  
  dist_check <- df_monthly_FCH4 %>%
    mutate(swc_bin = cut(SWC_3_1_1, 
                         breaks = c(0, threshold_val, 30, 50, 100),
                         labels = c(paste0("0-", round(threshold_val), "%"), 
                                   paste0(round(threshold_val), "-30%"),
                                   "30-50%", "50-100%"))) %>%
    group_by(swc_bin) %>%
    summarise(
      n_obs = n(),
      pct_data = round(n() / nrow(df_monthly_FCH4) * 100, 1),
      mean_FCH4 = round(mean(FCH4, na.rm = TRUE), 2),
      sd_FCH4 = round(sd(FCH4, na.rm = TRUE), 2),
      years = paste(unique(year), collapse = ", "),
      .groups = 'drop'
    )
  
  print(dist_check)
  
  # Visual: Histogram
  p_hist <- ggplot(df_monthly_FCH4, aes(x = SWC_3_1_1)) +
    geom_histogram(bins = 20, fill = "steelblue", color = "black", alpha = 0.7) +
    geom_vline(xintercept = threshold_val, color = "red", 
               linetype = "dashed", linewidth = 1.2) +
    annotate("text", x = threshold_val, y = Inf, 
             label = paste0("Threshold: ", round(threshold_val, 1), "%"),
             hjust = -0.1, vjust = 1.5, color = "red", fontface = "bold") +
    labs(title = "Distribution of Soil Moisture Observations",
         subtitle = paste("Total n =", nrow(df_monthly_FCH4)),
         x = "Soil Moisture (%)",
         y = "Count") +
    theme_bw() +
    theme(plot.title = element_text(face = "bold"))
  
  print(p_hist)
  
  # 2. TEST NEGATIVE SLOPE SIGNIFICANCE
  cat("\n\n--- 2. TESTING NEGATIVE SLOPE BELOW THRESHOLD ---\n\n")
  
  dry_data <- df_monthly_FCH4 %>%
    filter(SWC_3_1_1 <= threshold_val)
  
  cat("Dry conditions (≤", round(threshold_val, 1), "% SWC):\n")
  cat("  N observations:", nrow(dry_data), "\n")
  
  if(nrow(dry_data) >= 3) {
    dry_lm <- lm(FCH4 ~ SWC_3_1_1, data = dry_data)
    dry_summary <- summary(dry_lm)
    
    cat("  Slope:", round(coef(dry_lm)[2], 4), "\n")
    cat("  P-value:", round(dry_summary$coefficients[2, 4], 4), 
        ifelse(dry_summary$coefficients[2, 4] < 0.05, " (significant)", " (NOT significant)"), "\n")
    cat("  R²:", round(dry_summary$r.squared, 3), "\n")
    cat("  Years present:", paste(unique(dry_data$year), collapse = ", "), "\n")
    
    if(dry_summary$coefficients[2, 4] > 0.05) {
      cat("\n  ⚠️  WARNING: Negative slope is NOT statistically significant!\n")
      cat("     This suggests the threshold may be a data artifact.\n")
    }
  } else {
    cat("  ⚠️  WARNING: Too few observations (n < 3) to test slope!\n")
    cat("     Cannot reliably establish a relationship below threshold.\n")
  }
  
  # 3. SENSITIVITY ANALYSIS - TEST MULTIPLE THRESHOLDS
  cat("\n\n--- 3. SENSITIVITY ANALYSIS: ALTERNATIVE THRESHOLDS ---\n\n")
  
  test_thresholds <- seq(15, 40, by = 5)
  threshold_comparison <- data.frame()
  
  for(thresh in test_thresholds) {
    below <- df_monthly_FCH4 %>% filter(SWC_3_1_1 <= thresh)
    above <- df_monthly_FCH4 %>% filter(SWC_3_1_1 > thresh)
    
    if(nrow(below) >= 5 && nrow(above) >= 5) {
      lm_below <- lm(FCH4 ~ SWC_3_1_1, data = below)
      lm_above <- lm(FCH4 ~ SWC_3_1_1, data = above)
      
      slope_below <- coef(lm_below)[2]
      slope_above <- coef(lm_above)[2]
      p_below <- summary(lm_below)$coefficients[2, 4]
      p_above <- summary(lm_above)$coefficients[2, 4]
      
      threshold_comparison <- rbind(threshold_comparison, data.frame(
        threshold = thresh,
        n_below = nrow(below),
        n_above = nrow(above),
        slope_below = round(slope_below, 4),
        p_below = round(p_below, 4),
        slope_above = round(slope_above, 4),
        p_above = round(p_above, 4),
        slope_difference = round(abs(slope_above - slope_below), 4)
      ))
    }
  }
  
  print(threshold_comparison)
  
  # Visual: Slope differences
  p_sensitivity <- ggplot(threshold_comparison, aes(x = threshold, y = slope_difference)) +
    geom_line(linewidth = 1.2, color = "steelblue") +
    geom_point(size = 3, color = "steelblue") +
    geom_vline(xintercept = threshold_val, color = "red", 
               linetype = "dashed", linewidth = 1) +
    annotate("text", x = threshold_val, y = max(threshold_comparison$slope_difference),
             label = "Detected\nThreshold", hjust = -0.1, color = "red", fontface = "bold") +
    labs(title = "Sensitivity Analysis: How Slopes Change with Threshold Location",
         subtitle = "Larger difference = stronger evidence for threshold",
         x = "Potential Threshold (%)",
         y = "Absolute Difference in Slopes") +
    theme_bw() +
    theme(plot.title = element_text(face = "bold"))
  
  print(p_sensitivity)
  
  # 4. TEMPORAL PATTERNS
  cat("\n\n--- 4. TEMPORAL DISTRIBUTION: Are dry periods clustered? ---\n\n")
  
  temporal_dist <- df_monthly_FCH4 %>%
    mutate(moisture_regime = ifelse(SWC_3_1_1 <= threshold_val, 
                                    paste0("Dry (≤", round(threshold_val, 1), "%)"), 
                                    paste0("Moist (>", round(threshold_val, 1), "%)"))) %>%
    group_by(moisture_regime, year) %>%
    summarise(n = n(), .groups = 'drop') %>%
    tidyr::pivot_wider(names_from = year, values_from = n, values_fill = 0) %>%
    mutate(Total = rowSums(dplyr::select(., -moisture_regime)))
  
  print(temporal_dist)
  
  # 5. RECOMMENDATION
  cat("\n\n--- 5. RECOMMENDATION ---\n\n")
  
  n_dry <- nrow(df_monthly_FCH4 %>% filter(SWC_3_1_1 <= threshold_val))
  pct_dry <- round(n_dry / nrow(df_monthly_FCH4) * 100, 1)
  
  if(n_dry < 10) {
    cat("⚠️  CAUTION: Very few observations below threshold (n =", n_dry, ",", pct_dry, "% of data)\n\n")
    
    cat("SUGGESTED APPROACH:\n")
    cat("Option 1 (Conservative): Report only the well-supported positive relationship\n")
    cat("  'FCH4 increased with soil moisture at levels above ~30-40% (where data are adequate).'\n\n")
    
    cat("Option 2 (Exploratory): Acknowledge threshold with caveats\n")
    cat("  'Threshold analysis suggested a potential breakpoint at ~", round(threshold_val, 0), "% SWC,\n")
    cat("   but this should be interpreted cautiously given sparse observations below this value.\n")
    cat("   The primary pattern is a positive relationship at higher moisture levels.'\n\n")
    
    # Test high-moisture relationship
    high_moisture <- df_monthly_FCH4 %>% filter(SWC_3_1_1 > 35)
    if(nrow(high_moisture) >= 10) {
      kendall_high <- cor.test(high_moisture$SWC_3_1_1, high_moisture$FCH4, method = "kendall")
      cat("High moisture relationship (SWC > 35%):\n")
      cat("  n =", nrow(high_moisture), "\n")
      cat("  Kendall's τ =", round(kendall_high$estimate, 3), "\n")
      cat("  p-value =", format.pval(kendall_high$p.value, digits = 3), "\n")
    }
    
  } else {
    cat("✓ Adequate observations across moisture ranges\n")
    cat("  The threshold appears to be well-supported by the data.\n")
  }
  
} else {
  cat("No threshold detected or threshold analysis failed.\n")
}

# ============================================================================
# Test other relationships where GLS and Kendall disagreed
# ============================================================================

# You can add more relationships here
# Example format:

# cat("\n=== FC vs Air Temperature ===\n")
# fc_ta_threshold <- test_threshold(
#   df_monthly_FC, "FC", "TA_gapfilled",
#   "CO2 Flux", "Air Temperature (°C)",
#   autocorr_detected = FALSE
# )
# 
# if(!is.null(fc_ta_threshold)) {
#   p2 <- plot_threshold(fc_ta_threshold)
#   print(p2)
# }

# ============================================================================
# SUMMARY FUNCTION: Test all relationships at once
# ============================================================================

# test_all_thresholds <- function(flux_data, flux_var, flux_label, met_vars_list, 
#                                autocorr_results = NULL) {
#   
#   all_results <- list()
#   all_plots <- list()
#   
#   for(met in met_vars_list) {
#     # Check if this relationship had autocorrelation
#     has_autocorr <- FALSE
#     if(!is.null(autocorr_results)) {
#       result_row <- autocorr_results %>% filter(met_variable == met$label)
#       if(nrow(result_row) > 0) {
#         has_autocorr <- result_row$autocorr_detected
#       }
#     }
#     
#     # Test for threshold
#     result <- test_threshold(
#       flux_data, flux_var, met$var,
#       flux_label, met$label,
#       autocorr_detected = has_autocorr
#     )
#     
#     if(!is.null(result)) {
#       all_results[[met$label]] <- result
#       all_plots[[met$label]] <- plot_threshold(result)
#     }
#   }
#   
#   return(list(results = all_results, plots = all_plots))
# }

# # Example: Test all met variables for FCH4
# met_vars <- list(
#   list(var = "TA_gapfilled", label = "Air Temp"),
#   list(var = "TS_3_gapfilled", label = "Soil Temp"),
#   list(var = "SWC_3_1_1", label = "Soil Moisture"),
#   list(var = "VPD", label = "VPD"),
#   list(var = "RH", label = "RH")
# )

cat("\n\n============================================================\n")
cat("COMPREHENSIVE THRESHOLD TESTING: FCH4\n")
cat("============================================================\n")

# Run comprehensive test (comment out if you just want specific relationships)
# fch4_all_thresholds <- test_all_thresholds(
#   df_monthly_FCH4, "FCH4", "FCH4",
#   met_vars,
#   autocorr_results = fch4_overall_df  # From Part 2
# )

cat("\n\n============================================================\n")
cat("THRESHOLD ANALYSIS COMPLETE\n")
cat("============================================================\n\n")

cat("INTERPRETATION:\n")
cat("- Breakpoint: The value where relationship changes slope\n")
cat("- Davies test: Tests if a threshold exists (p < 0.05 = yes)\n")
cat("- Quartile tests: Tests if slopes differ above/below 25th, 50th, 75th percentiles\n")
cat("- Interaction p < 0.05: Slopes are significantly different across threshold\n\n")

cat("NEXT STEPS:\n")
cat("1. If threshold detected → Report piecewise relationship\n")
cat("2. If no threshold → Relationship may be continuously non-linear (use GAM)\n")
cat("3. Compare threshold model fit to linear model using AIC/BIC\n")
```


#Exploring FCH4 and LE due to significant slope from GLS but not sig slope per kendall 
```{r}
ggplot(df_monthly_FCH4, aes(x=LE, y = FCH4))+
  geom_point()+
  geom_smooth(method = "auto")+
  theme_bw()
```

```{r}
# Check the GLS results more carefully
library(nlme)

# Fit GLS
gls_model <- gls(FCH4 ~ LE, 
                 correlation = corAR1(form = ~ 1),
                 data = df_monthly_FCH4)

# Get detailed results
summary(gls_model)

# Check R² (pseudo R² for GLS)
cor(fitted(gls_model), df_monthly_FCH4$FCH4)^2

# Look for influential points
plot_data <- df_monthly_FCH4 %>%
  filter(!is.na(FCH4) & !is.na(LE))

# Identify high-leverage points
high_le <- plot_data %>% filter(LE > 40)
cat("High LE observations (n =", nrow(high_le), "):\n")
print(high_le %>% dplyr :: select(year, month, LE, FCH4))

# Retest WITHOUT high-leverage points
moderate_le <- plot_data %>% filter(LE <= 40)

if(nrow(moderate_le) >= 20) {
  gls_subset <- gls(FCH4 ~ LE, 
                    correlation = corAR1(form = ~ 1),
                    data = moderate_le)
  
  cat("\nWithout high LE points:\n")
  print(summary(gls_subset)$tTable)
  
  kendall_subset <- cor.test(moderate_le$LE, moderate_le$FCH4, method = "kendall")
  cat("Kendall's tau:", kendall_subset$estimate, "p =", kendall_subset$p.value, "\n")
}
```




#Visualize all plots with new stats - GLS1, LM, or kendall - streamlined code by claude
```{r}
# UPDATED VISUALIZATION: Flux-Meteorology Relationships
# Shows appropriate statistics based on GLS with AR(1) or Kendall's tau

library(ggplot2)
library(dplyr)
library(gridExtra)
library(nlme)

# ============================================================================
# FUNCTION: Create scatterplot with appropriate statistics
# ============================================================================

plot_flux_met_gls <- function(data, flux_var, met_var, 
                              flux_label, met_label, 
                              flux_units, met_units,
                              result_row,
                              text_position = "bottom-left") {
  
  # Prepare data
  plot_data <- data %>%
    dplyr::select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.))
  
  # Determine which method was used based on result_row
  method_used <- result_row$recommended_method
  
  # Create statistics label based on method
  if(method_used == "GLS with AR(1)") {
    stats_label <- paste0(
      "GLS with AR(1)\n",
      "Slope = ", sprintf("%.4f", result_row$gls_slope), "\n",
      "p = ", format.pval(result_row$gls_p, digits = 3), "\n",
      "Phi = ", sprintf("%.2f", result_row$phi),
      ifelse(!is.na(result_row$pseudo_r2), 
             paste0("\nPseudo-R² = ", sprintf("%.3f", result_row$pseudo_r2)), "")
    )
    line_color <- "blue"
    use_gls_line <- TRUE
    
  } else if(method_used == "Linear Regression") {
    stats_label <- paste0(
      "Linear Regression\n",
      "Slope = ", sprintf("%.4f", result_row$lm_slope), "\n",
      "R² = ", sprintf("%.3f", result_row$lm_r2), "\n",
      "p = ", format.pval(result_row$lm_p, digits = 3)
    )
    line_color <- "blue"
    use_gls_line <- FALSE
    
  } else if(grepl("Kendall", method_used)) {
    stats_label <- paste0(
      "Kendall's tau\n",
      "τ = ", sprintf("%.3f", result_row$kendall_tau), "\n",
      "p = ", format.pval(result_row$kendall_p, digits = 3), "\n",
      ifelse(result_row$autocorr_detected, "(Autocorr detected)", ""),
      ifelse(!result_row$residuals_normal || !result_row$homoscedastic,
             "\n(Non-normal/heteroscedastic)", "")
    )
    line_color <- "darkgreen"
    use_gls_line <- FALSE
  }
  
  # Create base plot
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    
    # Points colored by year
    geom_point(aes(color = as.factor(year)), size = 3, alpha = 0.7) +
    
    # Add appropriate line
    {if(use_gls_line && !is.na(result_row$gls_slope)) {
      # GLS line - manually add using slope and intercept
      geom_abline(slope = result_row$gls_slope, 
                  intercept = result_row$gls_intercept,
                  color = line_color, linewidth = 1.2)
    } else if(method_used == "Linear Regression") {
      # Standard LM line
      geom_smooth(method = "lm", se = TRUE, 
                  color = line_color, fill = line_color, 
                  alpha = 0.2, linewidth = 1.2)
    } else {
      # Kendall - use loess smoother
      geom_smooth(method = "loess", se = TRUE, 
                  color = line_color, fill = line_color, 
                  alpha = 0.2, linewidth = 1.2)
    }} +
    
    # Add statistics annotation
    {if(text_position == "top-right") {
      annotate("text", x = Inf, y = Inf, 
               label = stats_label,
               hjust = 1.1, vjust = 1.5, size = 3.5, fontface = "bold")
    } else if(text_position == "top-left") {
      annotate("text", x = -Inf, y = Inf, 
               label = stats_label,
               hjust = -0.1, vjust = 1.5, size = 3.5, fontface = "bold")
    } else {
      annotate("text", x = -Inf, y = -Inf, 
               label = stats_label,
               hjust = -0.1, vjust = -0.5, size = 3.5, fontface = "bold")
    }} +
    
    # Labels with proper subscripts
    labs(x = paste0(met_label, " (", met_units, ")"),
         y = if(grepl("CH", flux_label)) {
           bquote("Monthly Mean CH"[4] ~ "Flux (" * .(flux_units) * ")")
         } else if(grepl("CO", flux_label)) {
           bquote("Monthly Mean CO"[2] ~ "Flux (" * .(flux_units) * ")")
         } else {
           paste0("Monthly Mean ", flux_label, " (", flux_units, ")")
         },
         title = if(grepl("CH", flux_label)) {
           bquote("Monthly Mean CH"[4] ~ "Flux vs" ~ .(met_label))
         } else if(grepl("CO", flux_label)) {
           bquote("Monthly Mean CO"[2] ~ "Flux vs" ~ .(met_label))
         } else {
           paste0("Monthly Mean ", flux_label, " vs ", met_label)
         },
         color = "Year") +
    
    # Theme
    theme_bw() +
    theme(
      plot.title = element_text(face = "bold", size = 12),
      axis.title = element_text(face = "bold", size = 11),
      axis.text = element_text(face = "bold", size = 9),
      legend.position = "right",
      legend.title = element_text(face = "bold"),
      legend.text = element_text(size = 9)
    ) +
    
    # Color scale for years
    scale_color_manual(
      values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                 "2019" = "#4DAF4A", "2020" = "#984EA3", 
                 "2021" = "#FF7F00", "2022" = "#A65628")
    )
  
  return(p)
}

# ============================================================================
# HELPER: Calculate GLS intercept and pseudo-R²
# ============================================================================

calculate_gls_stats <- function(data, flux_var, met_var) {
  
  plot_data <- data %>%
    dplyr::select(flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.))
  
  tryCatch({
    gls_model <- gls(flux ~ met, 
                     correlation = corAR1(form = ~ 1),
                     data = plot_data)
    
    # Extract intercept
    intercept <- coef(gls_model)[1]
    
    # Calculate pseudo-R² (correlation between fitted and observed)
    pseudo_r2 <- cor(fitted(gls_model), plot_data$flux)^2
    
    # Extract Phi
    phi <- as.numeric(coef(gls_model$modelStruct$corStruct, unconstrained = FALSE))
    
    return(list(intercept = intercept, pseudo_r2 = pseudo_r2, phi = phi))
    
  }, error = function(e) {
    return(list(intercept = NA, pseudo_r2 = NA, phi = NA))
  })
}

# ============================================================================
# PREPARE RESULTS DATA
# ============================================================================

cat("============================================================\n")
cat("PREPARING UPDATED VISUALIZATIONS\n")
cat("============================================================\n\n")

# Add GLS intercept and pseudo-R² to results
if(exists("fc_overall_df")) {
  cat("Processing FC results...\n")
  
  # Initialize new columns
  fc_overall_df$gls_intercept <- NA
  fc_overall_df$pseudo_r2 <- NA
  fc_overall_df$phi <- NA
  
  for(i in 1:nrow(fc_overall_df)) {
    met_var <- fc_overall_df$met_variable[i]
    
    # Find the matching met variable name
    met_lookup <- list(
      "Air Temp" = "TA_gapfilled",
      "Soil Temp" = "TS_3_gapfilled",
      "Soil Moisture" = "SWC_3_1_1",
      "VPD" = "VPD",
      "RH" = "RH",
      "Latent Heat" = "LE",
      "Sensible Heat" = "H",
      "Soil Heat Flux" = "G_1_1_1"
    )
    
    met_var_name <- met_lookup[[met_var]]
    
    if(!is.null(met_var_name) && fc_overall_df$recommended_method[i] == "GLS with AR(1)") {
      gls_stats <- calculate_gls_stats(df_monthly_FC, "FC", met_var_name)
      fc_overall_df$gls_intercept[i] <- gls_stats$intercept
      fc_overall_df$pseudo_r2[i] <- gls_stats$pseudo_r2
      fc_overall_df$phi[i] <- gls_stats$phi
    }
  }
}

if(exists("fch4_overall_df")) {
  cat("Processing FCH4 results...\n")
  
  # Initialize new columns
  fch4_overall_df$gls_intercept <- NA
  fch4_overall_df$pseudo_r2 <- NA
  fch4_overall_df$phi <- NA
  
  for(i in 1:nrow(fch4_overall_df)) {
    met_var <- fch4_overall_df$met_variable[i]
    
    met_lookup <- list(
      "Air Temp" = "TA_gapfilled",
      "Soil Temp" = "TS_3_gapfilled",
      "Soil Moisture" = "SWC_3_1_1",
      "VPD" = "VPD",
      "RH" = "RH",
      "Latent Heat" = "LE",
      "Sensible Heat" = "H",
      "Soil Heat Flux" = "G_1_1_1"
    )
    
    met_var_name <- met_lookup[[met_var]]
    
    if(!is.null(met_var_name) && fch4_overall_df$recommended_method[i] == "GLS with AR(1)") {
      gls_stats <- calculate_gls_stats(df_monthly_FCH4, "FCH4", met_var_name)
      fch4_overall_df$gls_intercept[i] <- gls_stats$intercept
      fch4_overall_df$pseudo_r2[i] <- gls_stats$pseudo_r2
      fch4_overall_df$phi[i] <- gls_stats$phi
    }
  }
}

# ============================================================================
# CREATE PLOTS - SIGNIFICANT RELATIONSHIPS ONLY
# ============================================================================

cat("\n--- Creating Plots for Significant Relationships ---\n\n")

all_plots <- list()

# FC plots
if(exists("fc_overall_df")) {
  sig_fc <- fc_overall_df %>%
    dplyr::filter(grepl("Yes", significant))
  
  met_lookup <- list(
    "Air Temp" = list(var = "TA_gapfilled", label = "Air Temp", units = "°C"),
    "Soil Temp" = list(var = "TS_3_gapfilled", label = "Soil Temp", units = "°C"),
    "Soil Moisture" = list(var = "SWC_3_1_1", label = "Soil Moisture", units = "%"),
    "VPD" = list(var = "VPD", label = "VPD", units = "hPa"),
    "RH" = list(var = "RH", label = "RH", units = "%"),
    "Latent Heat" = list(var = "LE", label = "Latent Heat", units = "W/m²"),
    "Sensible Heat" = list(var = "H", label = "Sensible Heat", units = "W/m²"),
    "Soil Heat Flux" = list(var = "G_1_1_1", label = "Soil Heat Flux", units = "W/m²")
  )
  
  for(i in 1:nrow(sig_fc)) {
    met_info <- met_lookup[[sig_fc$met_variable[i]]]
    if(!is.null(met_info)) {
      p <- plot_flux_met_gls(
        df_monthly_FC, "FC", met_info$var,
        "CO₂ Flux", met_info$label, "µmol/m²/s", met_info$units,
        sig_fc[i, ]
      )
      all_plots[[paste0("FC_", met_info$label)]] <- p
      cat("Created: FC vs", met_info$label, "\n")
    }
  }
}

# FCH4 plots (excluding LE if not significant)
if(exists("fch4_overall_df")) {
  sig_fch4 <- fch4_overall_df %>%
    dplyr::filter(grepl("Yes", significant))
  
  for(i in 1:nrow(sig_fch4)) {
    met_info <- met_lookup[[sig_fch4$met_variable[i]]]
    if(!is.null(met_info)) {
      
      # Special handling for Soil Moisture (threshold case)
      text_pos <- ifelse(sig_fch4$met_variable[i] == "Soil Moisture", 
                        "top-left", "bottom-left")
      
      p <- plot_flux_met_gls(
        df_monthly_FCH4, "FCH4", met_info$var,
        "CH₄ Flux", met_info$label, "nmol/m²/s", met_info$units,
        sig_fch4[i, ],
        text_position = text_pos
      )
      all_plots[[paste0("FCH4_", met_info$label)]] <- p
      cat("Created: FCH4 vs", met_info$label, "\n")
    }
  }
}

# ============================================================================
# CREATE COMBINED FIGURE
# ============================================================================

cat("\n--- Creating Combined Multi-Panel Figure ---\n")

if(length(all_plots) > 0) {
  n_plots <- length(all_plots)
  ncol_plots <- 3
  nrow_plots <- ceiling(n_plots / ncol_plots)
  
  # Remove legends from all but first plot
  plots_for_grid <- lapply(seq_along(all_plots), function(i) {
    if(i == 1) {
      all_plots[[i]]
    } else {
      all_plots[[i]] + theme(legend.position = "none")
    }
  })
  
  # Create combined figure
  combined_fig <- grid.arrange(
    grobs = plots_for_grid,
    ncol = ncol_plots,
    top = grid::textGrob(
      "Monthly Mean Flux Relationships with Meteorological Variables", 
      gp = grid::gpar(fontsize = 16, fontface = "bold")
    )
  )
  
  # Save
  # ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Monthly_Flux_Met_Relationships.png", combined_fig,
  #        width = 6 * ncol_plots, height = 5 * nrow_plots, dpi = 300)
  # cat("\nSaved: Flux_Met_Relationships_Updated.png\n")
  
  # Print individual plots
  for(plot_name in names(all_plots)) {
    print(all_plots[[plot_name]])
  }
}

cat("\n\n============================================================\n")
cat("VISUALIZATION COMPLETE\n")
cat("============================================================\n\n")

cat("Methods shown:\n")
cat("- Blue line = GLS with AR(1) or Linear Regression (parametric)\n")
cat("- Green line = Kendall's tau with loess smoother (non-parametric)\n")
cat("- Statistics displayed match the recommended method\n")
cat("- Only significant relationships (where methods agree) are shown\n")
```



#Final plots 
```{r}
# UPDATED VISUALIZATION: Flux-Meteorology Relationships
# Shows appropriate statistics based on GLS with AR(1) or Kendall's tau

library(ggplot2)
library(dplyr)
library(gridExtra)
library(nlme)

# ============================================================================
# FUNCTION: Create scatterplot with appropriate statistics
# ============================================================================

plot_flux_met_gls <- function(data, flux_var, met_var, 
                              flux_label, met_label, 
                              flux_units, met_units,
                              result_row,
                              text_position = "bottom-left") {
  
  # Prepare data
  plot_data <- data %>%
    dplyr::select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.))
  
  # Determine which method was used based on result_row
  method_used <- result_row$recommended_method
  
  # Create statistics label based on method
  if(method_used == "GLS with AR(1)") {
    
    # Format p-value
    p_formatted <- if(result_row$gls_p < 0.0001) {
      "p < 0.0001"
    } else {
      paste0("p = ", sprintf("%.3f", result_row$gls_p))
    }
    
    stats_label <- paste0(
      "GLS with AR(1)\n",
      "Slope = ", sprintf("%.3f", result_row$gls_slope), "\n",
      p_formatted, "\n",
      "Phi = ", sprintf("%.2f", result_row$phi),
      ifelse(!is.na(result_row$pseudo_r2), 
             paste0("\nPseudo-R² = ", sprintf("%.3f", result_row$pseudo_r2)), "")
    )
    line_color <- "blue"
    use_gls_line <- TRUE
    
  } else if(method_used == "Linear Regression") {
    
    # Format p-value
    p_formatted <- if(result_row$lm_p < 0.0001) {
      "p < 0.0001"
    } else {
      paste0("p = ", sprintf("%.3f", result_row$lm_p))
    }
    
    stats_label <- paste0(
      "Linear Regression\n",
      "Slope = ", sprintf("%.3f", result_row$lm_slope), "\n",
      "R² = ", sprintf("%.3f", result_row$lm_r2), "\n",
      p_formatted
    )
    line_color <- "blue"
    use_gls_line <- FALSE
    
  } else if(grepl("Kendall", method_used)) {
    
    # Format p-value
    p_formatted <- if(result_row$kendall_p < 0.0001) {
      "p < 0.0001"
    } else {
      paste0("p = ", sprintf("%.3f", result_row$kendall_p))
    }
    
    stats_label <- paste0(
      "Kendall's tau\n",
      "τ = ", sprintf("%.3f", result_row$kendall_tau), "\n",
      p_formatted,
      ifelse(result_row$autocorr_detected, "\n(Autocorr detected)", "")
    )
    line_color <- "darkgreen"
    use_gls_line <- FALSE
  }
  
  # Create base plot
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    
    # Points colored by year
    geom_point(aes(color = as.factor(year)), size = 3, alpha = 0.7) +
    
    # Add appropriate line
    {if(use_gls_line && !is.na(result_row$gls_slope)) {
      # GLS line - manually add using slope and intercept
      geom_abline(slope = result_row$gls_slope, 
                  intercept = result_row$gls_intercept,
                  color = line_color, linewidth = 1.2)
    } else if(method_used == "Linear Regression") {
      # Standard LM line
      geom_smooth(method = "lm", se = TRUE, 
                  color = line_color, fill = line_color, 
                  alpha = 0.2, linewidth = 1.2)
    } else {
      # Kendall - use loess smoother
      geom_smooth(method = "loess", se = TRUE, 
                  color = line_color, fill = line_color, 
                  alpha = 0.2, linewidth = 1.2)
    }} +
    
    # Add statistics annotation
    {if(text_position == "top-right") {
      annotate("text", x = Inf, y = Inf, 
               label = stats_label,
               hjust = 1.1, vjust = 1.5, size = 3.5, fontface = "bold")
    } else if(text_position == "top-left") {
      annotate("text", x = -Inf, y = Inf, 
               label = stats_label,
               hjust = -0.1, vjust = 1.5, size = 3.5, fontface = "bold")
    } else {
      annotate("text", x = -Inf, y = -Inf, 
               label = stats_label,
               hjust = -0.1, vjust = -0.5, size = 3.5, fontface = "bold")
    }} +
    
    # Labels with proper subscripts
    labs(x = paste0(met_label, " (", met_units, ")"),
         y = if(grepl("CH", flux_label)) {
           bquote("Monthly Mean CH"[4] ~ "Flux (" * .(flux_units) * ")")
         } else if(grepl("CO", flux_label)) {
           bquote("Monthly Mean CO"[2] ~ "Flux (" * .(flux_units) * ")")
         } else {
           paste0("Monthly Mean ", flux_label, " (", flux_units, ")")
         },
         title = if(grepl("CH", flux_label)) {
           bquote("Monthly Mean CH"[4] ~ "Flux vs" ~ .(met_label))
         } else if(grepl("CO", flux_label)) {
           bquote("Monthly Mean CO"[2] ~ "Flux vs" ~ .(met_label))
         } else {
           paste0("Monthly Mean ", flux_label, " vs ", met_label)
         },
         color = "Year") +
    
    # Theme
    theme_bw() +
    theme(
      plot.title = element_text(face = "bold", size = 12),
      axis.title = element_text(face = "bold", size = 11),
      axis.text = element_text(face = "bold", size = 9),
      legend.position = "right",
      legend.title = element_text(face = "bold"),
      legend.text = element_text(size = 9)
    ) +
    
    # Color scale for years
    scale_color_manual(
      values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                 "2019" = "#4DAF4A", "2020" = "#984EA3", 
                 "2021" = "#FF7F00", "2022" = "#A65628")
    )
  
  return(p)
}

# ============================================================================
# HELPER: Calculate GLS intercept and pseudo-R²
# ============================================================================

calculate_gls_stats <- function(data, flux_var, met_var) {
  
  plot_data <- data %>%
    dplyr::select(flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.))
  
  tryCatch({
    gls_model <- gls(flux ~ met, 
                     correlation = corAR1(form = ~ 1),
                     data = plot_data)
    
    # Extract intercept
    intercept <- coef(gls_model)[1]
    
    # Calculate pseudo-R² (correlation between fitted and observed)
    pseudo_r2 <- cor(fitted(gls_model), plot_data$flux)^2
    
    # Extract Phi
    phi <- as.numeric(coef(gls_model$modelStruct$corStruct, unconstrained = FALSE))
    
    return(list(intercept = intercept, pseudo_r2 = pseudo_r2, phi = phi))
    
  }, error = function(e) {
    return(list(intercept = NA, pseudo_r2 = NA, phi = NA))
  })
}

# ============================================================================
# PREPARE RESULTS DATA
# ============================================================================

cat("============================================================\n")
cat("PREPARING UPDATED VISUALIZATIONS\n")
cat("============================================================\n\n")

# Add GLS intercept and pseudo-R² to results
if(exists("fc_overall_df")) {
  cat("Processing FC results...\n")
  
  # Initialize new columns
  if(!"gls_intercept" %in% names(fc_overall_df)) fc_overall_df$gls_intercept <- NA
  if(!"pseudo_r2" %in% names(fc_overall_df)) fc_overall_df$pseudo_r2 <- NA
  if(!"phi" %in% names(fc_overall_df)) fc_overall_df$phi <- NA
  
  for(i in 1:nrow(fc_overall_df)) {
    met_var <- fc_overall_df$met_variable[i]
    
    # Find the matching met variable name
    met_lookup <- list(
      "Air Temp" = "TA_gapfilled",
      "Soil Temp" = "TS_3_gapfilled",
      "Soil Moisture" = "SWC_3_1_1",
      "VPD" = "VPD",
      "RH" = "RH",
      "Latent Heat" = "LE",
      "Sensible Heat" = "H",
      "Soil Heat Flux" = "G_1_1_1"
    )
    
    met_var_name <- met_lookup[[met_var]]
    
    # Calculate GLS stats for GLS relationships OR Air Temp (forcing GLS)
    if(!is.null(met_var_name) && 
       (fc_overall_df$recommended_method[i] == "GLS with AR(1)" || met_var == "Air Temp")) {
      gls_stats <- calculate_gls_stats(df_monthly_FC, "FC", met_var_name)
      fc_overall_df$gls_intercept[i] <- gls_stats$intercept
      fc_overall_df$pseudo_r2[i] <- gls_stats$pseudo_r2
      fc_overall_df$phi[i] <- gls_stats$phi
    }
  }
}

if(exists("fch4_overall_df")) {
  cat("Processing FCH4 results...\n")
  
  # Initialize new columns
  fch4_overall_df$gls_intercept <- NA
  fch4_overall_df$pseudo_r2 <- NA
  fch4_overall_df$phi <- NA
  
  for(i in 1:nrow(fch4_overall_df)) {
    met_var <- fch4_overall_df$met_variable[i]
    
    met_lookup <- list(
      "Air Temp" = "TA_gapfilled",
      "Soil Temp" = "TS_3_gapfilled",
      "Soil Moisture" = "SWC_3_1_1",
      "VPD" = "VPD",
      "RH" = "RH",
      "Latent Heat" = "LE",
      "Sensible Heat" = "H",
      "Soil Heat Flux" = "G_1_1_1"
    )
    
    met_var_name <- met_lookup[[met_var]]
    
    if(!is.null(met_var_name) && fch4_overall_df$recommended_method[i] == "GLS with AR(1)") {
      gls_stats <- calculate_gls_stats(df_monthly_FCH4, "FCH4", met_var_name)
      fch4_overall_df$gls_intercept[i] <- gls_stats$intercept
      fch4_overall_df$pseudo_r2[i] <- gls_stats$pseudo_r2
      fch4_overall_df$phi[i] <- gls_stats$phi
    }
  }
}

# ============================================================================
# CREATE PLOTS - FINAL SIGNIFICANT RELATIONSHIPS
# ============================================================================

cat("\n--- Creating Plots for Final Significant Relationships ---\n\n")

all_plots <- list()

# Manual specification of relationships to include
# Based on: GLS/Kendall agreement, non-linearity considerations, and biological relevance

relationships_to_plot <- list(
  # FC relationships
  list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
       flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
       met_var = "TA_gapfilled", met_label = "Air Temp", met_units = "°C",
       result_source = "fc_overall_df", force_gls = TRUE),  # Force GLS for Air Temp
  
  list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
       flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
       met_var = "LE", met_label = "Latent Heat", met_units = "W/m²",
       result_source = "fc_overall_df"),
  
  # list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
  #      flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
  #      met_var = "H", met_label = "Sensible Heat", met_units = "W/m²",
  #      result_source = "fc_overall_df"),
  
  # list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
  #      flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
  #      met_var = "G_1_1_1", met_label = "Soil Heat Flux", met_units = "W/m²",
  #      result_source = "fc_overall_df"),
  
  #monotonic relationship for FC ~ G soil heat - override the lm 
  list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC",
       flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
       met_var = "G_1_1_1", met_label = "Soil Heat Flux", met_units = "W/m²",
       result_source = "fc_overall_df", force_kendall = TRUE),
  
  
  list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
       flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
       met_var = "TS_3_gapfilled", met_label = "Soil Temp", met_units = "°C",
       result_source = "fc_overall_df"),
  
  list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
       flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
       met_var = "RH", met_label = "RH", met_units = "%",
       result_source = "fc_overall_df"),
  
  list(flux_data = "FC", data = df_monthly_FC, flux_var = "FC", 
       flux_label = "CO₂ Flux", flux_units = "µmol/m²/s",
       met_var = "VPD", met_label = "VPD", met_units = "hPa",
       result_source = "fc_overall_df"),
  
  # FCH4 relationship - only Soil Moisture (Kendall significant, non-linear)
  # SPECIAL: Override to use Kendall instead of GLS for this relationship
  list(flux_data = "FCH4", data = df_monthly_FCH4, flux_var = "FCH4", 
       flux_label = "CH₄ Flux", flux_units = "nmol/m²/s",
       met_var = "SWC_3_1_1", met_label = "Soil Moisture", met_units = "%",
       result_source = "fch4_overall_df", force_kendall = TRUE)
)

# Create plots
for(rel in relationships_to_plot) {
  
  # Get result row
  if(rel$result_source == "fc_overall_df" && exists("fc_overall_df")) {
    result_row <- fc_overall_df %>% 
      dplyr::filter(met_variable == rel$met_label)
  } else if(rel$result_source == "fch4_overall_df" && exists("fch4_overall_df")) {
    result_row <- fch4_overall_df %>% 
      dplyr::filter(met_variable == rel$met_label)
  } else {
    next
  }
  
  if(nrow(result_row) == 0) next
  
  # SPECIAL: Override to Kendall for FCH4 vs Soil Moisture
  if(!is.null(rel$force_kendall) && rel$force_kendall) {
    result_row$recommended_method <- "Kendall's tau"
  }
  
  # Special positioning for FCH4 vs Soil Moisture
  text_pos <- if(rel$flux_data == "FCH4" && rel$met_label == "Soil Moisture") {
    "top-left"
  } else {
    "bottom-left"
  }
  
  p <- plot_flux_met_gls(
    rel$data, rel$flux_var, rel$met_var,
    rel$flux_label, rel$met_label, rel$flux_units, rel$met_units,
    result_row,
    text_position = text_pos
  )
  
  all_plots[[paste0(rel$flux_data, "_", rel$met_label)]] <- p
  cat("Created:", rel$flux_data, "vs", rel$met_label, "\n")
}

# ============================================================================
# CREATE COMBINED FIGURE
# ============================================================================


cat("\n--- Creating Combined Multi-Panel Figure ---\n")

if(length(all_plots) > 0) {
  n_plots <- length(all_plots)
  ncol_plots <- 3
  nrow_plots <- ceiling(n_plots / ncol_plots)
  
  # Extract legend from first plot and make it horizontal
  library(gridExtra)
  library(grid)
  
  # Recreate first plot with horizontal legend
  first_plot_horiz <- all_plots[[1]] + 
    theme(legend.position = "bottom",
          legend.direction = "horizontal",
          legend.box = "horizontal")
  
  g <- ggplotGrob(first_plot_horiz)
  legend <- g$grobs[[which(sapply(g$grobs, function(x) x$name) == "guide-box")]]
  
  # Remove legends from ALL plots
  plots_no_legend <- lapply(all_plots, function(p) {
    p + theme(legend.position = "none")
  })
  
  # Calculate layout
  # We want plots + legend at bottom
  n_plot_positions <- ncol_plots * nrow_plots
  
  # Add empty grobs to fill out the grid if needed
  n_empty <- n_plot_positions - n_plots
  if(n_empty > 0) {
    for(i in 1:n_empty) {
      plots_no_legend[[length(plots_no_legend) + 1]] <- grid::nullGrob()
    }
  }
  
  # Create plot grid
  plot_grid <- arrangeGrob(grobs = plots_no_legend, ncol = ncol_plots)
  
  # Combine with title and legend at bottom
  combined_fig <- grid.arrange(
    plot_grid,
    legend,
    ncol = 1,
    heights = c(10, 0.8),  # Slightly more space for horizontal legend
    top = textGrob(
      "Monthly Mean Flux Relationships with Meteorological Variables", 
      gp = gpar(fontsize = 16, fontface = "bold")
    )
  )
  

  cat("\nIncluded relationships:\n")
  cat("- FC: Air Temp, Latent Heat, Sensible Heat*, Soil Heat Flux*, Soil Temp, RH, VPD\n")
  cat("- FCH4: Soil Moisture* (threshold/non-linear)\n")
  cat("\n* = Non-linear relationship, Kendall's tau used\n")
  cat("\nExcluded relationships:\n")
  cat("- FCH4 vs Soil Temp (weak R², GLS-Kendall disagreement)\n")
  cat("- FCH4 vs LE (R² = 8.5%, GLS-Kendall disagreement)\n")
}

cat("\n\n============================================================\n")
cat("VISUALIZATION COMPLETE\n")
cat("============================================================\n\n")

cat("Final Methods Summary:\n")
cat("- Linear relationships with autocorrelation: GLS with AR(1)\n")
cat("- Non-linear relationships with autocorrelation: Kendall's tau\n")
cat("- Legend positioned at bottom of combined figure\n")
cat("- All relationships shown have robust statistical support\n")



```

#save combined fig
```{r}
  # Save
  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Monthly_Flux_Met_Relationships_Final.png", combined_fig,
         width = 6 * ncol_plots, height = 5 * nrow_plots + 0.5, dpi = 600)
```

#FC ~ Air temp manually annotated plots to show GLS results 

```{r}
# REPLACE FC ~ Air Temp plot with GLS stats
library(ggplot2)
library(dplyr)

cat("Rebuilding FC ~ Air Temp plot with GLS stats...\n")

# Prepare data
plot_data <- df_monthly_FC %>%
  dplyr::select(year, month, FC, TA_gapfilled) %>%
  dplyr::filter(complete.cases(.))

# Create fresh plot with GLS stats
p_airtemp_gls <- ggplot(plot_data, aes(x = TA_gapfilled, y = FC)) +
  geom_point(aes(color = as.factor(year)), size = 3, alpha = 0.7) +
  geom_smooth(method = "lm", se = TRUE, color = "blue", fill = "blue", 
              alpha = 0.2, linewidth = 1.2) +
  annotate("text", x = -Inf, y = -Inf,
           label = "GLS with AR(1)\nSlope = -0.092\np < 0.0001\nPhi = 0.18\nPseudo-R² = 0.676",
           hjust = -0.1, vjust = -0.5, size = 3.5, fontface = "bold") +
  labs(x = "Air Temp (°C)",
       y = bquote("Monthly Mean CO"[2] ~ "Flux (µmol/m²/s)"),
       title = bquote("Monthly Mean CO"[2] ~ "Flux vs Air Temp"),
       color = "Year") +
  scale_color_manual(values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                                "2019" = "#4DAF4A", "2020" = "#984EA3", 
                                "2021" = "#FF7F00", "2022" = "#A65628")) +
  theme_bw() +
  theme(plot.title = element_text(face = "bold", size = 12),
        axis.title = element_text(face = "bold", size = 11),
        axis.text = element_text(face = "bold", size = 9),
        legend.position = "right",
        legend.title = element_text(face = "bold"),
        legend.text = element_text(size = 9))

# Replace in all_plots list
all_plots[["FC_Air Temp"]] <- p_airtemp_gls

cat("✓ Replaced FC ~ Air Temp plot\n")
cat("Now recreate the combined figure with grid.arrange...\n")


#run this and now re-run the combining plot code above ** 
```










#Comprehensive autocorr checks
```{r}
# COMPREHENSIVE AUTOCORRELATION DIAGNOSTICS
# Checks DW test vs ACF lag-1 for all flux-meteorology relationships

library(dplyr)
library(lmtest)
library(ggplot2)
library(gridExtra)

cat("============================================================\n")
cat("AUTOCORRELATION DIAGNOSTIC: DW TEST vs ACF LAG-1\n")
cat("============================================================\n\n")

# ============================================================================
# FUNCTION: Check autocorrelation with both DW and ACF
# ============================================================================

check_autocorr_comprehensive <- function(data, flux_var, met_var, 
                                        flux_label, met_label) {
  
  # Prepare data
  plot_data <- data %>%
    dplyr::select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.)) %>%
    arrange(year, month)
  
  if(nrow(plot_data) < 10) {
    cat("Insufficient data for", flux_label, "~", met_label, "\n")
    return(NULL)
  }
  
  cat("\n--- ", flux_label, "~", met_label, " ---\n", sep = "")
  cat("N observations:", nrow(plot_data), "\n")
  
  # Fit linear model
  lm_model <- lm(flux ~ met, data = plot_data)
  residuals_vals <- residuals(lm_model)
  
  # 1. Durbin-Watson test
  dw_test <- dwtest(lm_model)
  dw_stat <- as.numeric(dw_test$statistic)
  dw_p <- as.numeric(dw_test$p.value)
  dw_significant <- dw_p < 0.05
  
  cat("\nDurbin-Watson Test:\n")
  cat("  DW statistic:", round(dw_stat, 3), "\n")
  cat("  p-value:", round(dw_p, 4), "\n")
  cat("  Autocorrelation:", ifelse(dw_significant, "YES (p < 0.05)", "NO (p >= 0.05)"), "\n")
  
  # 2. ACF analysis
  acf_result <- acf(residuals_vals, lag.max = 15, plot = FALSE)
  lag1_acf <- acf_result$acf[2]  # lag-1 (first element is lag-0)
  
  # Calculate 95% confidence threshold
  threshold <- 1.96 / sqrt(nrow(plot_data))
  lag1_significant <- abs(lag1_acf) > threshold
  
  cat("\nACF Lag-1:\n")
  cat("  Lag-1 ACF:", round(lag1_acf, 3), "\n")
  cat("  95% threshold: ±", round(threshold, 3), "\n")
  cat("  Exceeds threshold:", ifelse(lag1_significant, "YES", "NO"), "\n")
  
  # 3. Count how many lags breach
  n_breaches <- sum(abs(acf_result$acf[-1]) > threshold)  # Exclude lag-0
  cat("\nTotal lags breaching 95% CI:", n_breaches, "out of", length(acf_result$acf) - 1, "\n")
  
  # 4. Check for pattern in breaches
  first_3_breaches <- sum(abs(acf_result$acf[2:4]) > threshold)
  pattern_detected <- first_3_breaches >= 2
  
  if(pattern_detected) {
    cat("  Pattern: Multiple consecutive early lags breach (strong autocorrelation)\n")
  } else if(n_breaches > 0) {
    cat("  Pattern: Scattered breaches (possibly spurious)\n")
  }
  
  # 5. Agreement between DW and ACF lag-1
  agreement <- dw_significant == lag1_significant
  
  cat("\n--- ASSESSMENT ---\n")
  if(agreement) {
    cat("✓ DW and ACF lag-1 AGREE\n")
    if(dw_significant) {
      cat("  → Autocorrelation detected by both methods\n")
      cat("  → RECOMMENDATION: Use GLS with AR(1)\n")
    } else {
      cat("  → No autocorrelation detected by either method\n")
      cat("  → RECOMMENDATION: Standard linear regression is fine\n")
    }
  } else {
    cat("⚠ DW and ACF lag-1 DISAGREE\n")
    if(dw_significant && !lag1_significant) {
      cat("  → DW says YES, ACF lag-1 says NO (unusual)\n")
      cat("  → Lag-1 ACF might be near threshold\n")
      cat("  → RECOMMENDATION: Use GLS (trust DW)\n")
    } else if(!dw_significant && lag1_significant) {
      cat("  → DW says NO, ACF lag-1 says YES\n")
      cat("  → DW might have insufficient power (n =", nrow(plot_data), ")\n")
      cat("  → RECOMMENDATION: Use GLS (be conservative)\n")
    }
  }
  
  # Additional consideration for multiple breaches
  if(!dw_significant && !lag1_significant && n_breaches > 2) {
    cat("\n⚠ Note: Multiple other lags breach despite no lag-1 autocorrelation\n")
    cat("  → These are likely SPURIOUS (random false positives)\n")
    cat("  → With 15 lags tested, expect ~1 breach by chance\n")
    cat("  → RECOMMENDATION: Ignore scattered breaches, no GLS needed\n")
  }
  
  # Store results
  result <- data.frame(
    flux = flux_label,
    met_variable = met_label,
    n = nrow(plot_data),
    
    # DW test
    dw_statistic = dw_stat,
    dw_p = dw_p,
    dw_autocorr = dw_significant,
    
    # ACF
    lag1_acf = lag1_acf,
    acf_threshold = threshold,
    lag1_significant = lag1_significant,
    
    # Summary
    n_breaches = n_breaches,
    pattern_detected = pattern_detected,
    dw_acf_agree = agreement,
    
    # Recommendation
    recommendation = ifelse(
      dw_significant | lag1_significant | pattern_detected,
      "Use GLS",
      "Standard LM okay"
    ),
    
    stringsAsFactors = FALSE
  )
  
  # Create ACF plot
  acf_df <- data.frame(
    lag = 1:length(acf_result$acf[-1]),
    acf = acf_result$acf[-1]
  )
  
  p <- ggplot(acf_df, aes(x = lag, y = acf)) +
    geom_hline(yintercept = 0, color = "black") +
    geom_hline(yintercept = c(-threshold, threshold), 
               linetype = "dashed", color = "blue") +
    geom_segment(aes(xend = lag, yend = 0), linewidth = 2, color = "black") +
    geom_point(size = 2, color = "black") +
    # Highlight lag-1
    geom_point(data = acf_df[1, ], size = 4, color = "red") +
    labs(
      title = paste(flux_label, "~", met_label),
      subtitle = paste0("Lag-1 ACF: ", round(lag1_acf, 3), 
                       " | DW p = ", round(dw_p, 3),
                       " | ", result$recommendation),
      x = "Lag",
      y = "ACF"
    ) +
    annotate("text", x = max(acf_df$lag) * 0.7, y = max(acf_df$acf) * 0.8,
             label = "Red = Lag-1\nBlue = 95% CI",
             hjust = 0, size = 3) +
    theme_bw() +
    theme(plot.title = element_text(face = "bold", size = 11))
  
  return(list(result = result, plot = p))
}

# ============================================================================
# RUN DIAGNOSTICS FOR ALL RELATIONSHIPS
# ============================================================================

# Met variable lookup
met_vars <- list(
  list(var = "TA_gapfilled", label = "Air Temp"),
  list(var = "TS_3_gapfilled", label = "Soil Temp"),
  list(var = "SWC_3_1_1", label = "Soil Moisture"),
  list(var = "VPD", label = "VPD"),
  list(var = "RH", label = "RH"),
  list(var = "LE", label = "Latent Heat"),
  list(var = "H", label = "Sensible Heat"),
  list(var = "G_1_1_1", label = "Soil Heat Flux")
)

# FC relationships
cat("\n\n════════════════════════════════════════════════════════════\n")
cat("FC (CO₂ FLUX) RELATIONSHIPS\n")
cat("════════════════════════════════════════════════════════════\n")

fc_autocorr_results <- list()
fc_acf_plots <- list()

for(met in met_vars) {
  result_list <- check_autocorr_comprehensive(
    df_monthly_FC, "FC", met$var,
    "CO₂ Flux", met$label
  )
  
  if(!is.null(result_list)) {
    fc_autocorr_results[[met$label]] <- result_list$result
    fc_acf_plots[[met$label]] <- result_list$plot
  }
}

# FCH4 relationships
cat("\n\n════════════════════════════════════════════════════════════\n")
cat("FCH4 (CH₄ FLUX) RELATIONSHIPS\n")
cat("════════════════════════════════════════════════════════════\n")

fch4_autocorr_results <- list()
fch4_acf_plots <- list()

for(met in met_vars) {
  result_list <- check_autocorr_comprehensive(
    df_monthly_FCH4, "FCH4", met$var,
    "CH₄ Flux", met$label
  )
  
  if(!is.null(result_list)) {
    fch4_autocorr_results[[met$label]] <- result_list$result
    fch4_acf_plots[[met$label]] <- result_list$plot
  }
}

# ============================================================================
# SUMMARY TABLE
# ============================================================================

cat("\n\n════════════════════════════════════════════════════════════\n")
cat("SUMMARY TABLE: AUTOCORRELATION DIAGNOSTICS\n")
cat("════════════════════════════════════════════════════════════\n\n")

# Combine results
fc_summary <- do.call(rbind, fc_autocorr_results)
fch4_summary <- do.call(rbind, fch4_autocorr_results)
all_summary <- rbind(fc_summary, fch4_summary)

# Print summary
print(all_summary %>% 
      dplyr::select(flux, met_variable, n, dw_p, dw_autocorr, 
                    lag1_acf, lag1_significant, dw_acf_agree, recommendation))

cat("\n\nKEY:\n")
cat("dw_autocorr = Durbin-Watson detected autocorrelation (p < 0.05)\n")
cat("lag1_significant = Lag-1 ACF exceeds 95% threshold\n")
cat("dw_acf_agree = Both methods agree (TRUE) or disagree (FALSE)\n")

# ============================================================================
# CREATE ACF PLOT GRID
# ============================================================================

cat("\n\n--- Creating ACF Plot Grid ---\n")

# Combine all plots
all_acf_plots <- c(fc_acf_plots, fch4_acf_plots)

if(length(all_acf_plots) > 0) {
  n_plots <- length(all_acf_plots)
  ncol_plots <- 3
  nrow_plots <- ceiling(n_plots / ncol_plots)
  
  acf_grid <- grid.arrange(
    grobs = all_acf_plots,
    ncol = ncol_plots,
    top = grid::textGrob("ACF Plots: All Flux-Meteorology Relationships",
                        gp = grid::gpar(fontsize = 14, fontface = "bold"))
  )
  
  ggsave("ACF_Diagnostics_All_Relationships.png", acf_grid,
         width = 5 * ncol_plots, height = 4 * nrow_plots, dpi = 300)
  cat("Saved: ACF_Diagnostics_All_Relationships.png\n")
}

# ============================================================================
# DISAGREEMENT CASES
# ============================================================================

cat("\n\n════════════════════════════════════════════════════════════\n")
cat("CASES WHERE DW AND ACF DISAGREE\n")
cat("════════════════════════════════════════════════════════════\n\n")

disagreements <- all_summary %>%
  dplyr::filter(!dw_acf_agree)

if(nrow(disagreements) > 0) {
  print(disagreements %>%
        dplyr::select(flux, met_variable, dw_p, dw_autocorr, 
                      lag1_acf, lag1_significant, recommendation))
  
  cat("\n⚠ These relationships need careful consideration!\n")
  cat("Review the ACF plots for these cases.\n")
} else {
  cat("✓ No disagreements found - all methods agree!\n")
}

cat("\n\n════════════════════════════════════════════════════════════\n")
cat("DIAGNOSTIC COMPLETE\n")
cat("════════════════════════════════════════════════════════════\n")

#In initial analyses, code chose LM for FC vs air temp, but in this diagnostic, the GLS with AR1 option would be better since multiple lags breach the dotted line. 
```

#GLS AR1 for FC vs Air temp & comparison to lm - streamlined from claude 
```{r}
# Quick GLS for FC ~ Air Temp
library(nlme)
library(dplyr)

cat("============================================================\n")
cat("GLS ANALYSIS: FC ~ Air Temperature\n")
cat("============================================================\n\n")

# Prepare data
fc_airtemp_data <- df_monthly_FC %>%
  dplyr::select(FC, TA_gapfilled) %>%
  dplyr::filter(complete.cases(.))

cat("N observations:", nrow(fc_airtemp_data), "\n\n")

# Fit GLS with AR(1)
gls_model <- gls(FC ~ TA_gapfilled, 
                 correlation = corAR1(form = ~ 1),
                 data = fc_airtemp_data)

# Extract results
gls_summary <- summary(gls_model)

gls_slope <- coef(gls_model)[2]
gls_intercept <- coef(gls_model)[1]
gls_p <- gls_summary$tTable[2, 4]
phi <- as.numeric(coef(gls_model$modelStruct$corStruct, unconstrained = FALSE))

# Calculate pseudo-R² (correlation between fitted and observed)
pseudo_r2 <- cor(fitted(gls_model), fc_airtemp_data$FC)^2

# Print results
cat("GLS with AR(1) Results:\n")
cat("----------------------\n")
cat("Intercept:", round(gls_intercept, 3), "\n")
cat("Slope:", round(gls_slope, 3), "\n")
cat("p-value:", ifelse(gls_p < 0.0001, "< 0.0001", round(gls_p, 4)), "\n")
cat("Phi (autocorrelation):", round(phi, 2), "\n")
cat("Pseudo-R²:", round(pseudo_r2, 3), "\n\n")

# Compare to original LM
lm_model <- lm(FC ~ TA_gapfilled, data = fc_airtemp_data)
lm_summary <- summary(lm_model)

cat("Original LM Results (for comparison):\n")
cat("-------------------------------------\n")
cat("Slope:", round(coef(lm_model)[2], 3), "\n")
cat("p-value:", ifelse(lm_summary$coefficients[2, 4] < 0.0001, "< 0.0001", 
                      round(lm_summary$coefficients[2, 4], 4)), "\n")
cat("R²:", round(lm_summary$r.squared, 3), "\n\n")

cat("Interpretation:\n")
cat("---------------\n")
if(abs(gls_slope - coef(lm_model)[2]) / abs(coef(lm_model)[2]) < 0.1) {
  cat("✓ Slopes are very similar (< 10% difference)\n")
  cat("✓ Conclusions would be the same with either method\n")
  cat("✓ GLS accounts for mild autocorrelation (Phi =", round(phi, 2), ")\n")
} else {
  cat("⚠ Slopes differ substantially\n")
  cat("→ Autocorrelation was affecting the estimate\n")
  cat("→ Use GLS result\n")
}

cat("\n============================================================\n")
```



#quick look at methane & met relationships
```{r}
ggplot(df_monthly_FCH4, aes(x = TS_3_gapfilled, y = FCH4)) +
  geom_point()+
  geom_smooth(data = df_monthly_FCH4, aes(x = TS_3_gapfilled, y = FCH4, method = "loess"))+
   theme_bw()
```





```{r}
ggplot(df_monthly_FC, aes(x = TA_gapfilled, y = FC)) +
  geom_point()+
  geom_smooth(data = df_monthly_FC, aes(x = TA_gapfilled, y = FC, method = "loess"))+
   theme_bw() 

ggplot(df_monthly_FC, aes(x = G_1_1_1, y = FC)) +
  geom_point()+
  geom_smooth(data = df_monthly_FC, aes(x = G_1_1_1, y = FC, method = "loess"))+
   theme_bw()


poly_model <- lm(FC ~ TA_gapfilled + I(TA_gapfilled^2), data = df_monthly_FC)
summary(poly_model)


ggplot(df_monthly_FC, aes(x = TA_gapfilled, y = FC)) +
  geom_point() +
geom_smooth(method = "lm", formula = y ~ x + I(x^2), color = "blue", se = TRUE) +
  theme_bw()

shapiro.test(residuals(poly_model)) #ok
plot(fitted(poly_model), residuals(poly_model)) #seems ok 

library(lmtest)
dwtest(poly_model) #ok 


AIC(
  lm(FC ~ TA_gapfilled, data = df_monthly_FC),                    # linear
  lm(FC ~ TA_gapfilled + I(TA_gapfilled^2), data = df_monthly_FC),# quadratic
  lm(FC ~ TA_gapfilled + I(TA_gapfilled^2) + I(TA_gapfilled^3), data = df_monthly_FC) # cubic
)

colnames(df_monthly_FC)

```


#within-season relationships 
```{r}
#need to update for autocorr 

# ============================================================================
# PART 3: SEASONAL FLUX-MET RELATIONSHIPS
# Question: Within each season, is there a relationship?
# Year order doesn't matter - just comparing flux levels with met levels
# ============================================================================

cat("\n============================================================\n")
cat("PART 3: SEASONAL FLUX-MET RELATIONSHIPS\n")
cat("============================================================\n\n")

analyze_seasonal_relationship <- function(data, flux_var, met_var, 
                                         flux_label, met_label,
                                         season_name) {
  
  # Filter for season
  season_data <- data %>%
    filter(season == season_name) %>%
    select(flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.))
  
  if(nrow(season_data) < 10) {
    return(NULL)
  }
  
  # Linear model
  lm_model <- lm(flux ~ met, data = season_data)
  slope <- coef(lm_model)[2]
  slope_p <- summary(lm_model)$coefficients[2, 4]
  r2 <- summary(lm_model)$r.squared
  
  # Check normality of residuals
  shapiro_p <- shapiro.test(residuals(lm_model))$p.value
  normal <- shapiro_p > 0.05
  
  # Kendall's tau (non-parametric alternative)
  kendall_test <- cor.test(season_data$met, season_data$flux, method = "kendall")
  kendall_tau <- kendall_test$estimate
  kendall_p <- kendall_test$p.value
  
  result <- data.frame(
    flux = flux_label,
    met_variable = met_label,
    season = season_name,
    n_obs = nrow(season_data),
    
    # Linear model
    slope = slope,
    slope_p = slope_p,
    r2 = r2,
    
    # Normality
    shapiro_p = shapiro_p,
    residuals_normal = normal,
    
    # Non-parametric
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    
    # Recommendation
    recommended_test = ifelse(normal, "Linear Regression", "Kendall"),
    significant = ifelse(normal,
                        ifelse(slope_p < 0.05, "Yes*", "No"),
                        ifelse(kendall_p < 0.05, "Yes**", "No"))
  )
  
  return(result)
}

# Run for FC by season
cat("\n--- FC (CO₂) SEASONAL RELATIONSHIPS ---\n")
fc_seasonal_results <- list()

for(met in met_vars) {
  for(s in seasons) {
    result <- analyze_seasonal_relationship(
      df_monthly_FC, "FC", met$var,
      "CO₂ Flux", met$label, s
    )
    if(!is.null(result)) {
      fc_seasonal_results[[paste(met$label, s)]] <- result
    }
  }
}

fc_seasonal_df <- do.call(rbind, fc_seasonal_results)
cat("\nSignificant relationships only:\n")
print(fc_seasonal_df %>% 
      filter(significant %in% c("Yes*", "Yes**")) %>%
      select(met_variable, season, n_obs, recommended_test, 
             slope, slope_p, kendall_tau, kendall_p, significant))

# Run for FCH4 by season
cat("\n--- FCH4 (CH₄) SEASONAL RELATIONSHIPS ---\n")
fch4_seasonal_results <- list()

for(met in met_vars) {
  for(s in seasons) {
    result <- analyze_seasonal_relationship(
      df_monthly_FCH4, "FCH4", met$var,
      "CH₄ Flux", met$label, s
    )
    if(!is.null(result)) {
      fch4_seasonal_results[[paste(met$label, s)]] <- result
    }
  }
}

fch4_seasonal_df <- do.call(rbind, fch4_seasonal_results)
cat("\nSignificant relationships only:\n")
print(fch4_seasonal_df %>% 
      filter(significant %in% c("Yes*", "Yes**")) %>%
      select(met_variable, season, n_obs, recommended_test, 
             slope, slope_p, kendall_tau, kendall_p, significant))

cat("\n\n============================================================\n")
cat("ANALYSIS COMPLETE\n")
cat("============================================================\n\n")

cat("DATA STRUCTURE:\n")
cat("- Part 1: Uses seasonal_means_FC and seasonal_means_FCH4\n")
cat("- Parts 2 & 3: Use df_monthly_FC and df_monthly_FCH4\n\n")


cat("Part 3 (Seasonal Relationships): Flux-met relationships within each season\n")
cat("  - Uses monthly means within each season\n")
cat("  - Year order doesn't matter (not temporal)\n")
cat("  - Uses Kendall when residuals non-normal\n\n")

cat("* = Parametric test (LM)\n")
cat("** = Non-parametric test (Kendall)\n")
cat("GLS = Generalized Least Squares (accounts for autocorrelation)\n")

```


#Polynomial fits for Air temp and soil heat flux 

```{r}
################################################################################
# COMPREHENSIVE EDDY COVARIANCE FLUX ANALYSIS WITH GAMMs
# 
# Purpose: Analyze non-linear relationships between CO2/CH4 fluxes and 
#          meteorological variables using Generalized Additive Mixed Models
#
# Why GAMMs?
# - Handles non-monotonic curves (U-shapes, W-shapes, temperature optima)
# - Accounts for temporal autocorrelation in time series data
# - No need to pre-specify polynomial degree
# - Widely accepted in ecological literature
#
# Author: [Your name]
# Date: [Today's date]
################################################################################

# ==============================================================================
# SECTION 1: LOAD PACKAGES
# ==============================================================================
# Only three packages needed - if you get errors, install them first:
# install.packages(c("mgcv", "nlme", "tidyverse"))

library(mgcv)          # For GAM/GAMM models (Wood 2017)
library(nlme)          # For correlation structures (AR1)
library(tidyverse)     # For data manipulation and ggplot2

cat("\n=== Packages loaded successfully ===\n")

# ==============================================================================
# SECTION 2: LOAD AND PREPARE DATA
# ==============================================================================

# Load your CSV files
# NOTE: Make sure these files are in your working directory
# Check with: getwd()
# Change directory if needed with: setwd("path/to/your/data")

# df_FC <- read_csv("df_monthly_FC_vs_met_vars.csv", show_col_types = FALSE)
# df_FCH4 <- read_csv("df_monthly_FCH4_vs_met_vars.csv", show_col_types = FALSE)

# Create time index for AR(1) correlation structure
# This tells the model the temporal order of observations
df_FC <- df_FC %>%
  arrange(year, month) %>%              # Sort chronologically
  mutate(time_index = row_number(),     # Create sequential time index
         year_factor = factor(year))    # Year as categorical for plotting

df_FCH4 <- df_FCH4 %>%
  arrange(year, month) %>%
  mutate(time_index = row_number(),
         year_factor = factor(year))

# Print data summary
cat("\n=== DATA SUMMARY ===\n")
cat("FC data:", nrow(df_FC), "observations from", min(df_FC$year), "to", max(df_FC$year), "\n")
cat("FCH4 data:", nrow(df_FCH4), "observations from", min(df_FCH4$year), "to", max(df_FCH4$year), "\n\n")

# ==============================================================================
# SECTION 3: HELPER FUNCTIONS
# ==============================================================================

# ------------------------------------------------------------------------------
# Function: test_autocorr()
# Purpose: Test if residuals show temporal autocorrelation
# 
# What it does:
# 1. Extracts residuals from model (handles both GAM and GAMM)
# 2. Creates ACF/PACF plots to visualize autocorrelation
# 3. Runs Ljung-Box test (p < 0.05 means autocorrelation is present)
#
# Why this matters:
# If autocorrelation exists, we need AR(1) correction (use GAMM not GAM)
# ------------------------------------------------------------------------------

test_autocorr <- function(model) {
  
  # Get residuals - method depends on model type
  if(inherits(model, "gam")) {
    # For simple GAM models
    resids <- residuals(model, type = "deviance")
  } else if(inherits(model, "lme")) {
    # For GAMM models (which return lme objects)
    resids <- residuals(model, type = "normalized")
  } else {
    # Fallback for other model types
    resids <- residuals(model)
  }
  
  # Create diagnostic plots side-by-side
  par(mfrow = c(1, 2))  # 1 row, 2 columns
  
  # ACF plot: shows correlation at different time lags
  # Bars outside blue lines = significant autocorrelation
  acf(resids, main = "ACF of Residuals")
  
  # PACF plot: shows direct (not indirect) correlations
  pacf(resids, main = "PACF of Residuals")
  
  par(mfrow = c(1, 1))  # Reset to single plot
  
  # Ljung-Box test: formal statistical test for autocorrelation
  # H0: No autocorrelation present
  # p < 0.05 means REJECT H0 (autocorrelation IS present)
  lb_test <- Box.test(resids, lag = 10, type = "Ljung-Box")
  cat("Ljung-Box test p-value:", round(lb_test$p.value, 4), "\n")
  
  if(lb_test$p.value < 0.05) {
    cat("⚠ Significant autocorrelation detected (p < 0.05)\n")
    cat("   → Should use GAMM with AR(1) correction\n")
  } else {
    cat("✓ No significant autocorrelation detected\n")
    cat("   → Simple GAM is okay, but GAMM is safer\n")
  }
  
  return(lb_test)
}

# ------------------------------------------------------------------------------
# Function: create_diagnostics()
# Purpose: Create 4-panel diagnostic plots to check model assumptions
#
# What to look for:
# - Residuals should be randomly scattered (no patterns)
# - Q-Q plot points should fall along diagonal line (normality)
# - No funnel shapes (heteroscedasticity is usually okay for GAMs)
# ------------------------------------------------------------------------------

create_diagnostics <- function(model, model_name) {
  par(mfrow = c(2, 2))  # 2x2 grid of plots
  gam.check(model)      # Built-in GAM diagnostic function
  title(main = paste(model_name, "Diagnostics"), outer = TRUE, line = -2)
  par(mfrow = c(1, 1))  # Reset
}

# ==============================================================================
# SECTION 4: ANALYSIS 1 - FC ~ TA_gapfilled (CO2 vs Air Temperature)
# ==============================================================================
#
# ECOLOGICAL QUESTION:
# How does CO2 flux respond to air temperature? 
# We expect a temperature optimum where uptake is maximized.
#
# ==============================================================================

cat("\n=== ANALYZING FC ~ TA_gapfilled (CO2 vs Air Temperature) ===\n\n")

# Remove rows with missing data
df_FC_TA <- df_FC %>% filter(!is.na(FC), !is.na(TA_gapfilled))

# ------------------------------------------------------------------------------
# MODEL 1: Simple GAM (no autocorrelation correction)
# ------------------------------------------------------------------------------
# This is our baseline model to compare against
# Formula: FC ~ s(TA_gapfilled, k = 6)
#   - s() means "smooth function" (the non-linear part)
#   - k = 6 means maximum of 6-1 = 5 "wiggles" in the curve
#   - method = "REML" is best for comparing models

cat("Model 1: GAM with default settings\n")
m1_FC_TA <- gam(FC ~ s(TA_gapfilled, k = 6), 
                data = df_FC_TA,
                method = "REML")

# Print model summary
print(summary(m1_FC_TA))
cat("Deviance explained:", round(summary(m1_FC_TA)$dev.expl * 100, 1), "%\n")
cat("(Deviance explained is like R² for GAMs)\n\n")

# Check for autocorrelation
cat("Checking for autocorrelation in Model 1:\n")
test_autocorr(m1_FC_TA)

# ------------------------------------------------------------------------------
# MODEL 2: GAMM with AR(1) correlation structure
# ------------------------------------------------------------------------------
# This model corrects for temporal autocorrelation
# AR(1) = autoregressive order 1 = correlation with previous time point
# form = ~ time_index tells it the temporal order

cat("\nModel 2: GAMM with AR(1) correlation structure\n")
m2_FC_TA <- gamm(FC ~ s(TA_gapfilled, k = 6),
                 data = df_FC_TA,
                 correlation = corAR1(form = ~ time_index),
                 method = "REML")

# Note: gamm() returns a list with $gam and $lme components
# $gam = GAM part (for summaries, predictions, plots)
# $lme = mixed model part (for AIC, correlation structure)

print(summary(m2_FC_TA$gam))
cat("Deviance explained:", round(summary(m2_FC_TA$gam)$dev.expl * 100, 1), "%\n\n")

# ------------------------------------------------------------------------------
# Compare models using AIC (Akaike Information Criterion)
# ------------------------------------------------------------------------------
# Lower AIC = better model
# Difference > 2 = meaningful improvement
# Difference > 10 = strong evidence for better model

cat("=== MODEL COMPARISON ===\n")
cat("Model 1 (GAM) AIC:", round(AIC(m1_FC_TA), 1), "\n")
cat("Model 2 (GAMM+AR1) AIC:", round(AIC(m2_FC_TA$lme), 1), "\n")
cat("Difference:", round(AIC(m1_FC_TA) - AIC(m2_FC_TA$lme), 1), "\n\n")

# Use the better model (usually Model 2)
best_model_FC_TA <- m2_FC_TA

# ------------------------------------------------------------------------------
# Create diagnostic plots
# ------------------------------------------------------------------------------
cat("Creating diagnostic plots...\n")
create_diagnostics(best_model_FC_TA$gam, "FC ~ TA (GAMM with AR1)")

# ------------------------------------------------------------------------------
# Generate predictions for plotting
# ------------------------------------------------------------------------------
# Create a sequence of temperature values across the observed range
pred_data_FC_TA <- data.frame(
  TA_gapfilled = seq(min(df_FC_TA$TA_gapfilled, na.rm = TRUE),
                     max(df_FC_TA$TA_gapfilled, na.rm = TRUE),
                     length.out = 200)  # 200 points for smooth curve
)

# Get predictions with standard errors for confidence intervals
pred_FC_TA <- predict(best_model_FC_TA$gam, 
                      newdata = pred_data_FC_TA, 
                      se.fit = TRUE)

# Calculate 95% confidence intervals
# ± 1.96 * SE gives 95% CI for normal distribution
pred_data_FC_TA <- pred_data_FC_TA %>%
  mutate(fit = pred_FC_TA$fit,
         se = pred_FC_TA$se.fit,
         lower = fit - 1.96 * se,    # Lower CI bound
         upper = fit + 1.96 * se)    # Upper CI bound

# ------------------------------------------------------------------------------
# Create publication-quality plot
# ------------------------------------------------------------------------------

p_FC_TA <- ggplot() +
  # 1. Add confidence band (shaded region)
  geom_ribbon(data = pred_data_FC_TA,
              aes(x = TA_gapfilled, ymin = lower, ymax = upper),
              alpha = 0.3, fill = "darkgreen") +
  
  # 2. Add fitted line (the GAM smooth)
  geom_line(data = pred_data_FC_TA,
            aes(x = TA_gapfilled, y = fit),
            color = "darkgreen", size = 1.2) +
  
  # 3. Add observed data points, colored by year
  geom_point(data = df_FC_TA,
             aes(x = TA_gapfilled, y = FC, color = year_factor),
             size = 2.5, alpha = 0.7) +
  
  # 4. Color scale (viridis is colorblind-friendly)
  scale_color_viridis_d(name = "Year") +
  
  # 5. Labels with proper formatting
  labs(title = "CO₂ Flux vs Air Temperature",
       subtitle = paste0("GAMM with AR(1) | Dev. expl: ",
                        round(summary(best_model_FC_TA$gam)$dev.expl * 100, 1), "%"),
       x = "Air Temperature (°C)",
       y = expression(paste("CO"[2], " Flux (μmol ", m^-2, s^-1, ")"))) +
  
  # 6. Theme settings
  theme_bw(base_size = 12) +
  theme(legend.position = c(0.85, 0.85),
        legend.background = element_rect(fill = "white", color = "black"),
        panel.grid.minor = element_blank())

# Display the plot
print(p_FC_TA)

# Save plot (COMMENTED OUT - uncomment when you want to save)
# ggsave("FC_vs_TA.png", p_FC_TA, width = 10, height = 7, dpi = 300)
# ggsave("FC_vs_TA.pdf", p_FC_TA, width = 10, height = 7)
cat("✓ Plot created (not saved yet)\n")

# ------------------------------------------------------------------------------
# Find temperature optimum (ecological interpretation)
# ------------------------------------------------------------------------------
# The temperature where FC is minimized = maximum CO2 uptake
# (Remember: negative FC = CO2 uptake)

# Create fine-scale temperature sequence
temp_range <- seq(min(df_FC_TA$TA_gapfilled, na.rm = TRUE),
                  max(df_FC_TA$TA_gapfilled, na.rm = TRUE),
                  length.out = 1000)  # 1000 points for precision

# Predict FC at each temperature
opt_pred <- predict(best_model_FC_TA$gam, 
                   newdata = data.frame(TA_gapfilled = temp_range))

# Find temperature where FC is minimum
temp_optimum <- temp_range[which.min(opt_pred)]

cat("\n*** ECOLOGICAL FINDING ***\n")
cat("Temperature optimum (minimum FC / maximum uptake):", 
    round(temp_optimum, 2), "°C\n")
cat("FC at optimum:", round(min(opt_pred), 3), "μmol m⁻² s⁻¹\n")
cat("Interpretation: Maximum CO2 uptake occurs at", round(temp_optimum, 1), 
    "°C.\n")
cat("Below and above this temperature, net uptake decreases.\n\n")

# ==============================================================================
# SECTION 5: ANALYSIS 2 - FC ~ G_1_1_1 (CO2 vs Ground Heat Flux)
# ==============================================================================
#
# ECOLOGICAL QUESTION:
# How does soil thermal regime affect CO2 flux?
#
# ==============================================================================

cat("\n=== ANALYZING FC ~ G_1_1_1 (CO2 vs Ground Heat Flux) ===\n\n")

# Prepare data
df_FC_G <- df_FC %>% filter(!is.na(FC), !is.na(G_1_1_1))

# Fit GAMM with AR(1)
# (Skipping the comparison step since we know AR(1) is needed)
m_FC_G <- gamm(FC ~ s(G_1_1_1, k = 6),
               data = df_FC_G,
               correlation = corAR1(form = ~ time_index),
               method = "REML")

print(summary(m_FC_G$gam))
cat("Deviance explained:", round(summary(m_FC_G$gam)$dev.expl * 100, 1), "%\n\n")

# Generate predictions
pred_data_FC_G <- data.frame(
  G_1_1_1 = seq(min(df_FC_G$G_1_1_1, na.rm = TRUE),
                max(df_FC_G$G_1_1_1, na.rm = TRUE),
                length.out = 200)
)

pred_FC_G <- predict(m_FC_G$gam, newdata = pred_data_FC_G, se.fit = TRUE)

pred_data_FC_G <- pred_data_FC_G %>%
  mutate(fit = pred_FC_G$fit,
         lower = fit - 1.96 * pred_FC_G$se.fit,
         upper = fit + 1.96 * pred_FC_G$se.fit)

# Create plot
p_FC_G <- ggplot() +
  geom_ribbon(data = pred_data_FC_G,
              aes(x = G_1_1_1, ymin = lower, ymax = upper),
              alpha = 0.3, fill = "darkgreen") +
  geom_line(data = pred_data_FC_G,
            aes(x = G_1_1_1, y = fit),
            color = "darkgreen", size = 1.2) +
  geom_point(data = df_FC_G,
             aes(x = G_1_1_1, y = FC, color = year_factor),
             size = 2.5, alpha = 0.7) +
  scale_color_viridis_d(name = "Year") +
  labs(title = "CO₂ Flux vs Ground Heat Flux",
       subtitle = paste0("GAMM with AR(1) | Dev. expl: ",
                        round(summary(m_FC_G$gam)$dev.expl * 100, 1), "%"),
       x = expression(paste("Ground Heat Flux (W ", m^-2, ")")),
       y = expression(paste("CO"[2], " Flux (μmol ", m^-2, s^-1, ")"))) +
  theme_bw(base_size = 12) +
  theme(legend.position = c(0.15, 0.85),
        legend.background = element_rect(fill = "white", color = "black"),
        panel.grid.minor = element_blank())

print(p_FC_G)

# Save (commented out)
# ggsave("FC_vs_G.png", p_FC_G, width = 10, height = 7, dpi = 300)
# ggsave("FC_vs_G.pdf", p_FC_G, width = 10, height = 7)
cat("✓ Plot created (not saved yet)\n")

# ==============================================================================
# SECTION 6: ANALYSIS 3 - FC ~ H (CO2 vs Sensible Heat Flux)
# ==============================================================================
#
# ECOLOGICAL QUESTION:
# How does energy flux affect carbon flux?
#
# ==============================================================================

cat("\n=== ANALYZING FC ~ H (CO2 vs Sensible Heat Flux) ===\n\n")

# Prepare data
df_FC_H <- df_FC %>% filter(!is.na(FC), !is.na(H))

# Fit GAMM
m_FC_H <- gamm(FC ~ s(H, k = 6),
               data = df_FC_H,
               correlation = corAR1(form = ~ time_index),
               method = "REML")

print(summary(m_FC_H$gam))
cat("Deviance explained:", round(summary(m_FC_H$gam)$dev.expl * 100, 1), "%\n\n")

# Predictions
pred_data_FC_H <- data.frame(
  H = seq(min(df_FC_H$H, na.rm = TRUE),
          max(df_FC_H$H, na.rm = TRUE),
          length.out = 200)
)

pred_FC_H <- predict(m_FC_H$gam, newdata = pred_data_FC_H, se.fit = TRUE)

pred_data_FC_H <- pred_data_FC_H %>%
  mutate(fit = pred_FC_H$fit,
         lower = fit - 1.96 * pred_FC_H$se.fit,
         upper = fit + 1.96 * pred_FC_H$se.fit)

# Plot
p_FC_H <- ggplot() +
  geom_ribbon(data = pred_data_FC_H,
              aes(x = H, ymin = lower, ymax = upper),
              alpha = 0.3, fill = "darkgreen") +
  geom_line(data = pred_data_FC_H,
            aes(x = H, y = fit),
            color = "darkgreen", size = 1.2) +
  geom_point(data = df_FC_H,
             aes(x = H, y = FC, color = year_factor),
             size = 2.5, alpha = 0.7) +
  scale_color_viridis_d(name = "Year") +
  labs(title = "CO₂ Flux vs Sensible Heat Flux",
       subtitle = paste0("GAMM with AR(1) | Dev. expl: ",
                        round(summary(m_FC_H$gam)$dev.expl * 100, 1), "%"),
       x = expression(paste("Sensible Heat Flux (W ", m^-2, ")")),
       y = expression(paste("CO"[2], " Flux (μmol ", m^-2, s^-1, ")"))) +
  theme_bw(base_size = 12) +
  theme(legend.position = c(0.85, 0.85),
        legend.background = element_rect(fill = "white", color = "black"),
        panel.grid.minor = element_blank())

print(p_FC_H)

# Save (commented out)
# ggsave("FC_vs_H.png", p_FC_H, width = 10, height = 7, dpi = 300)
# ggsave("FC_vs_H.pdf", p_FC_H, width = 10, height = 7)
cat("✓ Plot created (not saved yet)\n")

# ==============================================================================
# SECTION 7: ANALYSIS 4 - FCH4 ~ SWC (CH4 vs Soil Moisture) - THE W-SHAPE!
# ==============================================================================
#
# ECOLOGICAL QUESTION:
# How does soil moisture affect CH4 flux?
# This is the most complex relationship - expect multiple thresholds!
#
# CH4 production (methanogenesis) requires:
#   - Anoxic conditions (high moisture)
#   - Available substrate
#   - Optimal temperature
#
# CH4 oxidation (methanotrophy) requires:
#   - Oxygen availability
#   - Active methanotroph community
#
# The balance creates complex moisture responses
#
# ==============================================================================

cat("\n=== ANALYZING FCH4 ~ SWC_3_1_1 (CH4 vs Soil Moisture) ===\n\n")

# Prepare data
df_FCH4_SWC <- df_FCH4 %>% filter(!is.na(FCH4), !is.na(SWC_3_1_1))

# ------------------------------------------------------------------------------
# Test different k values for the W-shaped relationship
# ------------------------------------------------------------------------------
# W-shapes are complex and may need higher k
# k = maximum "wiggliness" allowed (actual smoothness is data-driven)

cat("Testing different basis dimensions (k) for W-shape:\n")
cat("(Higher k allows more complex curves)\n\n")

# k = 6 (standard)
m_FCH4_k6 <- gamm(FCH4 ~ s(SWC_3_1_1, k = 6),
                  data = df_FCH4_SWC,
                  correlation = corAR1(form = ~ time_index))
cat("k=6: Dev.expl =", round(summary(m_FCH4_k6$gam)$dev.expl * 100, 1), 
    "%, AIC =", round(AIC(m_FCH4_k6$lme), 1), "\n")

# k = 8 (more flexible)
m_FCH4_k8 <- gamm(FCH4 ~ s(SWC_3_1_1, k = 8),
                  data = df_FCH4_SWC,
                  correlation = corAR1(form = ~ time_index))
cat("k=8: Dev.expl =", round(summary(m_FCH4_k8$gam)$dev.expl * 100, 1),
    "%, AIC =", round(AIC(m_FCH4_k8$lme), 1), "\n")

# k = 10 (very flexible)
m_FCH4_k10 <- gamm(FCH4 ~ s(SWC_3_1_1, k = 10),
                   data = df_FCH4_SWC,
                   correlation = corAR1(form = ~ time_index))
cat("k=10: Dev.expl =", round(summary(m_FCH4_k10$gam)$dev.expl * 100, 1),
    "%, AIC =", round(AIC(m_FCH4_k10$lme), 1), "\n\n")

# Choose k=8 as good balance (usually best AIC)
m_FCH4_SWC <- m_FCH4_k8
cat("Using k=8 model for final analysis\n\n")

print(summary(m_FCH4_SWC$gam))
cat("Deviance explained:", round(summary(m_FCH4_SWC$gam)$dev.expl * 100, 1), "%\n\n")

# Check if k is adequate
cat("Checking if k=8 is sufficient:\n")
cat("(If k-index < 1 or p < 0.05, increase k)\n")
gam.check(m_FCH4_SWC$gam)

# Predictions
pred_data_FCH4_SWC <- data.frame(
  SWC_3_1_1 = seq(min(df_FCH4_SWC$SWC_3_1_1, na.rm = TRUE),
                  max(df_FCH4_SWC$SWC_3_1_1, na.rm = TRUE),
                  length.out = 200)
)

pred_FCH4_SWC <- predict(m_FCH4_SWC$gam, 
                         newdata = pred_data_FCH4_SWC, 
                         se.fit = TRUE)

pred_data_FCH4_SWC <- pred_data_FCH4_SWC %>%
  mutate(fit = pred_FCH4_SWC$fit,
         lower = fit - 1.96 * pred_FCH4_SWC$se.fit,
         upper = fit + 1.96 * pred_FCH4_SWC$se.fit)
```


#Piecewise vs GAMM comparison for FC ~ G - for when G is <0 and > 0 

```{r}
# Create threshold variable
df_monthly_FC <- df_monthly_FC %>%
  mutate(G_phase = ifelse(G_1_1_1 < 0, "Cooling", "Warming"))

# Piecewise linear model
m_piecewise_G <- lm(FC ~ G_1_1_1 * G_phase, data = df_monthly_FC)
summary(m_piecewise_G)

# Compare with GAM
AIC(m_piecewise_G, m_FC_G$lme)
```
#Picewise vs GAMM for FC ~ H (inflection point seems to be ~ 40)
```{r}
# Threshold at H = 40
df_monthly_FC <- df_monthly_FC %>%
  mutate(H_regime = ifelse(H < 40, "Optimal", "Stress"))

# Piecewise model
m_piecewise_H <- lm(FC ~ H * H_regime, data = df_monthly_FC)

# Or quadratic
m_quad_H <- lm(FC ~ H + I(H^2), data = df_monthly_FC)

# Compare all three
AIC(m_piecewise_H, m_quad_H, m_FC_H$lme)
```
#rechecking relationships 

```{r}
################################################################################
# QUICK DIAGNOSTIC FUNCTION: Check all relationships for non-linearity
################################################################################

library(tidyverse)
library(gridExtra)

# Function to quickly plot and assess relationship patterns
quick_diagnostic_plots <- function(data, flux_var, flux_label) {
  
  # Get all potential predictor variables (exclude date/time columns)
  met_vars <- data %>%
    select(-any_of(c("date", "year", "month", "season", "DOY", 
                     "FC", "FCH4", "time_index", "year_factor"))) %>%
    select(where(is.numeric)) %>%
    names()
  
  # Create plots for each relationship
  plot_list <- list()
  
  for(var in met_vars) {
    
    # Skip if too many missing values
    if(sum(!is.na(data[[var]]) & !is.na(data[[flux_var]])) < 10) {
      next
    }
    
    # Create scatter plot with loess smooth
    p <- ggplot(data, aes_string(x = var, y = flux_var)) +
      geom_point(alpha = 0.6, size = 2) +
      geom_smooth(method = "loess", se = TRUE, color = "blue", size = 1) +
      geom_smooth(method = "lm", se = FALSE, color = "red", 
                  linetype = "dashed", size = 0.8) +
      labs(title = paste(flux_label, "~", var),
           x = var,
           y = flux_label) +
      theme_minimal(base_size = 10) +
      theme(plot.title = element_text(size = 9, face = "bold"))
    
    plot_list[[var]] <- p
  }
  
  # Arrange in grid
  n_plots <- length(plot_list)
  n_cols <- 3
  n_rows <- ceiling(n_plots / n_cols)
  
  # Print in batches if too many
  if(n_plots > 12) {
    cat("\n=== TOO MANY PLOTS - Showing in batches ===\n")
    
    batch_size <- 12
    n_batches <- ceiling(n_plots / batch_size)
    
    for(i in 1:n_batches) {
      start_idx <- (i-1) * batch_size + 1
      end_idx <- min(i * batch_size, n_plots)
      
      cat("\nBatch", i, "of", n_batches, 
          "(plots", start_idx, "to", end_idx, ")\n")
      
      batch_plots <- plot_list[start_idx:end_idx]
      grid.arrange(grobs = batch_plots, ncol = n_cols)
      
      if(i < n_batches) {
        cat("\nPress Enter for next batch...")
        readline()
      }
    }
  } else {
    grid.arrange(grobs = plot_list, ncol = n_cols)
  }
  
  # Return summary of potential non-linear relationships
  cat("\n=== VISUAL ASSESSMENT GUIDE ===\n")
  cat("Blue line (loess) = flexible smooth that follows data\n")
  cat("Red dashed line = linear fit\n\n")
  cat("LOOK FOR:\n")
  cat("1. Blue line clearly curved while red is straight → NON-LINEAR\n")
  cat("2. U-shape or inverted U → THRESHOLD/OPTIMUM\n")
  cat("3. Blue line flat → NO RELATIONSHIP\n")
  cat("4. Blue and red lines similar → LINEAR is fine\n\n")
  
  return(invisible(plot_list))
}

################################################################################
# AUTOMATED NON-LINEARITY DETECTION (FIXED)
################################################################################

detect_nonlinearity <- function(data, flux_var, met_var) {
  
  # Remove missing values
  clean_data <- data %>%
    filter(!is.na(.data[[flux_var]]), !is.na(.data[[met_var]]))
  
  if(nrow(clean_data) < 10) return(NULL)
  
  # Fit linear model
  m_linear <- lm(as.formula(paste(flux_var, "~", met_var)), data = clean_data)
  
  # Fit quadratic model (FIXED - use I() instead of poly())
  quad_formula <- paste(flux_var, "~", met_var, "+ I(", met_var, "^2)")
  m_quad <- lm(as.formula(quad_formula), data = clean_data)
  
  # Compare with likelihood ratio test
  lr_test <- anova(m_linear, m_quad)
  
  # Calculate correlation (for monotonicity check)
  cor_val <- cor(clean_data[[flux_var]], clean_data[[met_var]], 
                 use = "complete.obs")
  
  # Return results
  data.frame(
    flux = flux_var,
    predictor = met_var,
    n = nrow(clean_data),
    linear_R2 = summary(m_linear)$r.squared,
    quad_R2 = summary(m_quad)$r.squared,
    R2_improvement = summary(m_quad)$r.squared - summary(m_linear)$r.squared,
    quad_pvalue = lr_test$`Pr(>F)`[2],
    correlation = cor_val,
    nonlinear_evidence = ifelse(lr_test$`Pr(>F)`[2] < 0.05, 
                                "YES - Quadratic better", 
                                "No - Linear adequate"),
    stringsAsFactors = FALSE
  )
}

################################################################################
# RUN DIAGNOSTICS
################################################################################

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("DIAGNOSTIC PLOTS FOR CO2 FLUX (FC)\n")
cat(paste(rep("=", 80), collapse=""), "\n")

fc_plots <- quick_diagnostic_plots(df_monthly_FC, "FC", "CO₂ Flux")

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("DIAGNOSTIC PLOTS FOR CH4 FLUX (FCH4)\n")
cat(paste(rep("=", 80), collapse=""), "\n")

fch4_plots <- quick_diagnostic_plots(df_monthly_FCH4, "FCH4", "CH₄ Flux")

# Test all FC relationships
cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("AUTOMATED NON-LINEARITY DETECTION - CO2 FLUX\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

met_vars <- df_monthly_FC %>%
  select(-any_of(c("date", "year", "month", "season", "DOY", 
                   "FC", "FCH4", "time_index", "year_factor"))) %>%
  select(where(is.numeric)) %>%
  names()

# Use map_df with error handling
fc_nonlinearity <- map_df(met_vars, function(var) {
  result <- tryCatch(
    detect_nonlinearity(df_monthly_FC, "FC", var),
    error = function(e) {
      cat("Skipping", var, "- Error:", e$message, "\n")
      return(NULL)
    }
  )
  return(result)
})

fc_nonlinearity <- fc_nonlinearity %>%
  arrange(desc(R2_improvement)) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

print(fc_nonlinearity, n = 30)

# Test all FCH4 relationships
cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("AUTOMATED NON-LINEARITY DETECTION - CH4 FLUX\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

met_vars_ch4 <- df_monthly_FCH4 %>%
  select(-any_of(c("date", "year", "month", "season", "DOY", 
                   "FC", "FCH4", "time_index", "year_factor"))) %>%
  select(where(is.numeric)) %>%
  names()

# Use map_df with error handling
fch4_nonlinearity <- map_df(met_vars_ch4, function(var) {
  result <- tryCatch(
    detect_nonlinearity(df_monthly_FCH4, "FCH4", var),
    error = function(e) {
      cat("Skipping", var, "- Error:", e$message, "\n")
      return(NULL)
    }
  )
  return(result)
})

fch4_nonlinearity <- fch4_nonlinearity %>%
  arrange(desc(R2_improvement)) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

print(fch4_nonlinearity, n = 30)

################################################################################
# SUMMARY RECOMMENDATIONS
################################################################################

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("SUMMARY: WHICH RELATIONSHIPS NEED RE-ANALYSIS?\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

# FC relationships to re-examine
fc_reexamine <- fc_nonlinearity %>%
  filter(quad_pvalue < 0.05 | R2_improvement > 0.05)

if(nrow(fc_reexamine) > 0) {
  cat("CO2 FLUX - Consider GAM/piecewise for these:\n")
  print(fc_reexamine %>% select(predictor, linear_R2, quad_R2, 
                                R2_improvement, nonlinear_evidence))
  cat("\n")
} else {
  cat("CO2 FLUX - All relationships appear adequately linear\n\n")
}

# FCH4 relationships to re-examine
fch4_reexamine <- fch4_nonlinearity %>%
  filter(quad_pvalue < 0.05 | R2_improvement > 0.05)

if(nrow(fch4_reexamine) > 0) {
  cat("CH4 FLUX - Consider GAM/piecewise for these:\n")
  print(fch4_reexamine %>% select(predictor, linear_R2, quad_R2, 
                                  R2_improvement, nonlinear_evidence))
  cat("\n")
} else {
  cat("CH4 FLUX - All relationships appear adequately linear\n\n")
}

cat("\nRECOMMENDATIONS:\n")
cat("1. Visually inspect all plots above\n")
cat("2. For relationships with 'YES - Quadratic better':\n")
cat("   → Test GAM or piecewise models\n")
cat("   → Compare AIC with your previous linear/GLS models\n")
cat("3. For relationships with R² improvement > 0.10:\n")
cat("   → Strong evidence for non-linearity\n")
cat("   → Definitely re-analyze\n")
cat("4. For borderline cases (0.05 < improvement < 0.10):\n")
cat("   → Look at visual plot to decide\n\n")



```



#checking linearity 
```{r}
################################################################################
# AUTOMATED NON-LINEARITY DETECTION (with linear p-value added)
################################################################################

detect_nonlinearity <- function(data, flux_var, met_var) {
  
  # Remove missing values
  clean_data <- data %>%
    filter(!is.na(.data[[flux_var]]), !is.na(.data[[met_var]]))
  
  if(nrow(clean_data) < 10) return(NULL)
  
  # Fit linear model
  m_linear <- lm(as.formula(paste(flux_var, "~", met_var)), data = clean_data)
  linear_summary <- summary(m_linear)
  
  # Fit quadratic model
  quad_formula <- paste(flux_var, "~", met_var, "+ I(", met_var, "^2)")
  m_quad <- lm(as.formula(quad_formula), data = clean_data)
  
  # Compare with likelihood ratio test
  lr_test <- anova(m_linear, m_quad)
  
  # Calculate correlation (for monotonicity check)
  cor_val <- cor(clean_data[[flux_var]], clean_data[[met_var]], 
                 use = "complete.obs")
  
  # Get linear p-value (from F-statistic)
  linear_pval <- pf(linear_summary$fstatistic[1], 
                    linear_summary$fstatistic[2], 
                    linear_summary$fstatistic[3], 
                    lower.tail = FALSE)
  
  # Return results
  data.frame(
    flux = flux_var,
    predictor = met_var,
    n = nrow(clean_data),
    linear_R2 = linear_summary$r.squared,
    linear_pvalue = linear_pval,
    quad_R2 = summary(m_quad)$r.squared,
    quad_pvalue = lr_test$`Pr(>F)`[2],
    R2_improvement = summary(m_quad)$r.squared - linear_summary$r.squared,
    correlation = cor_val,
    linear_sig = ifelse(linear_pval < 0.05, "Significant", "Not significant"),
    nonlinear_evidence = ifelse(lr_test$`Pr(>F)`[2] < 0.05, 
                                "YES - Quadratic better", 
                                "No - Linear adequate"),
    stringsAsFactors = FALSE
  )
}

################################################################################
# RUN DIAGNOSTICS
################################################################################

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("DIAGNOSTIC PLOTS FOR CO2 FLUX (FC)\n")
cat(paste(rep("=", 80), collapse=""), "\n")

fc_plots <- quick_diagnostic_plots(df_monthly_FC, "FC", "CO₂ Flux")

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("DIAGNOSTIC PLOTS FOR CH4 FLUX (FCH4)\n")
cat(paste(rep("=", 80), collapse=""), "\n")

fch4_plots <- quick_diagnostic_plots(df_monthly_FCH4, "FCH4", "CH₄ Flux")

# Test all FC relationships
cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("AUTOMATED NON-LINEARITY DETECTION - CO2 FLUX\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

met_vars <- df_monthly_FC %>%
  select(-any_of(c("date", "year", "month", "season", "DOY", 
                   "FC", "FCH4", "time_index", "year_factor"))) %>%
  select(where(is.numeric)) %>%
  names()

# Use map_df with error handling
fc_nonlinearity <- map_df(met_vars, function(var) {
  result <- tryCatch(
    detect_nonlinearity(df_monthly_FC, "FC", var),
    error = function(e) {
      cat("Skipping", var, "- Error:", e$message, "\n")
      return(NULL)
    }
  )
  return(result)
})

fc_nonlinearity <- fc_nonlinearity %>%
  arrange(desc(R2_improvement)) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

print(fc_nonlinearity, n = 30)

# Test all FCH4 relationships
cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("AUTOMATED NON-LINEARITY DETECTION - CH4 FLUX\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

met_vars_ch4 <- df_monthly_FCH4 %>%
  select(-any_of(c("date", "year", "month", "season", "DOY", 
                   "FC", "FCH4", "time_index", "year_factor"))) %>%
  select(where(is.numeric)) %>%
  names()

# Use map_df with error handling
fch4_nonlinearity <- map_df(met_vars_ch4, function(var) {
  result <- tryCatch(
    detect_nonlinearity(df_monthly_FCH4, "FCH4", var),
    error = function(e) {
      cat("Skipping", var, "- Error:", e$message, "\n")
      return(NULL)
    }
  )
  return(result)
})

fch4_nonlinearity <- fch4_nonlinearity %>%
  arrange(desc(R2_improvement)) %>%
  mutate(across(where(is.numeric), ~round(., 4)))

print(fch4_nonlinearity, n = 30)

################################################################################
# ENHANCED SUMMARY RECOMMENDATIONS
################################################################################

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("SUMMARY: WHICH RELATIONSHIPS NEED RE-ANALYSIS?\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

# FC relationships - categorize by significance and linearity
cat("CO2 FLUX RELATIONSHIPS:\n")
cat("=" , paste(rep("-", 78), collapse=""), "\n\n")

# Category 1: Significant linear relationships
fc_linear_ok <- fc_nonlinearity %>%
  filter(linear_pvalue < 0.05, quad_pvalue >= 0.05)

if(nrow(fc_linear_ok) > 0) {
  cat("✓ LINEAR MODEL IS ADEQUATE (significant linear, no benefit from quadratic):\n")
  print(fc_linear_ok %>% 
          select(predictor, linear_R2, linear_pvalue, correlation) %>%
          arrange(desc(linear_R2)))
  cat("\n")
}

# Category 2: Significant AND non-linear
fc_nonlinear <- fc_nonlinearity %>%
  filter(linear_pvalue < 0.05, quad_pvalue < 0.05)

if(nrow(fc_nonlinear) > 0) {
  cat("⚠ NON-LINEAR - Use GAM or piecewise (significant but quadratic better):\n")
  print(fc_nonlinear %>% 
          select(predictor, linear_R2, quad_R2, R2_improvement, quad_pvalue) %>%
          arrange(desc(R2_improvement)))
  cat("\n")
}

# Category 3: Not significant at all
fc_not_sig <- fc_nonlinearity %>%
  filter(linear_pvalue >= 0.05)

if(nrow(fc_not_sig) > 0) {
  cat("✗ NOT SIGNIFICANT (no relationship detected):\n")
  print(fc_not_sig %>% 
          select(predictor, linear_R2, linear_pvalue) %>%
          arrange(linear_pvalue))
  cat("\n")
}

# Same for FCH4
cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("CH4 FLUX RELATIONSHIPS:\n")
cat("=" , paste(rep("-", 78), collapse=""), "\n\n")

# Category 1: Significant linear relationships
fch4_linear_ok <- fch4_nonlinearity %>%
  filter(linear_pvalue < 0.05, quad_pvalue >= 0.05)

if(nrow(fch4_linear_ok) > 0) {
  cat("✓ LINEAR MODEL IS ADEQUATE (significant linear, no benefit from quadratic):\n")
  print(fch4_linear_ok %>% 
          select(predictor, linear_R2, linear_pvalue, correlation) %>%
          arrange(desc(linear_R2)))
  cat("\n")
}

# Category 2: Significant AND non-linear
fch4_nonlinear <- fch4_nonlinearity %>%
  filter(linear_pvalue < 0.05, quad_pvalue < 0.05)

if(nrow(fch4_nonlinear) > 0) {
  cat("⚠ NON-LINEAR - Use GAM or piecewise (significant but quadratic better):\n")
  print(fch4_nonlinear %>% 
          select(predictor, linear_R2, quad_R2, R2_improvement, quad_pvalue) %>%
          arrange(desc(R2_improvement)))
  cat("\n")
}

# Category 3: Not significant at all
fch4_not_sig <- fch4_nonlinearity %>%
  filter(linear_pvalue >= 0.05)

if(nrow(fch4_not_sig) > 0) {
  cat("✗ NOT SIGNIFICANT (no relationship detected):\n")
  print(fch4_not_sig %>% 
          select(predictor, linear_R2, linear_pvalue) %>%
          arrange(linear_pvalue))
  cat("\n")
}

################################################################################
# ACTION ITEMS
################################################################################

cat("\n" , paste(rep("=", 80), collapse=""), "\n")
cat("ACTION ITEMS:\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

# Count relationships in each category
n_fc_linear <- nrow(fc_linear_ok)
n_fc_nonlinear <- nrow(fc_nonlinear)
n_fc_notsig <- nrow(fc_not_sig)

n_fch4_linear <- nrow(fch4_linear_ok)
n_fch4_nonlinear <- nrow(fch4_nonlinear)
n_fch4_notsig <- nrow(fch4_not_sig)

cat("CO2 FLUX:\n")
cat("  -", n_fc_linear, "relationships: Keep linear/GLS ✓\n")
cat("  -", n_fc_nonlinear, "relationships: Re-analyze with GAM/piecewise ⚠\n")
cat("  -", n_fc_notsig, "relationships: Not significant (don't report) ✗\n\n")

cat("CH4 FLUX:\n")
cat("  -", n_fch4_linear, "relationships: Keep linear/GLS ✓\n")
cat("  -", n_fch4_nonlinear, "relationships: Re-analyze with GAM/piecewise ⚠\n")
cat("  -", n_fch4_notsig, "relationships: Not significant (don't report) ✗\n\n")

cat("PRIORITY:\n")
cat("1. For NON-LINEAR relationships with R² improvement > 0.10:\n")
cat("   → DEFINITELY re-analyze (strong evidence)\n")
cat("2. For NON-LINEAR relationships with 0.05 < R² improvement < 0.10:\n")
cat("   → Check visual plot, probably re-analyze\n")
cat("3. For LINEAR relationships:\n")
cat("   → Your previous GLS/Kendall analyses are fine!\n")
cat("4. For NOT SIGNIFICANT relationships:\n")
cat("   → Don't report (or report as 'no significant relationship')\n\n")
```

#Comprehensive diagnostics for model selection
Linear assumptions met + No autocorr → Linear regression
Linear assumptions met + Autocorr    → GLS with AR(1)
Non-linear + No autocorr             → GAM
Non-linear + Autocorr                → GAMM with AR(1)
Threshold evident                     → Piecewise regression

```{r}
################################################################################
# USAGE - CORRECTED TO TEST ALL RELEVANT VARIABLES
################################################################################

# Check what variables are in your data
cat("All variables in df_monthly_FC:\n")
print(names(df_monthly_FC))
cat("\n")

# Get met variables - EXCLUDE flux variables and non-predictors
met_vars_fc <- df_monthly_FC %>%
  select(-any_of(c("date", "year", "month", "season", "DOY", 
                   "FC", "FCH4", "time_index", "year_factor",
                   "n_days", "n"))) %>%  # Exclude day counts!
  select(where(is.numeric)) %>%
  names()

cat("Meteorological variables to test:\n")
print(met_vars_fc)
cat("\nTotal:", length(met_vars_fc), "variables\n\n")

# Let user confirm before running
cat("These are the variables that will be tested.\n")
cat("If this list looks correct, press Enter to begin.\n")
cat("If not, stop here (Ctrl+C) and we'll adjust the exclusion list.\n")
readline()

################################################################################
# RUN DIAGNOSTICS
################################################################################

cat("\n\nCOMPREHENSIVE DIAGNOSTICS FOR CO2 FLUX\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

# Run on ALL met variables (not just first 3)
fc_diagnostics <- run_all_diagnostics(df_monthly_FC, "FC", met_vars_fc)

# View and save summary
cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
cat("FINAL SUMMARY TABLE\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

print(fc_diagnostics$summary)

# Save summary
write_csv(fc_diagnostics$summary, "model_diagnostics_summary_FC.csv")
cat("\n✓ Summary saved to: model_diagnostics_summary_FC.csv\n")

################################################################################
# CATEGORIZE RESULTS BY RECOMMENDATION
################################################################################

cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
cat("RESULTS BY MODEL TYPE\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

summary_df <- fc_diagnostics$summary

# Significant relationships only
sig_relationships <- summary_df %>%
  filter(linear_p < 0.05)

if(nrow(sig_relationships) > 0) {
  
  # Linear models (no autocorr, no nonlinearity)
  linear_models <- sig_relationships %>%
    filter(best_model == "linear")
  
  if(nrow(linear_models) > 0) {
    cat("✓ USE LINEAR REGRESSION (", nrow(linear_models), " relationships):\n", sep="")
    print(linear_models %>% select(predictor, R2, best_AIC))
    cat("\n")
  }
  
  # GLS models (autocorr, but linear)
  gls_models <- sig_relationships %>%
    filter(best_model == "gls")
  
  if(nrow(gls_models) > 0) {
    cat("⚠ USE GLS WITH AR(1) (", nrow(gls_models), " relationships):\n", sep="")
    print(gls_models %>% select(predictor, R2, autocorr_p, best_AIC))
    cat("\n")
  }
  
  # GAM models (nonlinear, no autocorr)
  gam_models <- sig_relationships %>%
    filter(best_model == "gam")
  
  if(nrow(gam_models) > 0) {
    cat("⚠ USE GAM (", nrow(gam_models), " relationships):\n", sep="")
    print(gam_models %>% select(predictor, R2, nonlin_p, best_AIC))
    cat("\n")
  }
  
  # GAMM models (nonlinear + autocorr)
  gamm_models <- sig_relationships %>%
    filter(best_model == "gamm")
  
  if(nrow(gamm_models) > 0) {
    cat("⚠ USE GAMM WITH AR(1) (", nrow(gamm_models), " relationships):\n", sep="")
    print(gamm_models %>% select(predictor, R2, nonlin_p, autocorr_p, best_AIC))
    cat("\n")
  }
  
  # Piecewise models
  piecewise_models <- sig_relationships %>%
    filter(best_model == "piecewise")
  
  if(nrow(piecewise_models) > 0) {
    cat("⚠ USE PIECEWISE (", nrow(piecewise_models), " relationships):\n", sep="")
    print(piecewise_models %>% select(predictor, R2, best_AIC))
    cat("\n")
  }
  
} else {
  cat("No significant relationships found!\n")
}

# Not significant
not_sig <- summary_df %>%
  filter(linear_p >= 0.05)

if(nrow(not_sig) > 0) {
  cat("✗ NOT SIGNIFICANT - Don't report (", nrow(not_sig), " relationships):\n", sep="")
  print(not_sig %>% select(predictor, R2, linear_p))
  cat("\n")
}

################################################################################
# OPTIONAL: Run same analysis for FCH4
################################################################################

cat("\n\nWould you like to run the same analysis for CH4 flux (FCH4)? (y/n): ")
run_ch4 <- readline()

if(tolower(run_ch4) == "y") {
  
  cat("\n\nCOMPREHENSIVE DIAGNOSTICS FOR CH4 FLUX\n")
  cat(paste(rep("=", 80), collapse=""), "\n\n")
  
  # Get met variables for FCH4 data
  met_vars_fch4 <- df_monthly_FCH4 %>%
    select(-any_of(c("date", "year", "month", "season", "DOY", 
                     "FC", "FCH4", "time_index", "year_factor",
                     "n_days", "n"))) %>%
    select(where(is.numeric)) %>%
    names()
  
  cat("Testing", length(met_vars_fch4), "variables for FCH4\n\n")
  
  # Run diagnostics
  fch4_diagnostics <- run_all_diagnostics(df_monthly_FCH4, "FCH4", met_vars_fch4)
  
  # Save summary
  write_csv(fch4_diagnostics$summary, "model_diagnostics_summary_FCH4.csv")
  cat("\n✓ Summary saved to: model_diagnostics_summary_FCH4.csv\n")
  
  # Categorize results
  cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
  cat("CH4 FLUX RESULTS BY MODEL TYPE\n")
  cat(paste(rep("=", 80), collapse=""), "\n\n")
  
  summary_df_ch4 <- fch4_diagnostics$summary
  
  sig_relationships_ch4 <- summary_df_ch4 %>%
    filter(linear_p < 0.05)
  
  if(nrow(sig_relationships_ch4) > 0) {
    cat("Significant relationships found:\n")
    print(sig_relationships_ch4 %>% 
            select(predictor, R2, best_model, best_AIC) %>%
            arrange(desc(R2)))
  } else {
    cat("No significant relationships found for FCH4\n")
  }
}

################################################################################
# CREATE COMPARISON WITH YOUR PREVIOUS ANALYSES
################################################################################

cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
cat("COMPARISON: Which relationships need re-analysis?\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

cat("Based on these diagnostics, you should:\n\n")

cat("1. KEEP your previous linear/GLS analysis for:\n")
keep_list <- summary_df %>%
  filter(best_model %in% c("linear", "gls"), linear_p < 0.05)
if(nrow(keep_list) > 0) {
  print(keep_list$predictor)
} else {
  cat("   (none)\n")
}

cat("\n2. RE-ANALYZE with GAM/GAMM/Piecewise for:\n")
reanalyze_list <- summary_df %>%
  filter(best_model %in% c("gam", "gamm", "piecewise"), linear_p < 0.05)
if(nrow(reanalyze_list) > 0) {
  print(reanalyze_list %>% select(predictor, best_model, R2))
} else {
  cat("   (none)\n")
}

cat("\n3. DROP from analysis (not significant):\n")
drop_list <- summary_df %>%
  filter(linear_p >= 0.05)
if(nrow(drop_list) > 0) {
  print(drop_list$predictor)
} else {
  cat("   (none)\n")
}

cat("\n\nAnalysis complete! Check the CSV files for full results.\n")
```




#Comprehensive tests for model selection by relationship

#FC ~ air temp 
```{r}
################################################################################
# COMPREHENSIVE SINGLE-CHUNK ANALYSIS: FC ~ PREDICTOR
# 
# This chunk:
# 1. Tests assumptions on LINEAR model residuals
# 2. Follows decision tree based on violations
# 3. Fits appropriate candidate models
# 4. Selects best model via AIC/BIC
# 5. Creates summary table + annotated figure
################################################################################

library(tidyverse)
library(lmtest)
library(nlme)
library(mgcv)
library(gridExtra)

# ==============================================================================
# USER INPUT: Change these for each relationship
# ==============================================================================

flux_var <- "FC"
predictor_var <- "TA_gapfilled"
flux_label <- expression(paste("CO"[2], " Flux (μmol ", m^-2, s^-1, ")"))
predictor_label <- "Air Temperature (°C)"

# ==============================================================================
# STEP 0: Prepare Data
# ==============================================================================

analysis_data <- df_monthly_FC %>%
  filter(!is.na(.data[[flux_var]]), !is.na(.data[[predictor_var]])) %>%
  arrange(year, month) %>%
  mutate(time_index = row_number())

n_obs <- nrow(analysis_data)

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("ANALYZING:", flux_var, "~", predictor_var, "\n")
cat("Sample size:", n_obs, "observations\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

# ==============================================================================
# STEP 1: Fit Baseline Linear Model and Test Assumptions
# ==============================================================================

cat("STEP 1: TESTING LINEAR MODEL ASSUMPTIONS\n")
cat(paste(rep("-", 80), collapse=""), "\n\n")

# Fit linear model
formula_linear <- as.formula(paste(flux_var, "~", predictor_var))
m_baseline <- lm(formula_linear, data = analysis_data)

# --- 1a. Normality Test ---
shapiro_test <- shapiro.test(residuals(m_baseline))
normality_ok <- shapiro_test$p.value >= 0.05

cat("1. NORMALITY (Shapiro-Wilk on residuals):\n")
cat("   W =", round(shapiro_test$statistic, 4), 
    ", p =", round(shapiro_test$p.value, 4))
cat(ifelse(normality_ok, " ✅ OK\n", " ❌ VIOLATED\n"))

# --- 1b. Homoscedasticity Test ---
bp_test <- bptest(m_baseline)
homoscedasticity_ok <- bp_test$p.value >= 0.05

cat("2. HOMOSCEDASTICITY (Breusch-Pagan on residuals):\n")
cat("   BP =", round(bp_test$statistic, 4), 
    ", p =", round(bp_test$p.value, 4))
cat(ifelse(homoscedasticity_ok, " ✅ OK\n", " ❌ VIOLATED\n"))

# --- 1c. Autocorrelation Tests ---
dw_test <- dwtest(m_baseline)
lb_test <- Box.test(residuals(m_baseline), lag = min(10, n_obs - 5), 
                    type = "Ljung-Box")
autocorr_detected <- (dw_test$p.value < 0.05 | lb_test$p.value < 0.05)

cat("3. AUTOCORRELATION (on residuals):\n")
cat("   Durbin-Watson: DW =", round(dw_test$statistic, 3), 
    ", p =", round(dw_test$p.value, 4))
cat(ifelse(dw_test$p.value < 0.05, " ⚠️\n", " ✅\n"))
cat("   Ljung-Box: X² =", round(lb_test$statistic, 3), 
    ", p =", round(lb_test$p.value, 4))
cat(ifelse(lb_test$p.value < 0.05, " ⚠️\n", " ✅\n"))
cat("   Overall: ", ifelse(autocorr_detected, 
                          "⚠️  AUTOCORRELATION DETECTED\n", 
                          "✅ NO AUTOCORRELATION\n"))

# Summary
linear_assumptions_met <- normality_ok & homoscedasticity_ok

cat("\n📋 ASSUMPTION SUMMARY:\n")
cat("   Linear assumptions (normality + homoscedasticity):", 
    ifelse(linear_assumptions_met, "✅ MET\n", "❌ NOT MET\n"))
cat("   Autocorrelation:", 
    ifelse(autocorr_detected, "⚠️  PRESENT\n", "✅ ABSENT\n\n"))

# ==============================================================================
# STEP 2: Test for Non-linearity
# ==============================================================================

cat("\nSTEP 2: TESTING FOR NON-LINEARITY\n")
cat(paste(rep("-", 80), collapse=""), "\n\n")

# Quadratic test
formula_quad <- as.formula(paste(flux_var, "~", predictor_var, 
                                "+ I(", predictor_var, "^2)"))
m_quad_test <- lm(formula_quad, data = analysis_data)
quad_anova <- anova(m_baseline, m_quad_test)

is_nonlinear <- !is.na(quad_anova$`Pr(>F)`[2]) && quad_anova$`Pr(>F)`[2] < 0.05

cat("Quadratic test:\n")
cat("   Linear R² =", round(summary(m_baseline)$r.squared, 3), "\n")
cat("   Quadratic R² =", round(summary(m_quad_test)$r.squared, 3), "\n")
cat("   Improvement =", round(summary(m_quad_test)$r.squared - 
                              summary(m_baseline)$r.squared, 3), "\n")
cat("   p-value =", round(quad_anova$`Pr(>F)`[2], 4))
cat(ifelse(is_nonlinear, " ⚠️  NON-LINEAR\n\n", " ✅ LINEAR ADEQUATE\n\n"))

# ==============================================================================
# STEP 3: Decision Tree - Fit Appropriate Models
# ==============================================================================

cat("\nSTEP 3: FITTING CANDIDATE MODELS (based on diagnostics)\n")
cat(paste(rep("-", 80), collapse=""), "\n\n")

# Initialize storage
models <- list()
model_info <- data.frame()

# Path 1: Linear assumptions MET, no autocorr --> Simple linear
# Path 2: Linear assumptions MET, autocorr --> GLS vs Quad+GLS vs GAM vs GAMM vs Piecewise
# Path 3: Linear assumptions NOT MET, no autocorr --> Quad vs GAM vs Piecewise  
# Path 4: Linear assumptions NOT MET, autocorr --> Quad+GLS vs GAMM vs Piecewise+GLS

# --- Always fit baseline linear for comparison ---
cat("→ Linear model (baseline)\n")
models$linear <- m_baseline
model_info <- bind_rows(model_info, data.frame(
  model = "Linear",
  aic = AIC(m_baseline),
  bic = BIC(m_baseline),
  r2 = summary(m_baseline)$r.squared,
  has_autocorr_correction = FALSE
))

# --- BRANCH A: Linear assumptions met ---
if(linear_assumptions_met) {
  
  cat("✓ Linear assumptions met\n")
  
  if(autocorr_detected) {
    cat("⚠️  Autocorrelation detected → Testing GLS with AR(1)\n")
    
    # GLS with AR(1)
    m_gls <- gls(formula_linear, 
                 data = analysis_data,
                 correlation = corAR1(form = ~ time_index),
                 method = "ML")
    
    models$gls_ar1 <- m_gls
    r2_gls <- 1 - sum(residuals(m_gls)^2) / 
      sum((analysis_data[[flux_var]] - mean(analysis_data[[flux_var]]))^2)
    
    model_info <- bind_rows(model_info, data.frame(
      model = "GLS_AR1",
      aic = AIC(m_gls),
      bic = BIC(m_gls),
      r2 = r2_gls,
      has_autocorr_correction = TRUE
    ))
    
    cat("   AIC =", round(AIC(m_gls), 1), "\n\n")
  }
  
} else {
  cat("❌ Linear assumptions NOT met\n")
}

# --- BRANCH B: Test non-linear models if indicated ---
if(is_nonlinear) {
  
  cat("⚠️  Non-linearity detected → Testing non-linear models\n\n")
  
  # Quadratic
  if(!autocorr_detected) {
    cat("→ Quadratic model\n")
    models$quadratic <- m_quad_test
    model_info <- bind_rows(model_info, data.frame(
      model = "Quadratic",
      aic = AIC(m_quad_test),
      bic = BIC(m_quad_test),
      r2 = summary(m_quad_test)$r.squared,
      has_autocorr_correction = FALSE
    ))
    cat("   AIC =", round(AIC(m_quad_test), 1), "\n\n")
  } else {
    cat("→ Quadratic with GLS AR(1)\n")
    m_quad_gls <- gls(formula_quad, 
                      data = analysis_data,
                      correlation = corAR1(form = ~ time_index),
                      method = "ML")
    
    models$quad_gls <- m_quad_gls
    r2_quad_gls <- 1 - sum(residuals(m_quad_gls)^2) / 
      sum((analysis_data[[flux_var]] - mean(analysis_data[[flux_var]]))^2)
    
    model_info <- bind_rows(model_info, data.frame(
      model = "Quad_GLS_AR1",
      aic = AIC(m_quad_gls),
      bic = BIC(m_quad_gls),
      r2 = r2_quad_gls,
      has_autocorr_correction = TRUE
    ))
    cat("   AIC =", round(AIC(m_quad_gls), 1), "\n\n")
  }
  
  # GAM
  if(!autocorr_detected) {
    cat("→ GAM\n")
    formula_gam <- as.formula(paste(flux_var, "~ s(", predictor_var, ", k=6)"))
    m_gam <- gam(formula_gam, data = analysis_data, method = "REML")
    
    models$gam <- m_gam
    model_info <- bind_rows(model_info, data.frame(
      model = "GAM",
      aic = AIC(m_gam),
      bic = BIC(m_gam),
      r2 = summary(m_gam)$r.sq,
      has_autocorr_correction = FALSE
    ))
    cat("   AIC =", round(AIC(m_gam), 1), 
        ", Dev.Expl =", round(summary(m_gam)$dev.expl * 100, 1), "%\n\n")
  } else {
    cat("→ GAMM with AR(1)\n")
    formula_gam <- as.formula(paste(flux_var, "~ s(", predictor_var, ", k=6)"))
    m_gamm <- gamm(formula_gam, 
                   data = analysis_data,
                   correlation = corAR1(form = ~ time_index))
    
    models$gamm <- m_gamm
    model_info <- bind_rows(model_info, data.frame(
      model = "GAMM_AR1",
      aic = AIC(m_gamm$lme),
      bic = BIC(m_gamm$lme),
      r2 = summary(m_gamm$gam)$r.sq,
      has_autocorr_correction = TRUE
    ))
    cat("   AIC =", round(AIC(m_gamm$lme), 1), 
        ", Dev.Expl =", round(summary(m_gamm$gam)$dev.expl * 100, 1), "%\n\n")
  }
}

# --- BRANCH C: Always test piecewise at median ---
cat("→ Piecewise (threshold at median)\n")
threshold <- median(analysis_data[[predictor_var]])
analysis_data$phase <- ifelse(analysis_data[[predictor_var]] < threshold, 
                              "Low", "High")

formula_piecewise <- as.formula(paste(flux_var, "~", predictor_var, "* phase"))

if(!autocorr_detected) {
  m_piecewise <- lm(formula_piecewise, data = analysis_data)
  
  models$piecewise <- m_piecewise
  model_info <- bind_rows(model_info, data.frame(
    model = "Piecewise",
    aic = AIC(m_piecewise),
    bic = BIC(m_piecewise),
    r2 = summary(m_piecewise)$r.squared,
    has_autocorr_correction = FALSE
  ))
  
  interaction_p <- summary(m_piecewise)$coefficients[4, 4]
  cat("   Threshold =", round(threshold, 2), 
      ", Interaction p =", round(interaction_p, 4),
      ", AIC =", round(AIC(m_piecewise), 1), "\n\n")
  
} else {
  m_piecewise_gls <- gls(formula_piecewise, 
                        data = analysis_data,
                        correlation = corAR1(form = ~ time_index),
                        method = "ML")
  
  models$piecewise_gls <- m_piecewise_gls
  r2_pw_gls <- 1 - sum(residuals(m_piecewise_gls)^2) / 
    sum((analysis_data[[flux_var]] - mean(analysis_data[[flux_var]]))^2)
  
  model_info <- bind_rows(model_info, data.frame(
    model = "Piecewise_GLS_AR1",
    aic = AIC(m_piecewise_gls),
    bic = BIC(m_piecewise_gls),
    r2 = r2_pw_gls,
    has_autocorr_correction = TRUE
  ))
  cat("   Threshold =", round(threshold, 2), 
      ", AIC =", round(AIC(m_piecewise_gls), 1), "\n\n")
}

# ==============================================================================
# STEP 4: Model Selection
# ==============================================================================

cat("\nSTEP 4: MODEL COMPARISON & SELECTION\n")
cat(paste(rep("-", 80), collapse=""), "\n\n")

# Add delta values
model_info <- model_info %>%
  mutate(
    delta_aic = aic - min(aic),
    delta_bic = bic - min(bic)
  ) %>%
  arrange(aic)

print(model_info %>% 
        select(model, aic, bic, r2, delta_aic, delta_bic) %>%
        mutate(across(where(is.numeric), ~round(., 3))))

# Select best model
best_model_name <- model_info$model[1]
cat("\n🏆 BEST MODEL:", best_model_name, "\n")
cat("   AIC =", round(model_info$aic[1], 1), 
    ", R² =", round(model_info$r2[1], 3), "\n\n")

# Get best model object
if(best_model_name == "GAMM_AR1") {
  best_model <- models$gamm$gam
  best_model_full <- models$gamm
  model_type <- "GAMM"
} else if(best_model_name == "GAM") {
  best_model <- models$gam
  best_model_full <- models$gam
  model_type <- "GAM"
} else if(best_model_name %in% names(models)) {
  best_model <- models[[tolower(gsub("_", "", best_model_name))]]
  best_model_full <- best_model
  model_type <- best_model_name
} else {
  # Handle GLS cases
  model_key <- tolower(gsub("_ar1", "", gsub("_gls", "", best_model_name)))
  if(paste0(model_key, "_gls") %in% names(models)) {
    best_model <- models[[paste0(model_key, "_gls")]]
  } else if(paste0("gls_", model_key) %in% names(models)) {
    best_model <- models[[paste0("gls_", model_key)]]
  } else {
    best_model <- models[[model_key]]
  }
  best_model_full <- best_model
  model_type <- best_model_name
}

# ==============================================================================
# STEP 5: Create Summary Statistics Table
# ==============================================================================

cat("\nSTEP 5: SUMMARY STATISTICS\n")
cat(paste(rep("-", 80), collapse=""), "\n\n")

# Extract key statistics based on model type
if(model_type %in% c("GAM", "GAMM", "GAMM_AR1")) {
  
  gam_summary <- summary(best_model)
  
  stats_table <- data.frame(
    Response = flux_var,
    Predictor = predictor_var,
    Model = model_type,
    N = n_obs,
    R2 = round(gam_summary$r.sq, 3),
    Dev_Explained_pct = round(gam_summary$dev.expl * 100, 1),
    edf = round(sum(gam_summary$edf), 2),
    F_value = round(gam_summary$s.table[1, 3], 2),
    p_value = ifelse(gam_summary$s.table[1, 4] < 0.001, 
                     "<0.001", 
                     round(gam_summary$s.table[1, 4], 4)),
    AIC = round(model_info$aic[1], 1),
    Autocorr_corrected = model_info$has_autocorr_correction[1]
  )
  
  # Find optimum for GAM/GAMM
  pred_seq <- seq(min(analysis_data[[predictor_var]]), 
                  max(analysis_data[[predictor_var]]), 
                  length.out = 1000)
  pred_vals <- predict(best_model, 
                       newdata = setNames(data.frame(pred_seq), predictor_var))
  optimum_val <- pred_seq[which.min(pred_vals)]
  flux_at_optimum <- min(pred_vals)
  
  stats_table$Optimum <- round(optimum_val, 2)
  stats_table$Flux_at_optimum <- round(flux_at_optimum, 3)
  
} else if(grepl("Piecewise", model_type)) {
  
  if(grepl("GLS", model_type)) {
    pw_summary <- summary(best_model)
    slope_low <- coef(best_model)[2]
    slope_high <- coef(best_model)[2] + coef(best_model)[4]
    inter_p <- "NA (GLS)"
  } else {
    pw_summary <- summary(best_model)
    slope_low <- pw_summary$coefficients[2, 1]
    slope_high <- pw_summary$coefficients[2, 1] + pw_summary$coefficients[4, 1]
    inter_p <- round(pw_summary$coefficients[4, 4], 4)
  }
  
  stats_table <- data.frame(
    Response = flux_var,
    Predictor = predictor_var,
    Model = model_type,
    N = n_obs,
    R2 = round(model_info$r2[1], 3),
    Threshold = round(threshold, 2),
    Slope_below = round(slope_low, 4),
    Slope_above = round(slope_high, 4),
    Interaction_p = inter_p,
    AIC = round(model_info$aic[1], 1),
    Autocorr_corrected = model_info$has_autocorr_correction[1]
  )
  
} else {
  
  # Linear, Quadratic, GLS
  if(grepl("GLS", model_type)) {
    lin_summary <- summary(best_model)
    slope <- coef(best_model)[2]
    intercept <- coef(best_model)[1]
    p_val <- "See summary"
  } else {
    lin_summary <- summary(best_model)
    slope <- lin_summary$coefficients[2, 1]
    intercept <- lin_summary$coefficients[1, 1]
    p_val <- ifelse(lin_summary$coefficients[2, 4] < 0.001,
                    "<0.001",
                    round(lin_summary$coefficients[2, 4], 4))
  }
  
  stats_table <- data.frame(
    Response = flux_var,
    Predictor = predictor_var,
    Model = model_type,
    N = n_obs,
    R2 = round(model_info$r2[1], 3),
    Intercept = round(intercept, 3),
    Slope = round(slope, 4),
    p_value = p_val,
    AIC = round(model_info$aic[1], 1),
    Autocorr_corrected = model_info$has_autocorr_correction[1]
  )
  
  if(grepl("Quad", model_type)) {
    stats_table$Quad_coef <- round(coef(best_model)[3], 5)
  }
}

print(stats_table)

# Save results
# filename <- paste0(flux_var, "_vs_", predictor_var, "_results.csv")
# write_csv(stats_table, filename)
# cat("\n✓ Results saved to:", filename, "\n")

# ==============================================================================
# STEP 6: Create Publication-Quality Figure with Stats
# ==============================================================================

cat("\nSTEP 6: CREATING FIGURE\n")
cat(paste(rep("-", 80), collapse=""), "\n\n")

# Generate predictions
pred_x <- seq(min(analysis_data[[predictor_var]]), 
              max(analysis_data[[predictor_var]]), 
              length.out = 200)

if(model_type %in% c("GAM", "GAMM", "GAMM_AR1")) {
  
  # GAM/GAMM predictions
  pred_obj <- predict(best_model, 
                      newdata = setNames(data.frame(pred_x), predictor_var),
                      se.fit = TRUE)
  
  pred_data <- data.frame(
    x = pred_x,
    fit = pred_obj$fit,
    lower = pred_obj$fit - 1.96 * pred_obj$se.fit,
    upper = pred_obj$fit + 1.96 * pred_obj$se.fit
  )
  
  # Create annotation text
  anno_text <- paste0(
    model_type, "\n",
    "R² = ", round(model_info$r2[1], 3), "\n",
    "Dev.Expl = ", round(stats_table$Dev_Explained_pct, 1), "%\n",
    "p ", stats_table$p_value, "\n",
    "Optimum: ", round(optimum_val, 1), " ", 
    gsub("\\(.*", "", predictor_label)
  )
  
  p <- ggplot() +
    geom_ribbon(data = pred_data,
                aes(x = x, ymin = lower, ymax = upper),
                fill = "darkgreen", alpha = 0.3) +
    geom_line(data = pred_data,
              aes(x = x, y = fit),
              color = "darkgreen", size = 1.5) +
    geom_point(data = analysis_data,
               aes_string(x = predictor_var, y = flux_var, color = "factor(year)"),
               size = 3, alpha = 0.7) +
    geom_vline(xintercept = optimum_val, 
               linetype = "dashed", color = "red", alpha = 0.5) +
    scale_color_viridis_d(name = "Year") +
    annotate("text", x = min(analysis_data[[predictor_var]]), 
             y = max(analysis_data[[flux_var]]),
             label = anno_text, hjust = 0, vjust = 1, size = 4,
             fontface = "bold") +
    labs(title = paste(flux_var, "~", predictor_var),
         x = predictor_label,
         y = flux_label) +
    theme_bw(base_size = 14) +
    theme(legend.position = c(0.85, 0.15),
          legend.background = element_rect(fill = "white", color = "black"),
          panel.grid.minor = element_blank(),
          plot.title = element_text(face = "bold", size = 16))
  
} else if(grepl("Piecewise", model_type)) {
  
  # Piecewise predictions
  pred_data <- setNames(data.frame(pred_x), predictor_var)
  pred_data$phase <- ifelse(pred_x < threshold, "Low", "High")
  pred_data$fit <- predict(best_model, newdata = pred_data)
  
  anno_text <- paste0(
    model_type, "\n",
    "R² = ", round(model_info$r2[1], 3), "\n",
    "Threshold: ", round(threshold, 1), "\n",
    "Slope(low): ", round(stats_table$Slope_below, 3), "\n",
    "Slope(high): ", round(stats_table$Slope_above, 3)
  )
  
  p <- ggplot() +
    geom_point(data = analysis_data,
               aes_string(x = predictor_var, y = flux_var, color = "factor(year)"),
               size = 3, alpha = 0.7) +
    geom_line(data = pred_data,
              aes_string(x = predictor_var, y = "fit"),
              color = "darkgreen", size = 1.5) +
    geom_vline(xintercept = threshold, 
               linetype = "dashed", color = "red", alpha = 0.7) +
    scale_color_viridis_d(name = "Year") +
    annotate("text", x = min(analysis_data[[predictor_var]]), 
             y = max(analysis_data[[flux_var]]),
             label = anno_text, hjust = 0, vjust = 1, size = 4,
             fontface = "bold") +
    labs(title = paste(flux_var, "~", predictor_var),
         x = predictor_label,
         y = flux_label) +
    theme_bw(base_size = 14) +
    theme(legend.position = c(0.85, 0.15),
          legend.background = element_rect(fill = "white", color = "black"),
          panel.grid.minor = element_blank(),
          plot.title = element_text(face = "bold", size = 16))
  
} else {
  
  # Linear/Quadratic predictions
  pred_data <- setNames(data.frame(pred_x), predictor_var)
  pred_data$fit <- predict(best_model, newdata = pred_data)
  
  anno_text <- paste0(
    model_type, "\n",
    "R² = ", round(model_info$r2[1], 3), "\n",
    "Slope: ", round(stats_table$Slope, 4), "\n",
    "p ", stats_table$p_value
  )
  
  p <- ggplot() +
    geom_point(data = analysis_data,
               aes_string(x = predictor_var, y = flux_var, color = "factor(year)"),
               size = 3, alpha = 0.7) +
    geom_line(data = pred_data,
              aes_string(x = predictor_var, y = "fit"),
              color = "darkgreen", size = 1.5) +
    scale_color_viridis_d(name = "Year") +
    annotate("text", x = min(analysis_data[[predictor_var]]), 
             y = max(analysis_data[[flux_var]]),
             label = anno_text, hjust = 0, vjust = 1, size = 4,
             fontface = "bold") +
    labs(title = paste(flux_var, "~", predictor_var),
         x = predictor_label,
         y = flux_label) +
    theme_bw(base_size = 14) +
    theme(legend.position = c(0.85, 0.15),
          legend.background = element_rect(fill = "white", color = "black"),
          panel.grid.minor = element_blank(),
          plot.title = element_text(face = "bold", size = 16))
}

print(p)

# Save figure
# figname <- paste0(flux_var, "_vs_", predictor_var, "_figure.png")
# ggsave(figname, p, width = 10, height = 7, dpi = 300)
# cat("✓ Figure saved to:", figname, "\n")

cat("\n", paste(rep("=", 80), collapse=""), "\n")
cat("✅ ANALYSIS COMPLETE FOR", flux_var, "~", predictor_var, "\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")
```
# =========================

#Visualizing ALL relationships - monthly 

#prepare and define variables 
```{r}
library(tidyverse)  # For data manipulation and ggplot2
library(scales)     # For nice axis labels
library(gridExtra)  # Alternative to patchwork for combining plots
library(cowplot)    # For extracting legends and plot_grid function


# Prepare data and define variables


# List of meteorological variables to analyze
# (excluding year, month, year_month, n_days, FC, FCH4)
met_vars <- c("TA_gapfilled", "TS_3_gapfilled", "SWC_3_1_1", 
              "VPD", "RH", "H", "LE", "G_1_1_1")

# Create nice labels for plotting (with proper formatting)
var_labels <- c(
  "TA_gapfilled" = "Air Temp GF (°C)",
  "TS_3_gapfilled" = "Soil Temp GF (°C)", 
  "SWC_3_1_1" = "Soil Moisture (%)",
  "VPD" = "VPD (hPa)",
  "RH" = "RH (%)",
  "H" = "Sensible Heat (W/m²)",
  "LE" = "Latent Heat (W/m²)",
  "G_1_1_1" = "Soil Heat Flux (W/m²)"
)

# Create flux labels
flux_labels <- c(
  "FC" = expression(paste("Monthly Mean HH CO"[2], " Flux (µmol/m²/s)")),
  "FCH4" = expression(paste("Monthly Mean HH CH"[4], " Flux (nmol/m²/s)"))
)

# Make year a factor for color mapping 
df_monthly_FC <- df_monthly_FC %>%
  mutate(year_for_color = as.character(year))  # Use the 'year' column directly

df_monthly_FCH4 <- df_monthly_FCH4 %>%
  mutate(year_for_color = as.character(year))


# Define your custom year colors (consistent with your existing analyses)
year_colors <- c(
  "2017" = "#E41A1C",  # Red
  "2018" = "#377EB8",  # Blue
  "2019" = "#4DAF4A",  # Green
  "2020" = "#984EA3",  # Purple
  "2021" = "#FF7F00",  # Orange
  "2022" = "#A65628"   # Brown
)

```

#Function to plot individual relationships

```{r}
# Function to create a single scatter plot with LOESS and linear fits
# 
# Parameters:
#   data: dataframe with flux and met variables
#   x_var: name of x-axis variable (met variable)
#   y_var: name of y-axis variable (flux: "FC" or "FCH4")
#   x_label: formatted label for x-axis
#   y_label: formatted label for y-axis
#
# Returns: a ggplot object

plot_relationship <- function(data, x_var, y_var, x_label, y_label) {
  
  # Create the base plot
  p <- ggplot(data, aes(x = .data[[x_var]], y = .data[[y_var]])) +
    
    # Add points colored by year for temporal patterns
    # Using your custom year colors for consistency across all analyses
    geom_point(aes(color = year_for_color), size = 2.5, alpha = 0.7) +
    
    # Add LOESS smooth (locally weighted regression) - captures non-linear patterns
    # span = 0.75 controls smoothness (smaller = more wiggly, larger = smoother)
    # se = TRUE shows 95% confidence interval as shaded area
    geom_smooth(method = "loess", span = 0.75, se = TRUE, 
                color = "black", fill = "gray70", alpha = 0.3, linewidth = 1) +
    
    # Add linear regression line in red/dashed to compare with LOESS
    # This helps visually identify if relationship is truly linear
    geom_smooth(method = "lm", se = FALSE, 
                color = "red", linetype = "dashed", linewidth = 0.8) +
    
    # Apply your custom year color scheme
    scale_color_manual(
      values = year_colors,
      name = "Year"
    ) +
    
    # Formatting
    labs(x = x_label, 
         y = y_label) +
    theme_bw(base_size = 20) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = "none",  # Remove legend for cleaner multi-panel figure
      plot.margin = margin(5, 5, 5, 5),
      
      # Make text text bold
     
  #text = element_text(face = "bold"),              # <- global bold
  #axis.text = element_text(face = "bold"),         # axis tick labels
  #axis.title = element_text(face = "bold"),        # axis titles
  #strip.text = element_text(face = "bold"),        # facet labels
  plot.title = element_text(face = "bold"),        # main title
  #legend.text = element_text(face = "bold"),       # legend text
  #legend.title = element_text(face = "bold")       # legend title
    )
  
  return(p)
}
```

# FC - all plots 
```{r}
# Create a list to store all FC plots
fc_plots <- list()

# Loop through each meteorological variable
for (var in met_vars) {
  
  # Create plot for this variable
  fc_plots[[var]] <- plot_relationship(
    data = df_monthly_FC,
    x_var = var,
    y_var = "FC",
    x_label = var_labels[var],
    y_label = flux_labels["FC"]
  )
  
  # Print progress message
  cat("Created FC ~", var, "plot\n")
}

```
#Combine FC figs
```{r}
#Create ONE plot WITH legend to extract


# Create a single plot WITH the legend (using the first variable as example)
plot_with_legend <- ggplot(df_monthly_FC, aes(x = TA_gapfilled, y = FC)) +
  geom_point(aes(color = year_for_color), size = 2.5, alpha = 0.7) +
  scale_color_manual(
    values = year_colors,
    name = "Year"
  ) +
  theme_bw(base_size = 20) +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 25),
    legend.title = element_text(size = 30, face = "bold"),
    legend.key.size = unit(2, "lines"), #spacing around legend labels 
    guides(color = guide_legend(override.aes = list(size = 5)))  # legend dot size
  )

# Extract the legend using cowplot
shared_legend <- get_legend(plot_with_legend)


```
#Combine plots with shared legend n empty space 
```{r}
# Create title and subtitle as text grobs (graphical objects)
title_text <- textGrob(
  expression(paste("Monthly Mean Half-hourly CO"[2], " Flux vs Monthly Mean Meteorological Variables")),
  gp = gpar(fontsize = 25, fontface = "bold")
)

subtitle_text <- textGrob(
  "Black line = LOESS fit; Red dashed line = Linear regression",
  gp = gpar(fontsize = 12, col = "gray30")
)

# Create a list that includes both plots AND the legend in the 9th position
# This places the legend in the bottom-right empty space
fc_plots_with_legend <- c(fc_plots, list(shared_legend))

# Combine all plots including legend in a 3x3 grid
# The legend will appear in position 9 (bottom-right)
fc_combined <- grid.arrange(
  grobs = fc_plots_with_legend,  # 8 plots + 1 legend = 9 items
  ncol = 3,                       # 3 columns
  nrow = 3,                       # 3 rows
  top = title_text,               # Add title at top
  bottom = subtitle_text          # Add subtitle at bottom
)

# Display message
cat("\nFC combined plot created successfully with legend in bottom-right!\n")


```


#save
```{r}
# To save properly with grid.arrange, use arrangeGrob first
 fc_combined_final <- arrangeGrob(grobs = fc_plots_with_legend, ncol = 3, nrow = 3,
                        top = title_text, bottom = subtitle_text)

  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Monthly_FC_Met_Relationships_ALL.png", fc_combined_final,
         width = 18, height = 20, dpi = 600)
```

#FCH4 - all plots 
```{r}
# Create a list to store all FCH4 plots
fch4_plots <- list()

# Loop through each meteorological variable
for (var in met_vars) {
  
  # Create plot for this variable
  fch4_plots[[var]] <- plot_relationship(
    data = df_monthly_FCH4,
    x_var = var,
    y_var = "FCH4",
    x_label = var_labels[var],
    y_label = flux_labels["FCH4"]
  )
}
```

#FCH4 - one plot with legend 

```{r}
# Create a single plot WITH the legend
plot_with_legend_ch4 <- ggplot(df_monthly_FCH4, aes(x = TA_gapfilled, y = FCH4)) +
  geom_point(aes(color = year_for_color), size = 2.5, alpha = 0.7) +
  scale_color_manual(
    values = year_colors,
    name = "Year"
  ) +
  theme_bw(base_size = 20) +
  theme(
    legend.position = "right",
    legend.text = element_text(size = 25),
    legend.title = element_text(size = 30, face = "bold"),
    legend.key.size = unit(2, "lines"), #spacing around legend labels 
    guides(color = guide_legend(override.aes = list(size = 5))) # legend dot size
    ) 

# Extract the legend
shared_legend_ch4 <- get_legend(plot_with_legend_ch4)

```
#Combine plots with legend in empty space
```{r}

# Create title and subtitle for FCH4 plot
title_text_ch4 <- textGrob(
  expression(paste("Monthly Mean CH"[4], " Flux vs Meteorological Variables")),
  gp = gpar(fontsize = 25, fontface = "bold")
)

subtitle_text_ch4 <- textGrob(
  "Black line = LOESS fit; Red dashed line = Linear regression",
  gp = gpar(fontsize = 12, col = "gray30")
)

# Create a list that includes both plots AND the legend in the 9th position
fch4_plots_with_legend <- c(fch4_plots, list(shared_legend_ch4))

# Combine all plots including legend in a 3x3 grid
fch4_combined <- grid.arrange(
  grobs = fch4_plots_with_legend,
  ncol = 3,
  nrow = 3,
  top = title_text_ch4,
  bottom = subtitle_text_ch4
)
```

#save
```{r}
# To save properly with grid.arrange, use arrangeGrob first
 fch4_combined_final <- arrangeGrob(grobs = fch4_plots_with_legend, ncol = 3, nrow = 3,
                          top = title_text_ch4, bottom = subtitle_text_ch4)

  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Monthly_FCH4_Met_Relationships_ALL.png", fch4_combined_final,
         width = 18, height = 20, dpi = 600)
```

#Comprehensive re-analysis of monotonic-appearing relationships:
#for FCH4 ~ RH, FCH4 ~ LE
#for FC ~ TA_gf, TS_3_gf, VPD, RH, and LE 
```{r}
# ============================================================================
# Comprehensive Analysis of Monotonic Flux-Meteorological Relationships
# ============================================================================
# Purpose: Analyze monotonic relationships between CO2/CH4 fluxes and met 
# variables using a hierarchical decision tree that tests linear assumptions,
# autocorrelation, and applies appropriate statistical methods including
# Linear Regression, GLS with AR(1), GLS with AR(2), or Kendall's tau


library(tidyverse)
library(nlme)      # For GLS models with autocorrelation structures
library(lmtest)    # For Breusch-Pagan and Durbin-Watson tests

# ----------------------------------------------------------------------------
# FUNCTION: Comprehensive relationship analysis with AR(1) and AR(2)
# ----------------------------------------------------------------------------

analyze_relationship_comprehensive <- function(data, flux_var, met_var, 
                                               flux_label, met_label) {
  
  # Prepare data - remove missing values and arrange by time
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month)
  
  # Need at least 10 observations for meaningful analysis
  if(nrow(plot_data) < 10) {
    cat("Insufficient data for", flux_label, "~", met_label, "\n")
    return(NULL)
  }
  
  # -------------------------------------------------------------------------
  # STEP 1: Fit standard linear model
  # -------------------------------------------------------------------------
  lm_model <- lm(flux ~ met, data = plot_data)
  lm_slope <- coef(lm_model)[2]
  lm_p <- summary(lm_model)$coefficients[2, 4]
  lm_r2 <- summary(lm_model)$r.squared
  residuals_vals <- residuals(lm_model)
  
  # -------------------------------------------------------------------------
  # STEP 2: Check linear regression assumptions
  # -------------------------------------------------------------------------
  
  # 2a. Normality of residuals (Shapiro-Wilk test)
  shapiro_test <- shapiro.test(residuals_vals)
  shapiro_p <- shapiro_test$p.value
  residuals_normal <- shapiro_p > 0.05  # TRUE if p > 0.05
  
  # 2b. Homogeneity of variance (Breusch-Pagan test)
  bp_test <- bptest(lm_model)
  bp_p <- bp_test$p.value
  homoscedastic <- bp_p > 0.05  # TRUE if p > 0.05
  
  # 2c. Autocorrelation (Durbin-Watson test)
  dw_test <- dwtest(lm_model)
  dw_stat <- as.numeric(dw_test$statistic)
  dw_p <- dw_test$p.value
  autocorr_detected <- dw_p < 0.05  # TRUE if autocorrelation detected
  
  # Summary: Are ALL linear assumptions met?
  lm_assumptions_met <- residuals_normal && homoscedastic && !autocorr_detected
  
  # STEP 3: Initialize variables for GLS models
  # -------------------------------------------------------------------------
  gls_AR1_slope <- NA
  gls_AR1_p <- NA
  gls_AR1_success <- FALSE
  gls_AR1_autocorr_resolved <- NA
  
  gls_AR2_slope <- NA
  gls_AR2_p <- NA
  gls_AR2_success <- FALSE
  gls_AR2_autocorr_resolved <- NA
  
  # Initialize Kendall's tau variables
  kendall_tau <- NA
  kendall_p <- NA
  kendall_autocorr_flagged <- FALSE
  
  # -------------------------------------------------------------------------
  # STEP 4: Apply decision tree based on assumption checks
  # -------------------------------------------------------------------------
  
  # DECISION PATH 1: Linear assumptions NOT met → Use Kendall's tau
  if(!residuals_normal || !homoscedastic) {
    
    # Non-parametric correlation (handles non-normality, heteroscedasticity)
    kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
    kendall_tau <- kendall_test$estimate
    kendall_p <- kendall_test$p.value
    
    # IMPORTANT: Check for autocorrelation even with Kendall's tau
    # Kendall's tau also assumes independence of observations
    if(autocorr_detected) {
      kendall_autocorr_flagged <- TRUE
      recommended_method <- "Kendall's tau (AUTOCORR DETECTED - CAUTION)"
      cat(flux_label, "~", met_label, ": Using Kendall's tau BUT autocorrelation detected!\n")
      cat("  WARNING: Kendall's tau assumes independence. Results may be unreliable.\n")
    } else {
      kendall_autocorr_flagged <- FALSE
      recommended_method <- "Kendall's tau"
      cat(flux_label, "~", met_label, ": Using Kendall's tau (assumptions violated, no autocorr)\n")
    }
    
    recommended_stat <- kendall_tau
    recommended_p <- kendall_p
    final_model_type <- "Non-parametric"
  
  # DECISION PATH 2: Linear assumptions met, but autocorrelation detected
  } else if(autocorr_detected) {
    
    # Try GLS with AR(1) autocorrelation structure
    cat(flux_label, "~", met_label, ": Trying GLS with AR(1)...\n")
    
    tryCatch({
      gls_AR1_model <- gls(flux ~ met, 
                           data = plot_data,
                           correlation = corAR1(form = ~ 1),
                           method = "REML")
      
      gls_AR1_slope <- coef(gls_AR1_model)[2]
      gls_AR1_p <- summary(gls_AR1_model)$tTable[2, 4]
      gls_AR1_success <- TRUE
      
      # Check if AR(1) resolved autocorrelation using residuals
      gls_AR1_resid <- residuals(gls_AR1_model, type = "normalized")
      
      # Test for remaining autocorrelation in AR(1) residuals
      # Using Durbin-Watson on normalized residuals
      gls_AR1_dw <- dwtest(gls_AR1_resid ~ 1)
      gls_AR1_autocorr_resolved <- gls_AR1_dw$p.value > 0.05
      
      cat("  AR(1) fit successful. Autocorr resolved:", gls_AR1_autocorr_resolved, "\n")
      
      # If AR(1) didn't resolve autocorrelation, try AR(2)
      if(!gls_AR1_autocorr_resolved) {
        cat("  Autocorrelation persists. Trying GLS with AR(2)...\n")
        
        tryCatch({
          gls_AR2_model <- gls(flux ~ met, 
                               data = plot_data,
                               correlation = corARMA(form = ~ 1, p = 2, q = 0),
                               method = "REML")
          
          gls_AR2_slope <- coef(gls_AR2_model)[2]
          gls_AR2_p <- summary(gls_AR2_model)$tTable[2, 4]
          gls_AR2_success <- TRUE
          
          # Check if AR(2) resolved autocorrelation
          gls_AR2_resid <- residuals(gls_AR2_model, type = "normalized")
          gls_AR2_dw <- dwtest(gls_AR2_resid ~ 1)
          gls_AR2_autocorr_resolved <- gls_AR2_dw$p.value > 0.05
          
          cat("  AR(2) fit successful. Autocorr resolved:", gls_AR2_autocorr_resolved, "\n")
          
          # Choose AR(2) as recommended method
          if(gls_AR2_autocorr_resolved) {
            recommended_method <- "GLS with AR(2)"
            recommended_stat <- gls_AR2_slope
            recommended_p <- gls_AR2_p
            final_model_type <- "GLS AR(2)"
          } else {
            # AR(2) still has autocorrelation - use it but flag warning
            recommended_method <- "GLS with AR(2) (autocorr persists)"
            recommended_stat <- gls_AR2_slope
            recommended_p <- gls_AR2_p
            final_model_type <- "GLS AR(2)*"
            cat("  WARNING: Autocorrelation persists even with AR(2)\n")
          }
          
        }, error = function(e) {
          cat("  AR(2) model failed. Using AR(1) results.\n")
          gls_AR2_success <<- FALSE
          
          # Fall back to AR(1)
          recommended_method <<- "GLS with AR(1)"
          recommended_stat <<- gls_AR1_slope
          recommended_p <<- gls_AR1_p
          final_model_type <<- "GLS AR(1)"
        })
        
      } else {
        # AR(1) resolved autocorrelation successfully
        recommended_method <- "GLS with AR(1)"
        recommended_stat <- gls_AR1_slope
        recommended_p <- gls_AR1_p
        final_model_type <- "GLS AR(1)"
      }
      
    }, error = function(e) {
      cat("  AR(1) model failed. Falling back to Kendall's tau.\n")
      gls_AR1_success <<- FALSE
      
      # Fallback to Kendall's tau
      kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
      kendall_tau <<- kendall_test$estimate
      kendall_p <<- kendall_test$p.value
      
      recommended_method <<- "Kendall's tau (GLS failed)"
      recommended_stat <<- kendall_tau
      recommended_p <<- kendall_p
      final_model_type <<- "Non-parametric"
    })
    
    # Calculate Kendall's tau regardless (for comparison)
    kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
    kendall_tau <- kendall_test$estimate
    kendall_p <- kendall_test$p.value
    
  # DECISION PATH 3: All assumptions met, no autocorrelation → Linear regression
  } else {
    
    kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
    kendall_tau <- kendall_test$estimate
    kendall_p <- kendall_test$p.value
    
    recommended_method <- "Linear Regression"
    recommended_stat <- lm_slope
    recommended_p <- lm_p
    final_model_type <- "Linear"
    
    cat(flux_label, "~", met_label, ": Using Linear Regression (all assumptions met)\n")
  }
  
  # -------------------------------------------------------------------------
  # STEP 5: Compile comprehensive results
  # -------------------------------------------------------------------------
  
  result <- data.frame(
    flux_variable = flux_label,
    met_variable = met_label,
    n_obs = nrow(plot_data),
    
    # Assumption test results
    shapiro_p = shapiro_p,
    residuals_normal = residuals_normal,
    bp_p = bp_p,
    homoscedastic = homoscedastic,
    dw_stat = dw_stat,
    dw_p = dw_p,
    autocorr_detected = autocorr_detected,
    lm_assumptions_met = lm_assumptions_met,
    
    # Linear regression results
    lm_r2 = lm_r2,
    lm_slope = lm_slope,
    lm_p = lm_p,
    
    # GLS AR(1) results
    gls_AR1_slope = gls_AR1_slope,
    gls_AR1_p = gls_AR1_p,
    gls_AR1_used = gls_AR1_success,
    gls_AR1_autocorr_resolved = gls_AR1_autocorr_resolved,
    
    # GLS AR(2) results
    gls_AR2_slope = gls_AR2_slope,
    gls_AR2_p = gls_AR2_p,
    gls_AR2_used = gls_AR2_success,
    gls_AR2_autocorr_resolved = gls_AR2_autocorr_resolved,
    
    # Kendall's tau results
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    kendall_autocorr_flagged = kendall_autocorr_flagged,
    
    # Final recommendation
    recommended_method = recommended_method,
    recommended_stat = recommended_stat,
    recommended_p = recommended_p,
    model_type = final_model_type,
    significant = ifelse(recommended_p < 0.05, 
                        paste0("Yes (", recommended_method, ")"), 
                        "No"),
    
    stringsAsFactors = FALSE
  )
  
  return(result)
}

# ----------------------------------------------------------------------------
# ANALYZE FC (CO2) MONOTONIC RELATIONSHIPS
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("ANALYZING FC (CO₂) MONOTONIC RELATIONSHIPS\n")
cat("========================================\n\n")

# Define monotonic relationships for FC based on visual inspection
fc_monotonic_vars <- list(
  list(var = "TA_gapfilled", label = "Air Temp GF"),
  list(var = "TS_3_gapfilled", label = "Soil Temp GF"),
  list(var = "VPD", label = "VPD"),
  list(var = "RH", label = "RH"),
  list(var = "LE", label = "Latent Heat")
)

# Run analysis for each FC relationship
fc_results <- list()

for(met in fc_monotonic_vars) {
  result <- analyze_relationship_comprehensive(
    data = df_monthly_FC,
    flux_var = "FC",
    met_var = met$var,
    flux_label = "FC",
    met_label = met$label
  )
  
  if(!is.null(result)) {
    fc_results[[met$label]] <- result
  }
}

# Combine into data frame
fc_results_df <- do.call(rbind, fc_results)
rownames(fc_results_df) <- NULL

# Display results
cat("\n--- FC COMPREHENSIVE RESULTS ---\n")
print(fc_results_df)

# ----------------------------------------------------------------------------
# ANALYZE FCH4 (CH4) MONOTONIC RELATIONSHIPS
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("ANALYZING FCH4 (CH₄) MONOTONIC RELATIONSHIPS\n")
cat("========================================\n\n")

# Define monotonic relationships for FCH4 based on visual inspection
fch4_monotonic_vars <- list(
  list(var = "RH", label = "RH"),
  list(var = "LE", label = "Latent Heat")
)

# Run analysis for each FCH4 relationship
fch4_results <- list()

for(met in fch4_monotonic_vars) {
  result <- analyze_relationship_comprehensive(
    data = df_monthly_FCH4,
    flux_var = "FCH4",
    met_var = met$var,
    flux_label = "FCH4",
    met_label = met$label
  )
  
  if(!is.null(result)) {
    fch4_results[[met$label]] <- result
  }
}

# Combine into data frame
fch4_results_df <- do.call(rbind, fch4_results)
rownames(fch4_results_df) <- NULL

# Display results
cat("\n--- FCH4 COMPREHENSIVE RESULTS ---\n")
print(fch4_results_df)

# ----------------------------------------------------------------------------
# CREATE SUMMARY TABLE WITH KEY COLUMNS
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("COMBINED SUMMARY TABLE\n")
cat("========================================\n\n")

# Combine FC and FCH4 results
all_results <- rbind(fc_results_df, fch4_results_df)

# Select key columns for summary
summary_table <- all_results %>%
  select(
    flux_variable,
    met_variable,
    n_obs,
    shapiro_p,
    residuals_normal,
    bp_p,
    homoscedastic,
    dw_stat,
    dw_p,
    lm_assumptions_met,
    recommended_method,
    lm_r2,
    lm_slope,
    lm_p,
    gls_AR1_slope,
    gls_AR1_p,
    gls_AR2_slope,
    gls_AR2_p,
    kendall_tau,
    kendall_p,
    kendall_autocorr_flagged,
    significant
  )

print(summary_table)

# Save summary table to CSV (commented out)
# write.csv(summary_table, 
#           "results/monotonic_relationships_summary.csv", 
#           row.names = FALSE)

# ----------------------------------------------------------------------------
# CREATE FORMATTED TABLE FOR PUBLICATION
# ----------------------------------------------------------------------------

# Round numeric columns for readability
summary_table_formatted <- summary_table %>%
  mutate(
    across(c(shapiro_p, bp_p, dw_stat, dw_p, lm_r2, lm_slope, lm_p,
             gls_AR1_slope, gls_AR1_p, gls_AR2_slope, gls_AR2_p,
             kendall_tau, kendall_p), 
           ~round(.x, 4))
  )

cat("\n--- FORMATTED SUMMARY TABLE ---\n")
print(summary_table_formatted)

# ----------------------------------------------------------------------------
# INTERPRETATION NOTES
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("INTERPRETATION GUIDE\n")
cat("========================================\n\n")

cat("ASSUMPTION TESTS:\n")
cat("- Shapiro-Wilk (shapiro_p > 0.05): Residuals are normally distributed\n")
cat("- Breusch-Pagan (bp_p > 0.05): Variance is homogeneous\n")
cat("- Durbin-Watson (dw_p > 0.05): No autocorrelation detected\n\n")

cat("DECISION TREE:\n")
cat("1. If residuals_normal=FALSE OR homoscedastic=FALSE → Kendall's tau\n")
cat("   - Check for autocorrelation in original data\n")
cat("   - If autocorr detected with Kendall's tau → FLAG WARNING\n")
cat("2. If assumptions met BUT autocorr_detected=TRUE → Try GLS AR(1) with REML\n")
cat("   - If AR(1) resolves autocorr → Use GLS AR(1)\n")
cat("   - If AR(1) doesn't resolve → Try GLS AR(2) with REML\n")
cat("   - If AR(2) resolves autocorr → Use GLS AR(2)\n")
cat("   - If AR(2) fails or autocorr persists → Flag warning\n")
cat("3. If all assumptions met AND no autocorr → Linear Regression with REML\n\n")

cat("SIGNIFICANT RELATIONSHIPS (p < 0.05):\n")
sig_relationships <- summary_table_formatted %>%
  filter(grepl("Yes", significant))

if(nrow(sig_relationships) > 0) {
  for(i in 1:nrow(sig_relationships)) {
    cat(sprintf("- %s ~ %s: %s (p = %.4f)\n",
                sig_relationships$flux_variable[i],
                sig_relationships$met_variable[i],
                sig_relationships$recommended_method[i],
                sig_relationships$recommended_p[i]))
  }
} else {
  cat("No significant relationships found.\n")
}

cat("\n========================================\n")
cat("ANALYSIS COMPLETE\n")
cat("========================================\n")


```

#using weighted varIdent by year for gls and LME
```{r}

library(tidyverse)
library(nlme)      # For GLS models with autocorrelation structures
library(lmtest)    # For Breusch-Pagan and Durbin-Watson tests

# ----------------------------------------------------------------------------
# FUNCTION: Comprehensive relationship analysis with AR(1) and AR(2)
# ----------------------------------------------------------------------------

analyze_relationship_comprehensive <- function(data, flux_var, met_var, 
                                               flux_label, met_label) {
  
  # Prepare data - remove missing values and arrange by time
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month)
  
  # Need at least 10 observations for meaningful analysis
  if(nrow(plot_data) < 10) {
    cat("Insufficient data for", flux_label, "~", met_label, "\n")
    return(NULL)
  }
  
  # -------------------------------------------------------------------------
  # STEP 1: Fit standard linear model
  # -------------------------------------------------------------------------
  lm_model <- lm(flux ~ met, data = plot_data)
  lm_slope <- coef(lm_model)[2]
  lm_p <- summary(lm_model)$coefficients[2, 4]
  lm_r2 <- summary(lm_model)$r.squared
  residuals_vals <- residuals(lm_model)
  
  # -------------------------------------------------------------------------
  # STEP 2: Check linear regression assumptions
  # -------------------------------------------------------------------------
  
  # 2a. Normality of residuals (Shapiro-Wilk test)
  shapiro_test <- shapiro.test(residuals_vals)
  shapiro_p <- shapiro_test$p.value
  residuals_normal <- shapiro_p > 0.05  # TRUE if p > 0.05
  
  # 2b. Homogeneity of variance (Breusch-Pagan test)
  bp_test <- bptest(lm_model)
  bp_p <- bp_test$p.value
  homoscedastic <- bp_p > 0.05  # TRUE if p > 0.05
  
  # 2c. Autocorrelation (Durbin-Watson test)
  dw_test <- dwtest(lm_model)
  dw_stat <- as.numeric(dw_test$statistic)
  dw_p <- dw_test$p.value
  autocorr_detected <- dw_p < 0.05  # TRUE if autocorrelation detected
  
  # Summary: Are ALL linear assumptions met?
  lm_assumptions_met <- residuals_normal && homoscedastic && !autocorr_detected
  
  # -------------------------------------------------------------------------
  # STEP 3: Initialize variables for all model types
  # -------------------------------------------------------------------------
  gls_AR1_slope <- NA
  gls_AR1_p <- NA
  gls_AR1_success <- FALSE
  gls_AR1_autocorr_resolved <- NA
  
  gls_AR2_slope <- NA
  gls_AR2_p <- NA
  gls_AR2_success <- FALSE
  gls_AR2_autocorr_resolved <- NA
  
  weighted_gls_slope <- NA
  weighted_gls_p <- NA
  weighted_gls_success <- FALSE
  weighted_gls_autocorr_resolved <- NA
  
  lme_slope <- NA
  lme_p <- NA
  lme_success <- FALSE
  lme_autocorr_resolved <- NA
  
  # Initialize Kendall's tau variables
  kendall_tau <- NA
  kendall_p <- NA
  kendall_autocorr_flagged <- FALSE
  
  # -------------------------------------------------------------------------
  # STEP 4: Apply decision tree based on assumption checks
  # -------------------------------------------------------------------------
  
  # DECISION PATH 1: Linear assumptions NOT met → Try advanced methods
  if(!residuals_normal || !homoscedastic) {
    
    cat(flux_label, "~", met_label, ": Distributional assumptions violated\n")
    
    # OPTION A: If autocorrelation also detected, try weighted GLS or LME
    if(autocorr_detected) {
      cat("  Autocorrelation also detected. Trying weighted GLS with AR(1)...\n")
      
      # Try weighted GLS with variance function + AR(1) correlation
      tryCatch({
        # Using varIdent to allow different variance per year
        # This is often more appropriate for time series data where
        # measurement precision or environmental variability differs by year
        weighted_gls_model <- gls(flux ~ met, 
                                  data = plot_data,
                                  weights = varIdent(form = ~ 1 | year),  # Different variance per year
                                  correlation = corAR1(form = ~ 1),
                                  method = "REML")
        
        # Alternative variance structures to consider:
        # weights = varPower(form = ~ abs(met))  # Variance as function of predictor
        # weights = varExp(form = ~ met)         # Exponential variance function
        # weights = varComb(varIdent(form = ~ 1 | year), 
        #                   varPower(form = ~ met))  # Combine both!
        
        weighted_gls_slope <- coef(weighted_gls_model)[2]
        weighted_gls_p <- summary(weighted_gls_model)$tTable[2, 4]
        weighted_gls_success <- TRUE
        
        # Check if weighted GLS resolved autocorrelation
        weighted_gls_resid <- residuals(weighted_gls_model, type = "normalized")
        weighted_gls_dw <- dwtest(weighted_gls_resid ~ 1)
        weighted_gls_autocorr_resolved <- weighted_gls_dw$p.value > 0.05
        
        cat("  Weighted GLS fit successful. Autocorr resolved:", weighted_gls_autocorr_resolved, "\n")
        
        # If weighted GLS worked, try LME with random year effect as alternative
        cat("  Also trying LME with random year effect...\n")
        tryCatch({
          # LME with random year intercept + year-specific variance + AR(1) correlation
          # lme_model <- lme(flux ~ met, 
          #                 random = ~ 1 | year,                     # Random intercept by year
          #                 correlation = corAR1(form = ~ 1 | year), # AR(1) within years
          #                 weights = varIdent(form = ~ 1 | year),   # Different variance per year
          #                 data = plot_data,
          #                 method = "REML")
          
          # Alternative: Let random year effect handle variance differences - tested below and this simple model is better than the more complex varIdent model 
          lme_model <- lme(flux ~ met,
                           random = ~ 1 | year,
                           correlation = corAR1(form = ~ 1 | year),
                           data = plot_data,
                           method = "REML")
          
          lme_slope <- fixef(lme_model)[2]
          lme_p <- summary(lme_model)$tTable[2, 5]  # p-value is in column 5 for lme
          lme_success <- TRUE
          
          # Check autocorrelation in LME residuals
          lme_resid <- residuals(lme_model, type = "normalized")
          lme_dw <- dwtest(lme_resid ~ 1)
          lme_autocorr_resolved <- lme_dw$p.value > 0.05
          
          cat("  LME fit successful. Autocorr resolved:", lme_autocorr_resolved, "\n")
          
        }, error = function(e) {
          cat("  LME failed:", e$message, "\n")
          lme_success <<- FALSE
        })
        
        # Choose best model between weighted GLS and LME
        if(lme_success && lme_autocorr_resolved) {
          recommended_method <- "LME with random year + year-specific AR(1) "
          recommended_stat <- lme_slope
          recommended_p <- lme_p
          final_model_type <- "LME"
          cat("  Recommending LME (autocorr resolved)\n")
        } else if(weighted_gls_autocorr_resolved) {
          recommended_method <- "Weighted GLS with AR(1)"
          recommended_stat <- weighted_gls_slope
          recommended_p <- weighted_gls_p
          final_model_type <- "Weighted GLS"
          cat("  Recommending Weighted GLS (autocorr resolved)\n")
        } else {
          recommended_method <- "Weighted GLS with AR(1) (autocorr persists)"
          recommended_stat <- weighted_gls_slope
          recommended_p <- weighted_gls_p
          final_model_type <- "Weighted GLS*"
          cat("  WARNING: Autocorrelation persists even with weighted GLS\n")
        }
        
      }, error = function(e) {
        cat("  Weighted GLS failed:", e$message, "\n")
        weighted_gls_success <<- FALSE
        
        # Fall back to Kendall's tau with warning
        kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
        kendall_tau <<- kendall_test$estimate
        kendall_p <<- kendall_test$p.value
        kendall_autocorr_flagged <<- TRUE
        
        recommended_method <<- "Kendall's tau (AUTOCORR + assumptions violated)"
        recommended_stat <<- kendall_tau
        recommended_p <<- kendall_p
        final_model_type <<- "Non-parametric*"
        cat("  Falling back to Kendall's tau (WARNING: autocorr + assumptions violated)\n")
      })
      
    } else {
      # OPTION B: Assumptions violated but NO autocorrelation → Kendall's tau is fine
      kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
      kendall_tau <- kendall_test$estimate
      kendall_p <- kendall_test$p.value
      kendall_autocorr_flagged <- FALSE
      
      recommended_method <- "Kendall's tau"
      recommended_stat <- kendall_tau
      recommended_p <- kendall_p
      final_model_type <- "Non-parametric"
      cat("  Using Kendall's tau (assumptions violated, no autocorr)\n")
    }
  
  # DECISION PATH 2: Linear assumptions met, but autocorrelation detected
  } else if(autocorr_detected) {
    
    # Try GLS with AR(1) autocorrelation structure
    cat(flux_label, "~", met_label, ": Trying GLS with AR(1)...\n")
    
    tryCatch({
      gls_AR1_model <- gls(flux ~ met, 
                           data = plot_data,
                           correlation = corAR1(form = ~ 1),
                           method = "REML")
      
      gls_AR1_slope <- coef(gls_AR1_model)[2]
      gls_AR1_p <- summary(gls_AR1_model)$tTable[2, 4]
      gls_AR1_success <- TRUE
      
      # Check if AR(1) resolved autocorrelation using residuals
      gls_AR1_resid <- residuals(gls_AR1_model, type = "normalized")
      
      # Test for remaining autocorrelation in AR(1) residuals
      # Using Durbin-Watson on normalized residuals
      gls_AR1_dw <- dwtest(gls_AR1_resid ~ 1)
      gls_AR1_autocorr_resolved <- gls_AR1_dw$p.value > 0.05
      
      cat("  AR(1) fit successful. Autocorr resolved:", gls_AR1_autocorr_resolved, "\n")
      
      # If AR(1) didn't resolve autocorrelation, try AR(2)
      if(!gls_AR1_autocorr_resolved) {
        cat("  Autocorrelation persists. Trying GLS with AR(2)...\n")
        
        tryCatch({
          gls_AR2_model <- gls(flux ~ met, 
                               data = plot_data,
                               correlation = corARMA(form = ~ 1, p = 2, q = 0),
                               method = "REML")
          
          gls_AR2_slope <- coef(gls_AR2_model)[2]
          gls_AR2_p <- summary(gls_AR2_model)$tTable[2, 4]
          gls_AR2_success <- TRUE
          
          # Check if AR(2) resolved autocorrelation
          gls_AR2_resid <- residuals(gls_AR2_model, type = "normalized")
          gls_AR2_dw <- dwtest(gls_AR2_resid ~ 1)
          gls_AR2_autocorr_resolved <- gls_AR2_dw$p.value > 0.05
          
          cat("  AR(2) fit successful. Autocorr resolved:", gls_AR2_autocorr_resolved, "\n")
          
          # Choose AR(2) as recommended method
          if(gls_AR2_autocorr_resolved) {
            recommended_method <- "GLS with AR(2)"
            recommended_stat <- gls_AR2_slope
            recommended_p <- gls_AR2_p
            final_model_type <- "GLS AR(2)"
          } else {
            # AR(2) still has autocorrelation - use it but flag warning
            recommended_method <- "GLS with AR(2) (autocorr persists)"
            recommended_stat <- gls_AR2_slope
            recommended_p <- gls_AR2_p
            final_model_type <- "GLS AR(2)*"
            cat("  WARNING: Autocorrelation persists even with AR(2)\n")
          }
          
        }, error = function(e) {
          cat("  AR(2) model failed. Using AR(1) results.\n")
          gls_AR2_success <<- FALSE
          
          # Fall back to AR(1)
          recommended_method <<- "GLS with AR(1)"
          recommended_stat <<- gls_AR1_slope
          recommended_p <<- gls_AR1_p
          final_model_type <<- "GLS AR(1)"
        })
        
      } else {
        # AR(1) resolved autocorrelation successfully
        recommended_method <- "GLS with AR(1)"
        recommended_stat <- gls_AR1_slope
        recommended_p <- gls_AR1_p
        final_model_type <- "GLS AR(1)"
      }
      
    }, error = function(e) {
      cat("  AR(1) model failed. Falling back to Kendall's tau.\n")
      gls_AR1_success <<- FALSE
      
      # Fallback to Kendall's tau
      kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
      kendall_tau <<- kendall_test$estimate
      kendall_p <<- kendall_test$p.value
      
      recommended_method <<- "Kendall's tau (GLS failed)"
      recommended_stat <<- kendall_tau
      recommended_p <<- kendall_p
      final_model_type <<- "Non-parametric"
    })
    
    # Calculate Kendall's tau regardless (for comparison)
    kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
    kendall_tau <- kendall_test$estimate
    kendall_p <- kendall_test$p.value
    
  # DECISION PATH 3: All assumptions met, no autocorrelation → Linear regression
  } else {
    
    kendall_test <- cor.test(plot_data$met, plot_data$flux, method = "kendall")
    kendall_tau <- kendall_test$estimate
    kendall_p <- kendall_test$p.value
    
    recommended_method <- "Linear Regression"
    recommended_stat <- lm_slope
    recommended_p <- lm_p
    final_model_type <- "Linear"
    
    cat(flux_label, "~", met_label, ": Using Linear Regression (all assumptions met)\n")
  }
  
  # -------------------------------------------------------------------------
  # STEP 5: Compile comprehensive results
  # -------------------------------------------------------------------------
  
  result <- data.frame(
    flux_variable = flux_label,
    met_variable = met_label,
    n_obs = nrow(plot_data),
    
    # Assumption test results
    shapiro_p = shapiro_p,
    residuals_normal = residuals_normal,
    bp_p = bp_p,
    homoscedastic = homoscedastic,
    dw_stat = dw_stat,
    dw_p = dw_p,
    autocorr_detected = autocorr_detected,
    lm_assumptions_met = lm_assumptions_met,
    
    # Linear regression results
    lm_r2 = lm_r2,
    lm_slope = lm_slope,
    lm_p = lm_p,
    
    # GLS AR(1) results
    gls_AR1_slope = gls_AR1_slope,
    gls_AR1_p = gls_AR1_p,
    gls_AR1_used = gls_AR1_success,
    gls_AR1_autocorr_resolved = gls_AR1_autocorr_resolved,
    
    # GLS AR(2) results
    gls_AR2_slope = gls_AR2_slope,
    gls_AR2_p = gls_AR2_p,
    gls_AR2_used = gls_AR2_success,
    gls_AR2_autocorr_resolved = gls_AR2_autocorr_resolved,
    
    # Weighted GLS results
    weighted_gls_slope = weighted_gls_slope,
    weighted_gls_p = weighted_gls_p,
    weighted_gls_used = weighted_gls_success,
    weighted_gls_autocorr_resolved = weighted_gls_autocorr_resolved,
    
    # LME results
    lme_slope = lme_slope,
    lme_p = lme_p,
    lme_used = lme_success,
    lme_autocorr_resolved = lme_autocorr_resolved,
    
    # Kendall's tau results
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    kendall_autocorr_flagged = kendall_autocorr_flagged,
    
    # Final recommendation
    recommended_method = recommended_method,
    recommended_stat = recommended_stat,
    recommended_p = recommended_p,
    model_type = final_model_type,
    significant = ifelse(recommended_p < 0.05, 
                        paste0("Yes (", recommended_method, ")"), 
                        "No"),
    
    stringsAsFactors = FALSE
  )
  
  return(result)
}

# ----------------------------------------------------------------------------
# ANALYZE FC (CO2) MONOTONIC RELATIONSHIPS
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("ANALYZING FC (CO₂) MONOTONIC RELATIONSHIPS\n")
cat("========================================\n\n")

# Define monotonic relationships for FC based on visual inspection
fc_monotonic_vars <- list(
  list(var = "TA_gapfilled", label = "Air Temp"),
  list(var = "TS_3_gapfilled", label = "Soil Temp"),
  list(var = "VPD", label = "VPD"),
  list(var = "RH", label = "RH"),
  list(var = "LE", label = "Latent Heat")
)

# Run analysis for each FC relationship
fc_results <- list()

for(met in fc_monotonic_vars) {
  result <- analyze_relationship_comprehensive(
    data = df_monthly_FC,
    flux_var = "FC",
    met_var = met$var,
    flux_label = "FC",
    met_label = met$label
  )
  
  if(!is.null(result)) {
    fc_results[[met$label]] <- result
  }
}

# Combine into data frame
fc_results_df <- do.call(rbind, fc_results)
rownames(fc_results_df) <- NULL

# Display results
cat("\n--- FC COMPREHENSIVE RESULTS ---\n")
print(fc_results_df)

# ----------------------------------------------------------------------------
# ANALYZE FCH4 (CH4) MONOTONIC RELATIONSHIPS
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("ANALYZING FCH4 (CH₄) MONOTONIC RELATIONSHIPS\n")
cat("========================================\n\n")

# Define monotonic relationships for FCH4 based on visual inspection
fch4_monotonic_vars <- list(
  list(var = "RH", label = "RH"),
  list(var = "LE", label = "Latent Heat")
)

# Run analysis for each FCH4 relationship
fch4_results <- list()

for(met in fch4_monotonic_vars) {
  result <- analyze_relationship_comprehensive(
    data = df_monthly_FCH4,
    flux_var = "FCH4",
    met_var = met$var,
    flux_label = "FCH4",
    met_label = met$label
  )
  
  if(!is.null(result)) {
    fch4_results[[met$label]] <- result
  }
}

# Combine into data frame
fch4_results_df <- do.call(rbind, fch4_results)
rownames(fch4_results_df) <- NULL

# Display results
cat("\n--- FCH4 COMPREHENSIVE RESULTS ---\n")
print(fch4_results_df)

# ----------------------------------------------------------------------------
# CREATE SUMMARY TABLE WITH KEY COLUMNS
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("COMBINED SUMMARY TABLE\n")
cat("========================================\n\n")

# Combine FC and FCH4 results
all_results <- rbind(fc_results_df, fch4_results_df)

# Select key columns for summary
summary_table <- all_results %>%
  select(
    flux_variable,
    met_variable,
    n_obs,
    shapiro_p,
    residuals_normal,
    bp_p,
    homoscedastic,
    dw_stat,
    dw_p,
    lm_assumptions_met,
    recommended_method,
    lm_r2,
    lm_slope,
    lm_p,
    gls_AR1_slope,
    gls_AR1_p,
    gls_AR2_slope,
    gls_AR2_p,
    weighted_gls_slope,
    weighted_gls_p,
    lme_slope,
    lme_p,
    kendall_tau,
    kendall_p,
    kendall_autocorr_flagged,
    significant
  )

print(summary_table)

# Save summary table to CSV (commented out)
# write.csv(summary_table, 
#           "results/monotonic_relationships_summary.csv", 
#           row.names = FALSE)

# ----------------------------------------------------------------------------
# CREATE FORMATTED TABLE FOR PUBLICATION
# ----------------------------------------------------------------------------

# Round numeric columns for readability
summary_table_formatted <- summary_table %>%
  mutate(
    across(c(shapiro_p, bp_p, dw_stat, dw_p, lm_r2, lm_slope, lm_p,
             gls_AR1_slope, gls_AR1_p, gls_AR2_slope, gls_AR2_p,
             kendall_tau, kendall_p), 
           ~round(.x, 4))
  )

cat("\n--- FORMATTED SUMMARY TABLE ---\n")
print(summary_table_formatted)

# ----------------------------------------------------------------------------
# INTERPRETATION NOTES
# ----------------------------------------------------------------------------

cat("\n========================================\n")
cat("INTERPRETATION GUIDE\n")
cat("========================================\n\n")

cat("ASSUMPTION TESTS:\n")
cat("- Shapiro-Wilk (shapiro_p > 0.05): Residuals are normally distributed\n")
cat("- Breusch-Pagan (bp_p > 0.05): Variance is homogeneous\n")
cat("- Durbin-Watson (dw_p > 0.05): No autocorrelation detected\n\n")

cat("MODEL SELECTION HIERARCHY:\n")
cat("1. DISTRIBUTIONAL ASSUMPTIONS VIOLATED:\n")
cat("   • No autocorr → Kendall's tau\n")
cat("   • With autocorr → Weighted GLS or LME (best option!)\n")
cat("     - Weighted GLS: varIdent allows different variance per year\n")
cat("     - LME: Adds random year effect + handles autocorr + year-specific variance\n\n")

cat("2. ASSUMPTIONS MET, AUTOCORRELATION PRESENT:\n")
cat("   • Try GLS AR(1) → if fails → GLS AR(2)\n\n")

cat("3. ALL ASSUMPTIONS MET:\n")
cat("   • Standard Linear Regression\n\n")

cat("WEIGHTED GLS EXPLANATION:\n")
cat("- varIdent(form = ~ 1 | year): Different variance for each year\n")
cat("  • Accounts for year-to-year differences in measurement precision\n")
cat("  • Or environmental variability differences between years\n")
cat("  • Estimates one variance parameter per year\n")
cat("- Alternative: varPower(form = ~ met) models variance as function of predictor\n")
cat("- Can combine both with varComb() for complex variance structures\n\n")

cat("LME BENEFITS:\n")
cat("- Random year effect: Accounts for year-to-year baseline differences\n")
cat("- Can combine: random effects + AR correlation + variance structure\n")
cat("- Most flexible option for complex temporal data\n\n")

cat("DECISION TREE:\n")
cat("1. If residuals_normal=FALSE OR homoscedastic=FALSE:\n")
cat("   a) Check for autocorrelation\n")
cat("      - If NO autocorr → Kendall's tau ✓\n")
cat("      - If autocorr detected → Try Weighted GLS with AR(1) + varIdent(year)\n")
cat("        • Also try LME with random year + AR(1) + varIdent(year)\n")
cat("        • Compare and choose best model\n")
cat("        • If both fail → Kendall's tau with AUTOCORR WARNING\n\n")
cat("2. If assumptions met BUT autocorr_detected=TRUE → Try GLS AR(1) with REML\n")
cat("   - If AR(1) resolves autocorr → Use GLS AR(1)\n")
cat("   - If AR(1) doesn't resolve → Try GLS AR(2) with REML\n")
cat("   - If AR(2) resolves autocorr → Use GLS AR(2)\n")
cat("   - If AR(2) fails or autocorr persists → Flag warning\n\n")
cat("3. If all assumptions met AND no autocorr → Linear Regression with REML\n\n")

cat("SIGNIFICANT RELATIONSHIPS (p < 0.05):\n")
sig_relationships <- summary_table_formatted %>%
  filter(grepl("Yes", significant))

if(nrow(sig_relationships) > 0) {
  for(i in 1:nrow(sig_relationships)) {
    cat(sprintf("- %s ~ %s: %s (p = %.4f)\n",
                sig_relationships$flux_variable[i],
                sig_relationships$met_variable[i],
                sig_relationships$recommended_method[i],
                sig_relationships$recommended_p[i]))
  }
} else {
  cat("No significant relationships found.\n")
}

cat("\n========================================\n")
cat("ANALYSIS COMPLETE\n")
cat("========================================\n")

# ============================================================================
# NEXT STEPS:
# ============================================================================
# 
# 1. Review the summary table to identify significant relationships
# 2. For significant relationships, create publication-quality figures
# 3. Report the recommended method and statistics in your manuscript
# 4. For non-monotonic relationships (FC ~ H, FC ~ SWC, etc.), consider GAM
# 
# =========================================================================
```
```{r}
summary_table
```
#save formatted summary table 
```{r}
library(writexl)

write_xlsx(summary_table_formatted, "C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/monthly_mean_monotonic_C_Met_relationship_summary.xlsx")



```
#which LME model with corr / variance structure is best for FC~ RH and VPD
```{r}
# ============================================================================
# Compare Simple LME vs LME with varIdent 
# ============================================================================
# Purpose: Test whether adding year-specific variance (varIdent) improves
# model fit for FC ~ VPD and FC ~ RH relationships
#
# Author: [Your name]
# Date: October 25, 2025
# ============================================================================

library(tidyverse)
library(nlme)
library(lmtest)

# ----------------------------------------------------------------------------
# FUNCTION: Compare two LME model versions
# ----------------------------------------------------------------------------

compare_lme_models <- function(data, flux_var, met_var, 
                               flux_label, met_label) {
  
  cat("\n========================================\n")
  cat("COMPARING LME MODELS:", flux_label, "~", met_label, "\n")
  cat("========================================\n\n")
  
  # Prepare data
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month)
  
  cat("Number of observations:", nrow(plot_data), "\n\n")
  
  # -------------------------------------------------------------------------
  # CHECK ASSUMPTIONS ON ORIGINAL LINEAR MODEL FIRST
  # -------------------------------------------------------------------------
  
  cat("PRELIMINARY CHECK: Linear Model Assumptions\n")
  cat("(Testing whether LME is appropriate at all)\n\n")
  
  lm_model <- lm(flux ~ met, data = plot_data)
  
  # Normality
  shapiro_test <- shapiro.test(residuals(lm_model))
  cat(sprintf("  Shapiro-Wilk p-value: %.4f ", shapiro_test$p.value))
  if(shapiro_test$p.value > 0.05) {
    cat("→ Residuals normal ✓\n")
    normal_ok <- TRUE
  } else {
    cat("→ Residuals NOT normal ✗\n")
    normal_ok <- FALSE
  }
  
  # Homoscedasticity
  bp_test <- bptest(lm_model)
  cat(sprintf("  Breusch-Pagan p-value: %.4f ", bp_test$p.value))
  if(bp_test$p.value > 0.05) {
    cat("→ Homoscedastic ✓\n")
    homosced_ok <- TRUE
  } else {
    cat("→ Heteroscedastic ✗\n")
    homosced_ok <- FALSE
  }
  
  cat("\n")
  
  if(!normal_ok || !homosced_ok) {
    cat("⚠ WARNING: Distributional assumptions violated!\n")
    cat("  LME with AR(1) alone cannot fix these issues.\n")
    cat("  Consider:\n")
    cat("  1. Adding variance structure: weights = varIdent(form = ~ 1 | year)\n")
    cat("  2. Transforming the response variable\n")
    cat("  3. Using robust methods or non-parametric alternatives\n\n")
    
    if(!homosced_ok && normal_ok) {
      cat("  ✓ Since only heteroscedasticity is violated, varIdent should help!\n")
      cat("    Testing LME with varIdent is especially important here.\n\n")
    } else if(!normal_ok && homosced_ok) {
      cat("  ⚠ Non-normality detected. LME is somewhat robust to this,\n")
      cat("    but results should be interpreted cautiously.\n\n")
    } else {
      cat("  ⚠ BOTH assumptions violated. LME results may be unreliable.\n")
      cat("    Strong recommendation to use varIdent or alternative methods.\n\n")
    }
  } else {
    cat("✓ All distributional assumptions met. LME with AR(1) is appropriate.\n\n")
  }
  
  # -------------------------------------------------------------------------
  # MODEL 1: Simple LME (random year + AR1)
  # -------------------------------------------------------------------------
  
  cat("Fitting MODEL 1: Simple LME...\n")
  cat("  Components: random intercept by year + AR(1) correlation\n")
  
  lme_simple <- lme(flux ~ met, 
                    random = ~ 1 | year,
                    correlation = corAR1(form = ~ 1 | year),
                    data = plot_data,
                    method = "REML")
  
  cat("  ✓ Model fit successful\n\n")
  
  # -------------------------------------------------------------------------
  # MODEL 2: LME with varIdent (random year + AR1 + year-specific variance)
  # -------------------------------------------------------------------------
  
  cat("Fitting MODEL 2: LME with varIdent...\n")
  cat("  Components: random intercept by year + AR(1) + different variance per year\n")
  
  lme_varIdent <- lme(flux ~ met, 
                      random = ~ 1 | year,
                      correlation = corAR1(form = ~ 1 | year),
                      weights = varIdent(form = ~ 1 | year),
                      data = plot_data,
                      method = "REML")
  
  cat("  ✓ Model fit successful\n\n")
  
  # -------------------------------------------------------------------------
  # EXTRACT KEY STATISTICS
  # -------------------------------------------------------------------------
  
  # Model 1 results
  slope_simple <- fixef(lme_simple)[2]
  p_simple <- summary(lme_simple)$tTable[2, 5]
  
  # Model 2 results
  slope_varIdent <- fixef(lme_varIdent)[2]
  p_varIdent <- summary(lme_varIdent)$tTable[2, 5]
  
  cat("PARAMETER ESTIMATES:\n")
  cat(sprintf("  Simple LME:     Slope = %.6f, p = %.4f\n", slope_simple, p_simple))
  cat(sprintf("  LME varIdent:   Slope = %.6f, p = %.4f\n\n", slope_varIdent, p_varIdent))
  
  # -------------------------------------------------------------------------
  # MODEL COMPARISON CRITERIA
  # -------------------------------------------------------------------------
  
  cat("========================================\n")
  cat("MODEL COMPARISON\n")
  cat("========================================\n\n")
  
  # 1. AIC (Akaike Information Criterion) - lower is better
  aic_simple <- AIC(lme_simple)
  aic_varIdent <- AIC(lme_varIdent)
  delta_aic <- aic_varIdent - aic_simple
  
  cat("1. AIC (Akaike Information Criterion)\n")
  cat("   Lower values indicate better model fit\n")
  cat(sprintf("   Simple LME:    AIC = %.2f\n", aic_simple))
  cat(sprintf("   LME varIdent:  AIC = %.2f\n", aic_varIdent))
  cat(sprintf("   ΔAIC:          %.2f ", delta_aic))
  
  # Interpret AIC difference
  if(abs(delta_aic) < 2) {
    cat("→ Models essentially equivalent (prefer simpler)\n")
    aic_winner <- "Equivalent (prefer simple)"
  } else if(delta_aic < 0) {
    cat("→ varIdent model better\n")
    aic_winner <- "varIdent"
  } else {
    cat("→ Simple model better\n")
    aic_winner <- "Simple"
  }
  
  cat("\n   Rule of thumb:\n")
  cat("   • ΔAIC < 2:    Models essentially equivalent\n")
  cat("   • ΔAIC 2-7:    Moderate evidence for better model\n")
  cat("   • ΔAIC > 10:   Strong evidence for better model\n\n")
  
  # 2. BIC (Bayesian Information Criterion) - lower is better
  bic_simple <- BIC(lme_simple)
  bic_varIdent <- BIC(lme_varIdent)
  delta_bic <- bic_varIdent - bic_simple
  
  cat("2. BIC (Bayesian Information Criterion)\n")
  cat("   More strongly penalizes model complexity than AIC\n")
  cat(sprintf("   Simple LME:    BIC = %.2f\n", bic_simple))
  cat(sprintf("   LME varIdent:  BIC = %.2f\n", bic_varIdent))
  cat(sprintf("   ΔBIC:          %.2f ", delta_bic))
  
  if(delta_bic < 0) {
    cat("→ varIdent model better\n")
    bic_winner <- "varIdent"
  } else {
    cat("→ Simple model better\n")
    bic_winner <- "Simple"
  }
  cat("\n")
  
  # 3. Likelihood Ratio Test
  cat("3. Likelihood Ratio Test (LRT)\n")
  cat("   Formal hypothesis test comparing nested models\n")
  cat("   Requires refitting with ML instead of REML\n")
  
  # Refit with ML for LRT
  lme_simple_ml <- update(lme_simple, method = "ML")
  lme_varIdent_ml <- update(lme_varIdent, method = "ML")
  
  lrt_result <- anova(lme_simple_ml, lme_varIdent_ml)
  lrt_p <- lrt_result$`p-value`[2]
  
  cat(sprintf("   LRT p-value:   %.4f ", lrt_p))
  
  if(lrt_p < 0.05) {
    cat("→ varIdent model SIGNIFICANTLY better\n")
    lrt_winner <- "varIdent"
  } else {
    cat("→ No significant improvement with varIdent\n")
    lrt_winner <- "Simple"
  }
  
  cat("\n   Interpretation:\n")
  cat("   • p < 0.05:  varIdent significantly improves fit\n")
  cat("   • p ≥ 0.05:  No significant improvement (use simpler model)\n\n")
  
  # 4. Check autocorrelation resolution
  cat("4. Autocorrelation Check\n")
  
  # Simple model
  resid_simple <- residuals(lme_simple, type = "normalized")
  dw_simple <- dwtest(resid_simple ~ 1)
  autocorr_simple <- dw_simple$p.value > 0.05
  
  # varIdent model
  resid_varIdent <- residuals(lme_varIdent, type = "normalized")
  dw_varIdent <- dwtest(resid_varIdent ~ 1)
  autocorr_varIdent <- dw_varIdent$p.value > 0.05
  
  cat(sprintf("   Simple LME:    DW p = %.4f ", dw_simple$p.value))
  if(autocorr_simple) {
    cat("→ Autocorrelation resolved ✓\n")
  } else {
    cat("→ Autocorrelation persists ✗\n")
  }
  
  cat(sprintf("   LME varIdent:  DW p = %.4f ", dw_varIdent$p.value))
  if(autocorr_varIdent) {
    cat("→ Autocorrelation resolved ✓\n")
  } else {
    cat("→ Autocorrelation persists ✗\n")
  }
  cat("\n")
  
  # -------------------------------------------------------------------------
  # FINAL RECOMMENDATION
  # -------------------------------------------------------------------------
  
  cat("========================================\n")
  cat("RECOMMENDATION\n")
  cat("========================================\n\n")
  
  # Count votes for each model
  simple_votes <- sum(c(aic_winner %in% c("Simple", "Equivalent (prefer simple)"),
                       bic_winner == "Simple",
                       lrt_winner == "Simple"))
  
  varIdent_votes <- sum(c(aic_winner == "varIdent",
                         bic_winner == "varIdent",
                         lrt_winner == "varIdent"))
  
  cat("Criteria Summary:\n")
  cat(sprintf("  AIC:  %s\n", aic_winner))
  cat(sprintf("  BIC:  %s\n", bic_winner))
  cat(sprintf("  LRT:  %s\n", lrt_winner))
  cat("\n")
  
  if(simple_votes >= 2 && lrt_p >= 0.05) {
    recommended <- "Simple LME"
    cat("✓ RECOMMENDATION: Use SIMPLE LME\n")
    cat("  Reason: Majority of criteria favor simpler model,\n")
    cat("          and LRT shows no significant improvement with varIdent.\n")
    cat("          Principle of parsimony: prefer simpler model when equivalent.\n")
    
    # Add caveat if assumptions violated
    if(!homosced_ok) {
      cat("\n  ⚠ CAVEAT: Heteroscedasticity was detected in preliminary checks.\n")
      cat("    The simple LME does not address this. Consider:\n")
      cat("    - Reporting with caveat about heteroscedasticity\n")
      cat("    - Using the varIdent model despite AIC/BIC preferring simple\n")
      cat("    - Transforming the response variable and refitting\n")
    }
    if(!normal_ok) {
      cat("\n  ⚠ CAVEAT: Non-normal residuals detected in preliminary checks.\n")
      cat("    LME is moderately robust to this, but interpret cautiously.\n")
    }
    
  } else if(varIdent_votes >= 2 || lrt_p < 0.05) {
    recommended <- "LME with varIdent"
    cat("✓ RECOMMENDATION: Use LME with varIdent\n")
    cat("  Reason: Majority of criteria favor varIdent model,\n")
    cat("          or LRT shows significant improvement in fit.\n")
    
    if(!homosced_ok) {
      cat("  ✓ BONUS: varIdent addresses the heteroscedasticity detected!\n")
    }
    
  } else {
    recommended <- "Simple LME (tie-breaker)"
    cat("✓ RECOMMENDATION: Use SIMPLE LME (by parsimony)\n")
    cat("  Reason: Criteria are mixed, so prefer simpler model.\n")
    
    if(!homosced_ok) {
      cat("\n  ⚠ CAVEAT: But heteroscedasticity was detected.\n")
      cat("    Consider using varIdent model instead to address this.\n")
    }
  }
  
  cat("\n")
  
  # -------------------------------------------------------------------------
  # RETURN RESULTS
  # -------------------------------------------------------------------------
  
  result <- data.frame(
    flux_variable = flux_label,
    met_variable = met_label,
    n_obs = nrow(plot_data),
    
    # Assumption checks
    shapiro_p = shapiro_test$p.value,
    residuals_normal = normal_ok,
    bp_p = bp_test$p.value,
    homoscedastic = homosced_ok,
    assumptions_met = normal_ok && homosced_ok,
    
    # Simple LME
    simple_slope = slope_simple,
    simple_p = p_simple,
    simple_AIC = aic_simple,
    simple_BIC = bic_simple,
    simple_autocorr_resolved = autocorr_simple,
    
    # varIdent LME
    varIdent_slope = slope_varIdent,
    varIdent_p = p_varIdent,
    varIdent_AIC = aic_varIdent,
    varIdent_BIC = bic_varIdent,
    varIdent_autocorr_resolved = autocorr_varIdent,
    
    # Comparison
    delta_AIC = delta_aic,
    delta_BIC = delta_bic,
    LRT_p = lrt_p,
    
    # Recommendation
    recommended_model = recommended,
    
    stringsAsFactors = FALSE
  )
  
  return(result)
}

# ----------------------------------------------------------------------------
# RUN COMPARISONS FOR FC ~ VPD AND FC ~ RH
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# COMPARING LME MODELS FOR FC RELATIONSHIPS\n")
cat("############################################################\n")

# Compare FC ~ VPD
result_vpd <- compare_lme_models(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "VPD",
  flux_label = "FC",
  met_label = "VPD"
)

# Compare FC ~ RH
result_rh <- compare_lme_models(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "RH",
  flux_label = "FC",
  met_label = "RH"
)

# ----------------------------------------------------------------------------
# COMBINED SUMMARY TABLE
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# COMBINED SUMMARY TABLE\n")
cat("############################################################\n\n")

combined_results <- rbind(result_vpd, result_rh)

# Print key columns
summary_cols <- combined_results %>%
  select(met_variable, 
         simple_slope, simple_p, simple_AIC,
         varIdent_slope, varIdent_p, varIdent_AIC,
         delta_AIC, LRT_p, recommended_model)

print(summary_cols)

# ----------------------------------------------------------------------------
# SAVE RESULTS
# ----------------------------------------------------------------------------

# Uncomment to save
# write.csv(combined_results, 
#           "results/LME_model_comparison_FC.csv", 
#           row.names = FALSE)
# 
# cat("\n✓ Results saved to: results/LME_model_comparison_FC.csv\n")

# ----------------------------------------------------------------------------
# FINAL SUMMARY
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# FINAL SUMMARY\n")
cat("############################################################\n\n")

for(i in 1:nrow(combined_results)) {
  cat(sprintf("FC ~ %s:\n", combined_results$met_variable[i]))
  cat(sprintf("  Recommended: %s\n", combined_results$recommended_model[i]))
  
  if(grepl("Simple", combined_results$recommended_model[i])) {
    cat(sprintf("  Slope: %.6f (p = %.4f)\n", 
                combined_results$simple_slope[i], 
                combined_results$simple_p[i]))
  } else {
    cat(sprintf("  Slope: %.6f (p = %.4f)\n", 
                combined_results$varIdent_slope[i], 
                combined_results$varIdent_p[i]))
  }
  cat("\n")
}

cat("============================================================\n")
cat("Analysis complete!\n")
cat("============================================================\n")

```
#Visual assessment of FC ~ VPD and RH, FCH4 ~ RH which used LME but violated linear assumptions 
```{r}

library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)

# ----------------------------------------------------------------------------
# FUNCTION: Create comprehensive diagnostic plots for LME model
# ----------------------------------------------------------------------------

create_lme_diagnostics <- function(data, flux_var, met_var, 
                                   flux_label, met_label,
                                   model_description) {
  
  cat("\n========================================\n")
  cat("Creating diagnostics for:", flux_label, "~", met_label, "\n")
  cat("========================================\n\n")
  
  # Prepare data
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month) %>%
    mutate(year = as.factor(year))
  
  # Fit the simple LME model
  lme_model <- lme(flux ~ met, 
                   random = ~ 1 | year,
                   correlation = corAR1(form = ~ 1 | year),
                   data = plot_data,
                   method = "REML")
  
  # Extract residuals (normalized/standardized)
  plot_data$residuals <- residuals(lme_model, type = "normalized")
  plot_data$fitted <- fitted(lme_model)
  
  # Extract random effects for each year
  random_effects <- ranef(lme_model)
  
  # -------------------------------------------------------------------------
  # PLOT 1: QQ Plot (Normality check)
  # -------------------------------------------------------------------------
  
  p1 <- ggplot(plot_data, aes(sample = residuals)) +
    stat_qq(color = "#377EB8", size = 2, alpha = 0.7) +
    stat_qq_line(color = "red", linetype = "dashed", linewidth = 1) +
    labs(
      title = "QQ Plot: Normality of Residuals",
      subtitle = "Points should fall along the red line if normally distributed",
      x = "Theoretical Quantiles",
      y = "Sample Quantiles (Standardized Residuals)"
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      plot.subtitle = element_text(size = 10, color = "gray30")
    )
  
  # -------------------------------------------------------------------------
  # PLOT 2: Histogram of Residuals (Normality check)
  # -------------------------------------------------------------------------
  
  p2 <- ggplot(plot_data, aes(x = residuals)) +
    geom_histogram(aes(y = after_stat(density)), 
                   bins = 15, 
                   fill = "#377EB8", 
                   color = "white", 
                   alpha = 0.7) +
    geom_density(color = "red", linewidth = 1) +
    stat_function(fun = dnorm, 
                  args = list(mean = mean(plot_data$residuals), 
                             sd = sd(plot_data$residuals)),
                  color = "black", 
                  linetype = "dashed",
                  linewidth = 1) +
    labs(
      title = "Histogram of Residuals",
      subtitle = "Red = actual density; Black dashed = normal distribution",
      x = "Standardized Residuals",
      y = "Density"
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      plot.subtitle = element_text(size = 10, color = "gray30")
    )
  
  # -------------------------------------------------------------------------
  # PLOT 3: Residuals vs Fitted (Homoscedasticity check)
  # -------------------------------------------------------------------------
  
  p3 <- ggplot(plot_data, aes(x = fitted, y = residuals)) +
    geom_point(aes(color = year), size = 2.5, alpha = 0.7) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
    geom_smooth(method = "loess", se = TRUE, 
                color = "blue", fill = "lightblue", alpha = 0.2) +
    scale_color_manual(
      values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                 "2019" = "#4DAF4A", "2020" = "#984EA3", 
                 "2021" = "#FF7F00", "2022" = "#A65628"),
      name = "Year"
    ) +
    labs(
      title = "Residuals vs Fitted Values",
      subtitle = "Should show random scatter around zero with constant spread",
      x = "Fitted Values",
      y = "Standardized Residuals"
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      plot.subtitle = element_text(size = 10, color = "gray30"),
      legend.position = "right"
    )
  
  # -------------------------------------------------------------------------
  # PLOT 4: Scale-Location Plot (Homoscedasticity check)
  # -------------------------------------------------------------------------
  
  plot_data$sqrt_abs_resid <- sqrt(abs(plot_data$residuals))
  
  p4 <- ggplot(plot_data, aes(x = fitted, y = sqrt_abs_resid)) +
    geom_point(aes(color = year), size = 2.5, alpha = 0.7) +
    geom_smooth(method = "loess", se = TRUE, 
                color = "red", fill = "pink", alpha = 0.2) +
    scale_color_manual(
      values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                 "2019" = "#4DAF4A", "2020" = "#984EA3", 
                 "2021" = "#FF7F00", "2022" = "#A65628"),
      name = "Year"
    ) +
    labs(
      title = "Scale-Location Plot",
      subtitle = "Red line should be horizontal if variance is constant",
      x = "Fitted Values",
      y = expression(sqrt("|Standardized Residuals|"))
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      plot.subtitle = element_text(size = 10, color = "gray30"),
      legend.position = "right"
    )
  
  # -------------------------------------------------------------------------
  # PLOT 5: Residuals vs Predictor (Pattern check)
  # -------------------------------------------------------------------------
  
  p5 <- ggplot(plot_data, aes(x = met, y = residuals)) +
    geom_point(aes(color = year), size = 2.5, alpha = 0.7) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red", linewidth = 1) +
    geom_smooth(method = "loess", se = TRUE, 
                color = "blue", fill = "lightblue", alpha = 0.2) +
    scale_color_manual(
      values = c("2017" = "#E41A1C", "2018" = "#377EB8", 
                 "2019" = "#4DAF4A", "2020" = "#984EA3", 
                 "2021" = "#FF7F00", "2022" = "#A65628"),
      name = "Year"
    ) +
    labs(
      title = "Residuals vs Predictor",
      subtitle = "Should show random scatter with no pattern",
      x = met_label,
      y = "Standardized Residuals"
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      plot.subtitle = element_text(size = 10, color = "gray30"),
      legend.position = "right"
    )
  
  # -------------------------------------------------------------------------
  # PLOT 6: Random Effects by Year (Year-to-year variation)
  # -------------------------------------------------------------------------
  
  random_effects_df <- data.frame(
    year = rownames(random_effects),
    intercept = random_effects[, 1]
  ) %>%
    mutate(year = factor(year, levels = sort(unique(plot_data$year))))
  
  p6 <- ggplot(random_effects_df, aes(x = year, y = intercept)) +
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray50") +
    geom_point(size = 4, color = "#377EB8") +
    geom_segment(aes(xend = year, y = 0, yend = intercept), 
                 color = "#377EB8", linewidth = 1) +
    labs(
      title = "Random Year Effects",
      subtitle = "Deviation of each year from overall mean",
      x = "Year",
      y = "Random Intercept"
    ) +
    theme_bw(base_size = 12) +
    theme(
      plot.title = element_text(face = "bold", size = 13),
      plot.subtitle = element_text(size = 10, color = "gray30")
    )
  
  # -------------------------------------------------------------------------
  # COMBINE ALL PLOTS
  # -------------------------------------------------------------------------
  
  # Create title
  main_title <- textGrob(
    paste0(flux_label, " ~ ", met_label, ": ", model_description),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  # Arrange plots in a 3x2 grid
  combined_plot <- grid.arrange(
    p1, p2,
    p3, p4,
    p5, p6,
    ncol = 2,
    top = main_title
  )
  
  # -------------------------------------------------------------------------
  # INTERPRETATION GUIDE
  # -------------------------------------------------------------------------
  
  cat("\n=== INTERPRETATION GUIDE ===\n\n")
  
  cat("QQ PLOT (Top-left):\n")
  cat("  ✓ Good: Points follow the red dashed line closely\n")
  cat("  ✗ Bad:  Points deviate systematically (S-curve, heavy tails, skewness)\n\n")
  
  cat("HISTOGRAM (Top-right):\n")
  cat("  ✓ Good: Red curve (actual) matches black dashed (normal)\n")
  cat("  ✗ Bad:  Skewed, bimodal, or heavy-tailed distribution\n\n")
  
  cat("RESIDUALS vs FITTED (Middle-left):\n")
  cat("  ✓ Good: Random scatter around zero, constant spread\n")
  cat("  ✗ Bad:  Funnel shape (heteroscedasticity), curved pattern (non-linearity)\n\n")
  
  cat("SCALE-LOCATION (Middle-right):\n")
  cat("  ✓ Good: Red line is roughly horizontal\n")
  cat("  ✗ Bad:  Red line trends up/down (variance increases/decreases)\n\n")
  
  cat("RESIDUALS vs PREDICTOR (Bottom-left):\n")
  cat("  ✓ Good: Random scatter, no pattern\n")
  cat("  ✗ Bad:  Curved pattern suggests non-linear relationship\n\n")
  
  cat("RANDOM EFFECTS (Bottom-right):\n")
  cat("  Shows how much each year deviates from overall mean\n")
  cat("  Larger deviations = more year-to-year variation\n\n")
  
  return(combined_plot)
}

# ----------------------------------------------------------------------------
# CREATE DIAGNOSTICS FOR FC ~ VPD
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# DIAGNOSTIC PLOTS FOR FC ~ VPD\n")
cat("############################################################\n")

diagnostics_vpd <- create_lme_diagnostics(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "VPD",
  flux_label = "FC",
  met_label = "VPD",
  model_description = "LME with random year + AR(1)"
)

# Save plot (commented out)
# ggsave("figures/diagnostics_FC_VPD.png", 
#        plot = diagnostics_vpd, 
#        width = 12, height = 14, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# CREATE DIAGNOSTICS FOR FC ~ RH
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# DIAGNOSTIC PLOTS FOR FC ~ RH\n")
cat("############################################################\n")

diagnostics_rh <- create_lme_diagnostics(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "RH",
  flux_label = "FC",
  met_label = "RH",
  model_description = "LME with random year + AR(1)"
)

# Save plot (commented out)
# ggsave("figures/diagnostics_FC_RH.png", 
#        plot = diagnostics_rh, 
#        width = 12, height = 14, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# CREATE DIAGNOSTICS FOR FCH4 ~ RH
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# DIAGNOSTIC PLOTS FOR FCH4 ~ RH\n")
cat("############################################################\n")

diagnostics_fch4_rh <- create_lme_diagnostics(
  data = df_monthly_FCH4,
  flux_var = "FCH4",
  met_var = "RH",
  flux_label = "FCH4",
  met_label = "RH",
  model_description = "LME with random year + AR(1)"
)

# Save plot (commented out)
# ggsave("figures/diagnostics_FCH4_RH.png", 
#        plot = diagnostics_fch4_rh, 
#        width = 12, height = 14, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# PRINT MODEL SUMMARIES
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# MODEL SUMMARIES\n")
cat("############################################################\n\n")

# Prepare data for VPD
vpd_data <- df_monthly_FC %>%
  select(year, month, flux = FC, met = VPD) %>%
  filter(complete.cases(.)) %>%
  arrange(year, month) %>%
  mutate(year = as.factor(year))

lme_vpd <- lme(flux ~ met, 
               random = ~ 1 | year,
               correlation = corAR1(form = ~ 1 | year),
               data = vpd_data,
               method = "REML")

cat("=== FC ~ VPD MODEL SUMMARY ===\n")
print(summary(lme_vpd))

cat("\n\n")

# Prepare data for RH
rh_data <- df_monthly_FC %>%
  select(year, month, flux = FC, met = RH) %>%
  filter(complete.cases(.)) %>%
  arrange(year, month) %>%
  mutate(year = as.factor(year))

lme_rh <- lme(flux ~ met, 
              random = ~ 1 | year,
              correlation = corAR1(form = ~ 1 | year),
              data = rh_data,
              method = "REML")

cat("=== FC ~ RH MODEL SUMMARY ===\n")
print(summary(lme_rh))

cat("\n\n")

# Prepare data for FCH4 ~ RH
fch4_rh_data <- df_monthly_FCH4 %>%
  select(year, month, flux = FCH4, met = RH) %>%
  filter(complete.cases(.)) %>%
  arrange(year, month) %>%
  mutate(year = as.factor(year))

lme_fch4_rh <- lme(flux ~ met, 
                   random = ~ 1 | year,
                   correlation = corAR1(form = ~ 1 | year),
                   data = fch4_rh_data,
                   method = "REML")

cat("=== FCH4 ~ RH MODEL SUMMARY ===\n")
print(summary(lme_fch4_rh))


```
#Kendall's tau for FCH4~RH
```{r}
# Non-parametric test that doesn't assume normality
cor.test(fch4_rh_data$met, fch4_rh_data$flux, method = "kendall")

```
#compare weighted gls and lme for FCH4~RH

```{r}
# Prepare data
fch4_rh_data <- df_monthly_FCH4 %>%
  select(year, month, flux = FCH4, met = RH) %>%
  filter(complete.cases(.)) %>%
  arrange(year, month) %>%
  mutate(year = as.factor(year))

# Model 1: Simple LME (what you've been using)
lme_model <- lme(flux ~ met, 
                 random = ~ 1 | year,
                 correlation = corAR1(form = ~ 1 | year),
                 data = fch4_rh_data,
                 method = "REML")

# Model 2: Weighted GLS (the one that found significance)
weighted_gls <- gls(flux ~ met, 
                    data = fch4_rh_data,
                    weights = varIdent(form = ~ 1 | year),
                    correlation = corAR1(form = ~ 1),
                    method = "REML")


VarCorr(lme_model)


# Compare
cat("LME Results:\n")
summary(lme_model)$tTable[2, c(1,5)]  # slope and p-value

cat("\nWeighted GLS Results:\n")
summary(weighted_gls)$tTable[2, c(1,4)]  # slope and p-value

# Compare AIC
cat("\nModel Comparison:\n")
cat("LME AIC:", AIC(lme_model), "\n")
cat("GLS AIC:", AIC(weighted_gls), "\n")

# Check residuals for both
cat("\nResidual checks:\n")
cat("LME residuals normality:", shapiro.test(residuals(lme_model, type = "normalized"))$p.value, "\n")
cat("GLS residuals normality:", shapiro.test(residuals(weighted_gls, type = "normalized"))$p.value, "\n")
```
#Comparing gls, weighted gls, and lme models for FC~ VPD, RH
```{r}


library(tidyverse)
library(nlme)
library(lmtest)

# ----------------------------------------------------------------------------
# FUNCTION: Compare LME vs GLS for a single relationship
# ----------------------------------------------------------------------------

compare_lme_vs_gls <- function(data, flux_var, met_var, 
                               flux_label, met_label) {
  
  cat("\n############################################################\n")
  cat("# COMPARING LME vs GLS:", flux_label, "~", met_label, "\n")
  cat("############################################################\n\n")
  
  # Prepare data
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month) %>%
    mutate(year = as.factor(year))
  
  cat("Number of observations:", nrow(plot_data), "\n\n")
  
  # -------------------------------------------------------------------------
  # Check basic assumptions on linear model
  # -------------------------------------------------------------------------
  
  cat("=== PRELIMINARY ASSUMPTION CHECKS ===\n\n")
  
  lm_model <- lm(flux ~ met, data = plot_data)
  
  shapiro_test <- shapiro.test(residuals(lm_model))
  bp_test <- bptest(lm_model)
  dw_test <- dwtest(lm_model)
  
  cat(sprintf("Shapiro-Wilk (normality):        p = %.4f", shapiro_test$p.value))
  if(shapiro_test$p.value > 0.05) {
    cat(" ✓ Normal\n")
    normal_ok <- TRUE
  } else {
    cat(" ✗ Non-normal\n")
    normal_ok <- FALSE
  }
  
  cat(sprintf("Breusch-Pagan (homoscedasticity): p = %.4f", bp_test$p.value))
  if(bp_test$p.value > 0.05) {
    cat(" ✓ Homoscedastic\n")
    homosced_ok <- TRUE
  } else {
    cat(" ✗ Heteroscedastic\n")
    homosced_ok <- FALSE
  }
  
  cat(sprintf("Durbin-Watson (autocorrelation):  p = %.4f", dw_test$p.value))
  if(dw_test$p.value > 0.05) {
    cat(" ✓ No autocorrelation\n")
    autocorr_ok <- TRUE
  } else {
    cat(" ✗ Autocorrelation detected\n")
    autocorr_ok <- FALSE
  }
  
  cat("\n")
  
  # -------------------------------------------------------------------------
  # MODEL 1: Simple LME (random year + AR1)
  # -------------------------------------------------------------------------
  
  cat("=== MODEL 1: LME with Random Year + AR(1) ===\n")
  cat("Structure: random intercept by year + AR(1) within years\n\n")
  
  lme_simple <- lme(flux ~ met, 
                    random = ~ 1 | year,
                    correlation = corAR1(form = ~ 1 | year),
                    data = plot_data,
                    method = "REML")
  
  # Extract results
  lme_slope <- fixef(lme_simple)[2]
  lme_p <- summary(lme_simple)$tTable[2, 5]
  lme_aic <- AIC(lme_simple)
  lme_bic <- BIC(lme_simple)
  
  # Check random effect variance
  lme_variances <- VarCorr(lme_simple)
  random_year_var <- as.numeric(lme_variances[1, 1])
  random_year_sd <- as.numeric(lme_variances[1, 2])
  residual_sd <- as.numeric(lme_variances[2, 2])
  
  cat(sprintf("Slope:                    %.6f\n", lme_slope))
  cat(sprintf("P-value:                  %.4f", lme_p))
  if(lme_p < 0.05) {
    cat(" *** SIGNIFICANT\n")
  } else {
    cat(" (not significant)\n")
  }
  cat(sprintf("AIC:                      %.2f\n", lme_aic))
  cat(sprintf("BIC:                      %.2f\n", lme_bic))
  cat(sprintf("Random year SD:           %.6f\n", random_year_sd))
  cat(sprintf("Residual SD:              %.6f\n", residual_sd))
  cat(sprintf("Ratio (year/residual):    %.4f\n", random_year_sd / residual_sd))
  
  # Check autocorrelation
  lme_resid <- residuals(lme_simple, type = "normalized")
  lme_dw <- dwtest(lme_resid ~ 1)
  cat(sprintf("Autocorrelation resolved: DW p = %.4f", lme_dw$p.value))
  if(lme_dw$p.value > 0.05) {
    cat(" ✓\n")
    lme_autocorr_ok <- TRUE
  } else {
    cat(" ✗\n")
    lme_autocorr_ok <- FALSE
  }
  
  # Check normality
  lme_shapiro <- shapiro.test(lme_resid)
  cat(sprintf("Residuals normal:         p = %.4f", lme_shapiro$p.value))
  if(lme_shapiro$p.value > 0.05) {
    cat(" ✓\n\n")
    lme_normal_ok <- TRUE
  } else {
    cat(" ✗\n\n")
    lme_normal_ok <- FALSE
  }
  
  # -------------------------------------------------------------------------
  # MODEL 2: Weighted GLS (varIdent by year + AR1)
  # -------------------------------------------------------------------------
  
  cat("=== MODEL 2: Weighted GLS with varIdent + AR(1) ===\n")
  cat("Structure: year-specific variances + AR(1) across all time\n\n")
  
  gls_weighted <- gls(flux ~ met, 
                      data = plot_data,
                      weights = varIdent(form = ~ 1 | year),
                      correlation = corAR1(form = ~ 1),
                      method = "REML")
  
  # Extract results
  gls_slope <- coef(gls_weighted)[2]
  gls_p <- summary(gls_weighted)$tTable[2, 4]
  gls_aic <- AIC(gls_weighted)
  gls_bic <- BIC(gls_weighted)
  
  cat(sprintf("Slope:                    %.6f\n", gls_slope))
  cat(sprintf("P-value:                  %.4f", gls_p))
  if(gls_p < 0.05) {
    cat(" *** SIGNIFICANT\n")
  } else {
    cat(" (not significant)\n")
  }
  cat(sprintf("AIC:                      %.2f\n", gls_aic))
  cat(sprintf("BIC:                      %.2f\n", gls_bic))
  
  # Check autocorrelation
  gls_resid <- residuals(gls_weighted, type = "normalized")
  gls_dw <- dwtest(gls_resid ~ 1)
  cat(sprintf("Autocorrelation resolved: DW p = %.4f", gls_dw$p.value))
  if(gls_dw$p.value > 0.05) {
    cat(" ✓\n")
    gls_autocorr_ok <- TRUE
  } else {
    cat(" ✗\n")
    gls_autocorr_ok <- FALSE
  }
  
  # Check normality
  gls_shapiro <- shapiro.test(gls_resid)
  cat(sprintf("Residuals normal:         p = %.4f", gls_shapiro$p.value))
  if(gls_shapiro$p.value > 0.05) {
    cat(" ✓\n\n")
    gls_normal_ok <- TRUE
  } else {
    cat(" ✗\n\n")
    gls_normal_ok <- FALSE
  }
  
  # -------------------------------------------------------------------------
  # MODEL 3: Simple GLS (just AR1, no weights)
  # -------------------------------------------------------------------------
  
  cat("=== MODEL 3: Simple GLS with AR(1) only ===\n")
  cat("Structure: constant variance + AR(1) across all time\n")
  cat("Note: AR(1) is continuous (form = ~ 1), NOT year-specific\n\n")
  
  gls_simple <- gls(flux ~ met, 
                    data = plot_data,
                    correlation = corAR1(form = ~ 1),  # Cannot use | year in GLS
                    method = "REML")
  
  # Extract results
  gls_simple_slope <- coef(gls_simple)[2]
  gls_simple_p <- summary(gls_simple)$tTable[2, 4]
  gls_simple_aic <- AIC(gls_simple)
  gls_simple_bic <- BIC(gls_simple)
  
  cat(sprintf("Slope:                    %.6f\n", gls_simple_slope))
  cat(sprintf("P-value:                  %.4f", gls_simple_p))
  if(gls_simple_p < 0.05) {
    cat(" *** SIGNIFICANT\n")
  } else {
    cat(" (not significant)\n")
  }
  cat(sprintf("AIC:                      %.2f\n", gls_simple_aic))
  cat(sprintf("BIC:                      %.2f\n", gls_simple_bic))
  
  # Check autocorrelation
  gls_simple_resid <- residuals(gls_simple, type = "normalized")
  gls_simple_dw <- dwtest(gls_simple_resid ~ 1)
  cat(sprintf("Autocorrelation resolved: DW p = %.4f", gls_simple_dw$p.value))
  if(gls_simple_dw$p.value > 0.05) {
    cat(" ✓\n")
    gls_simple_autocorr_ok <- TRUE
  } else {
    cat(" ✗\n")
    gls_simple_autocorr_ok <- FALSE
  }
  
  # Check normality
  gls_simple_shapiro <- shapiro.test(gls_simple_resid)
  cat(sprintf("Residuals normal:         p = %.4f", gls_simple_shapiro$p.value))
  if(gls_simple_shapiro$p.value > 0.05) {
    cat(" ✓\n\n")
    gls_simple_normal_ok <- TRUE
  } else {
    cat(" ✗\n\n")
    gls_simple_normal_ok <- FALSE
  }
  
  # -------------------------------------------------------------------------
  # COMPARISON
  # -------------------------------------------------------------------------
  
  cat("=== MODEL COMPARISON (3-way) ===\n\n")
  
  cat("Model                          AIC      BIC      Slope      P-value\n")
  cat("----------------------------------------------------------------\n")
  cat(sprintf("1. LME (random year + AR1)    %.2f   %.2f   %.6f   %.4f", 
              lme_aic, lme_bic, lme_slope, lme_p))
  if(lme_p < 0.05) cat(" ***") 
  cat("\n")
  cat(sprintf("2. Weighted GLS (varIdent+AR) %.2f   %.2f   %.6f   %.4f", 
              gls_aic, gls_bic, gls_slope, gls_p))
  if(gls_p < 0.05) cat(" ***")
  cat("\n")
  cat(sprintf("3. Simple GLS (AR1 only)      %.2f   %.2f   %.6f   %.4f", 
              gls_simple_aic, gls_simple_bic, gls_simple_slope, gls_simple_p))
  if(gls_simple_p < 0.05) cat(" ***")
  cat("\n\n")
  
  # Find best AIC
  aic_values <- c(lme_aic, gls_aic, gls_simple_aic)
  aic_names <- c("LME", "Weighted GLS", "Simple GLS")
  best_aic_idx <- which.min(aic_values)
  
  cat(sprintf("Best AIC: %s (%.2f)\n", aic_names[best_aic_idx], aic_values[best_aic_idx]))
  
  # Find best BIC
  bic_values <- c(lme_bic, gls_bic, gls_simple_bic)
  bic_names <- c("LME", "Weighted GLS", "Simple GLS")
  best_bic_idx <- which.min(bic_values)
  
  cat(sprintf("Best BIC: %s (%.2f)\n\n", bic_names[best_bic_idx], bic_values[best_bic_idx]))
  
  # AIC comparison
  delta_aic <- gls_aic - lme_aic
  cat(sprintf("AIC Difference (GLS - LME): %.2f\n", delta_aic))
  if(abs(delta_aic) < 2) {
    cat("  → Models essentially equivalent\n")
    aic_winner <- "Equivalent"
  } else if(delta_aic < 0) {
    cat("  → GLS better (lower AIC)\n")
    aic_winner <- "GLS"
  } else {
    cat("  → LME better (lower AIC)\n")
    aic_winner <- "LME"
  }
  
  # BIC comparison
  delta_bic <- gls_bic - lme_bic
  cat(sprintf("BIC Difference (GLS - LME): %.2f\n", delta_bic))
  if(abs(delta_bic) < 2) {
    cat("  → Models essentially equivalent\n")
    bic_winner <- "Equivalent"
  } else if(delta_bic < 0) {
    cat("  → GLS better (lower BIC)\n")
    bic_winner <- "GLS"
  } else {
    cat("  → LME better (lower BIC)\n")
    bic_winner <- "LME"
  }
  
  cat("\n")
  
  # Slope comparison
  cat(sprintf("Slope Comparison:\n"))
  cat(sprintf("  LME: %.6f (p = %.4f)\n", lme_slope, lme_p))
  cat(sprintf("  GLS: %.6f (p = %.4f)\n", gls_slope, gls_p))
  cat(sprintf("  Difference: %.6f (%.1f%% change)\n", 
              gls_slope - lme_slope, 
              abs((gls_slope - lme_slope) / lme_slope * 100)))
  
  # Significance agreement
  lme_sig <- lme_p < 0.05
  gls_sig <- gls_p < 0.05
  
  if(lme_sig == gls_sig) {
    if(lme_sig) {
      cat("  ✓ Both models agree: SIGNIFICANT\n\n")
    } else {
      cat("  ✓ Both models agree: NOT SIGNIFICANT\n\n")
    }
    agreement <- "Agree"
  } else {
    cat("  ✗ MODELS DISAGREE on significance!\n")
    cat("    This is a red flag - interpret cautiously\n\n")
    agreement <- "Disagree"
  }
  
  # -------------------------------------------------------------------------
  # RANDOM EFFECT ASSESSMENT
  # -------------------------------------------------------------------------
  
  cat("=== RANDOM EFFECT NECESSITY ===\n\n")
  
  ratio <- random_year_sd / residual_sd
  
  cat(sprintf("Random year SD / Residual SD = %.4f\n\n", ratio))
  
  if(ratio < 0.01) {
    cat("  → Random year effect is NEGLIGIBLE (< 1% of residual variation)\n")
    cat("  → GLS (without random effects) is more appropriate\n")
    cat("  → Random effect is not adding meaningful information\n\n")
    random_needed <- "No - GLS preferred"
  } else if(ratio < 0.1) {
    cat("  → Random year effect is SMALL (< 10% of residual variation)\n")
    cat("  → GLS may be sufficient, but LME is defensible\n")
    cat("  → Choice depends on conceptual considerations\n\n")
    random_needed <- "Marginal"
  } else if(ratio < 0.3) {
    cat("  → Random year effect is MODERATE (10-30% of residual variation)\n")
    cat("  → LME is appropriate if you want to generalize beyond these years\n")
    cat("  → Random effects are meaningful\n\n")
    random_needed <- "Yes - LME preferred"
  } else {
    cat("  → Random year effect is SUBSTANTIAL (> 30% of residual variation)\n")
    cat("  → LME is strongly preferred\n")
    cat("  → Random effects are clearly important\n\n")
    random_needed <- "Yes - LME strongly preferred"
  }
  
  # -------------------------------------------------------------------------
  # LIKELIHOOD RATIO TEST
  # -------------------------------------------------------------------------
  
  cat("=== LIKELIHOOD RATIO TEST ===\n\n")
  
  # Refit with ML for LRT
  lme_ml <- update(lme_simple, method = "ML")
  gls_ml <- update(gls_weighted, method = "ML")
  
  lrt <- anova(gls_ml, lme_ml)
  lrt_p <- lrt$`p-value`[2]
  
  cat("Testing: Does adding random year effect improve fit?\n")
  cat(sprintf("LRT p-value: %.4f\n\n", lrt_p))
  
  if(lrt_p < 0.05) {
    cat("  → YES, random year effect significantly improves fit\n")
    cat("  → Use LME\n\n")
    lrt_winner <- "LME"
  } else {
    cat("  → NO, random year effect does not significantly improve fit\n")
    cat("  → Use GLS (simpler model)\n\n")
    lrt_winner <- "GLS"
  }
  
  # -------------------------------------------------------------------------
  # FINAL RECOMMENDATION
  # -------------------------------------------------------------------------
  
  cat("=== FINAL RECOMMENDATION ===\n\n")
  
  # Count evidence
  evidence_for_lme <- sum(c(
    aic_winner == "LME",
    bic_winner == "LME",
    lrt_winner == "LME",
    ratio >= 0.1
  ))
  
  evidence_for_gls <- sum(c(
    aic_winner == "GLS",
    bic_winner == "GLS",
    lrt_winner == "GLS",
    ratio < 0.1
  ))
  
  cat("Evidence Summary:\n")
  cat(sprintf("  AIC:               %s\n", aic_winner))
  cat(sprintf("  BIC:               %s\n", bic_winner))
  cat(sprintf("  LRT:               %s\n", lrt_winner))
  cat(sprintf("  Random effect:     %s\n", random_needed))
  cat(sprintf("  Significance:      %s\n\n", agreement))
  
  if(agreement == "Disagree") {
    cat("⚠ WARNING: Models disagree on significance!\n")
    cat("  This suggests model structure uncertainty.\n")
    cat("  Consider reporting as inconclusive or use the more conservative result.\n\n")
    recommended <- "UNCERTAIN - use conservative approach"
  } else if(evidence_for_gls > evidence_for_lme) {
    cat("✓ RECOMMENDATION: Use WEIGHTED GLS\n")
    cat(sprintf("  Slope = %.6f, p = %.4f\n", gls_slope, gls_p))
    cat("  Reason: Majority of criteria favor GLS, and random year effect\n")
    cat("          is not adding meaningful information.\n\n")
    recommended <- "Weighted GLS"
  } else if(evidence_for_lme > evidence_for_gls) {
    cat("✓ RECOMMENDATION: Use LME\n")
    cat(sprintf("  Slope = %.6f, p = %.4f\n", lme_slope, lme_p))
    cat("  Reason: Majority of criteria favor LME, and random year effect\n")
    cat("          explains meaningful between-year variation.\n\n")
    recommended <- "LME"
  } else {
    cat("✓ RECOMMENDATION: Use LME (by parsimony and consistency)\n")
    cat(sprintf("  Slope = %.6f, p = %.4f\n", lme_slope, lme_p))
    cat("  Reason: Evidence is mixed. LME is preferred for consistency with\n")
    cat("          other analyses and conceptual appropriateness of random effects.\n\n")
    recommended <- "LME (tie-breaker)"
  }
  
  # -------------------------------------------------------------------------
  # RETURN RESULTS
  # -------------------------------------------------------------------------
  
  result <- data.frame(
    flux_variable = flux_label,
    met_variable = met_label,
    n_obs = nrow(plot_data),
    
    # Assumption checks
    shapiro_p = shapiro_test$p.value,
    residuals_normal = normal_ok,
    bp_p = bp_test$p.value,
    homoscedastic = homosced_ok,
    dw_p = dw_test$p.value,
    autocorr_detected = !autocorr_ok,
    
    # LME results
    lme_slope = lme_slope,
    lme_p = lme_p,
    lme_aic = lme_aic,
    lme_bic = lme_bic,
    lme_random_year_sd = random_year_sd,
    lme_residual_sd = residual_sd,
    lme_random_ratio = ratio,
    lme_autocorr_resolved = lme_autocorr_ok,
    lme_residuals_normal = lme_normal_ok,
    
    # GLS results
    gls_slope = gls_slope,
    gls_p = gls_p,
    gls_aic = gls_aic,
    gls_bic = gls_bic,
    gls_autocorr_resolved = gls_autocorr_ok,
    gls_residuals_normal = gls_normal_ok,
    
    # Simple GLS results
    gls_simple_slope = gls_simple_slope,
    gls_simple_p = gls_simple_p,
    gls_simple_aic = gls_simple_aic,
    gls_simple_bic = gls_simple_bic,
    gls_simple_autocorr_resolved = gls_simple_autocorr_ok,
    gls_simple_residuals_normal = gls_simple_normal_ok,
    
    # Comparison
    delta_aic = delta_aic,
    delta_bic = delta_bic,
    lrt_p = lrt_p,
    models_agree = agreement,
    
    # Recommendation
    recommended_model = recommended,
    
    stringsAsFactors = FALSE
  )
  
  return(result)
}

# ----------------------------------------------------------------------------
# RUN COMPARISONS
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# LME vs GLS COMPARISON FOR FC RELATIONSHIPS\n")
cat("############################################################\n")

# FC ~ VPD
result_vpd <- compare_lme_vs_gls(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "VPD",
  flux_label = "FC",
  met_label = "VPD"
)

# FC ~ RH
result_rh <- compare_lme_vs_gls(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "RH",
  flux_label = "FC",
  met_label = "RH"
)

# ----------------------------------------------------------------------------
# COMBINED SUMMARY
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# COMBINED SUMMARY TABLE\n")
cat("############################################################\n\n")

combined_results <- rbind(result_vpd, result_rh)

# Print key comparison columns
summary_table <- combined_results %>%
  select(met_variable,
         lme_slope, lme_p, lme_aic, lme_random_ratio,
         gls_slope, gls_p, gls_aic,
         delta_aic, lrt_p, models_agree, recommended_model)

print(summary_table)

# Save results (commented out)
# write.csv(combined_results, 
#           "results/LME_vs_GLS_comparison_FC.csv", 
#           row.names = FALSE)

cat("\n############################################################\n")
cat("# ANALYSIS COMPLETE\n")
cat("############################################################\n")
```
#Figures for paper: final 

#Making final figures with updated stats*****
```{r}
# ============================================================================
# Significant Monotonic Flux Relationships
# ============================================================================


library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)

# Define custom year colors (consistent with all analyses)
year_colors <- c(
  "2017" = "#E41A1C",  # Red
  "2018" = "#377EB8",  # Blue
  "2019" = "#4DAF4A",  # Green
  "2020" = "#984EA3",  # Purple
  "2021" = "#FF7F00",  # Orange
  "2022" = "#A65628"   # Brown
)

# ----------------------------------------------------------------------------
# FUNCTION: Create publication-quality plot with stats
# ----------------------------------------------------------------------------

create_flux_plot <- function(data, flux_var, met_var, 
                             flux_label, met_label, met_units,
                             model_type = "lm") {
  
  # Prepare data
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month) %>%
    mutate(year = as.factor(year))
  
  # -------------------------------------------------------------------------
  # Fit appropriate model and extract statistics
  # -------------------------------------------------------------------------
  
  if(model_type == "lm") {
    # Linear regression (REML)
    model <- lm(flux ~ met, data = plot_data)
    slope <- coef(model)[2]
    p_value <- summary(model)$coefficients[2, 4]
    r_squared <- summary(model)$r.squared
    model_name <- "Linear Regression"
    line_color <- "#377EB8"  # Blue for linear regression
    
  } else if(model_type == "gls") {
    # GLS with AR(1) correlation structure
    model <- gls(flux ~ met, 
                 data = plot_data,
                 correlation = corAR1(form = ~ 1),
                 method = "REML")
    slope <- coef(model)[2]
    p_value <- summary(model)$tTable[2, 4]
    
    # Calculate pseudo-R² for GLS (correlation-based)
    fitted_vals <- fitted(model)
    r_squared <- cor(plot_data$flux, fitted_vals)^2
    
    model_name <- "GLS with AR(1)"
    line_color <- "#4DAF4A"  # Green for GLS
    
  } else {
    stop("model_type must be 'lm' or 'gls'")
  }
  
  # Get fitted values for plotting the line
  plot_data$fitted <- fitted(model)
  
  # -------------------------------------------------------------------------
  # Create the plot
  # -------------------------------------------------------------------------
  
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    
    # Add fitted line
    geom_line(aes(y = fitted), color = line_color, linewidth = 1.2) +
    
    # Add points colored by year
    geom_point(aes(color = year), size = 3, alpha = 0.8) +
    
    # Apply custom year colors
    scale_color_manual(
      values = year_colors,
      name = "Year"
    ) +
    
    # Labels
    labs(
      x = paste0(met_label, " (", met_units, ")"),
      y = flux_label
    ) +
    
    # Theme
    theme_bw(base_size = 13) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = c(0.85, 0.85),  # Top right inside plot
      legend.background = element_rect(fill = "white", color = "black", linewidth = 0.3),
      legend.title = element_text(size = 11, face = "bold"),
      legend.text = element_text(size = 9),
      legend.key.size = unit(0.7, "lines"),
      plot.margin = margin(10, 10, 10, 10),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text = element_text(size = 11)
    )
  
  # -------------------------------------------------------------------------
  # Add statistics box in upper left
  # -------------------------------------------------------------------------
  
  # Format p-value
  if(p_value < 0.001) {
    p_text <- "p < 0.001"
  } else if(p_value < 0.01) {
    p_text <- sprintf("p = %.3f", p_value)
  } else {
    p_text <- sprintf("p = %.2f", p_value)
  }
  
  # Create statistics text
  stats_text <- paste0(
    model_name, "\n",
    "R² = ", sprintf("%.3f", r_squared), "\n",
    "Slope = ", sprintf("%.4f", slope), "\n",
    p_text
  )
  
  # Add text annotation in upper left corner
  # Find good position based on data range
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  x_pos <- x_range[1] + 0.05 * diff(x_range)
  y_pos <- y_range[2] - 0.05 * diff(y_range)
  
  p <- p +
    annotate("text", 
             x = x_pos, 
             y = y_pos, 
             label = stats_text,
             hjust = 0,
             vjust = 1,
             size = 3.5,
             fontface = "plain",
             color = "black",
             lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# CREATE ALL PLOTS
# ----------------------------------------------------------------------------

cat("\n=== Creating publication-quality figures ===\n\n")

# FC ~ Air Temperature (GLS with AR1)
cat("1. FC ~ Air Temperature (GLS with AR1)\n")
p1 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TA_gapfilled",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Air Temperature GF",
  met_units = "°C",
  model_type = "gls"
)

# FC ~ Soil Temperature (Linear Regression)
cat("2. FC ~ Soil Temperature (Linear Regression)\n")
p2 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TS_3_gapfilled",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Soil Temperature GF",
  met_units = "°C",
  model_type = "lm"
)

# FC ~ VPD (GLS with AR1)
cat("3. FC ~ VPD (GLS with AR1)\n")
p3 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "VPD",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "VPD",
  met_units = "hPa",
  model_type = "gls"
)

# FC ~ RH (GLS with AR1)
cat("4. FC ~ RH (GLS with AR1)\n")
p4 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "RH",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Relative Humidity",
  met_units = "%",
  model_type = "gls"
)

# FC ~ Latent Heat (Linear Regression)
cat("5. FC ~ Latent Heat (Linear Regression)\n")
p5 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "LE",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Latent Heat Flux",
  met_units = "W m⁻²",
  model_type = "lm"
)

# FCH4 ~ Latent Heat (GLS with AR1)
cat("6. FCH4 ~ Latent Heat (GLS with AR1)\n")
p6 <- create_flux_plot(
  data = df_monthly_FCH4,
  flux_var = "FCH4",
  met_var = "LE",
  flux_label = expression(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")")),
  met_label = "Latent Heat Flux",
  met_units = "W m⁻²",
  model_type = "gls"
)

cat("\nAll plots created successfully!\n\n")

# ----------------------------------------------------------------------------
# COMBINE INTO MULTI-PANEL FIGURE
# ----------------------------------------------------------------------------

# Option 1: 3x2 grid for all 6 relationships
cat("=== Creating combined figure (3x2 grid) ===\n")

combined_figure <- grid.arrange(
  p1, p2,
  p3, p4,
  p5, p6,
  ncol = 2,
  top = textGrob("Significant Monotonic Relationships: Monthly Mean Fluxes vs Meteorological Variables",
                 gp = gpar(fontsize = 16, fontface = "bold"))
)

# Save combined figure (commented out)
# ggsave("figures/flux_meteorological_relationships_combined.png",
#        plot = combined_figure,
#        width = 14, height = 16, dpi = 300, bg = "white")
# 
# ggsave("figures/flux_meteorological_relationships_combined.pdf",
#        plot = combined_figure,
#        width = 14, height = 16, device = "pdf")

# ----------------------------------------------------------------------------
# SEPARATE FIGURES FOR CO2 AND CH4
# ----------------------------------------------------------------------------

cat("=== Creating separate figures for CO2 and CH4 ===\n")

# CO2 relationships only (5 plots in 3x2 grid with empty space)
fc_figure <- grid.arrange(
  p1, p2,
  p3, p4,
  p5, 
  ncol = 2,
  top = textGrob(expression(paste("CO"[2], " Flux Relationships with Meteorological Variables")),
                 gp = gpar(fontsize = 16, fontface = "bold"))
)

# Save FC figure (commented out)
# ggsave("figures/FC_meteorological_relationships.png",
#        plot = fc_figure,
#        width = 14, height = 14, dpi = 300, bg = "white")

# CH4 relationship (single plot - can be larger)
fch4_figure <- grid.arrange(
  p6,
  top = textGrob(expression(paste("CH"[4], " Flux Relationship with Latent Heat")),
                 gp = gpar(fontsize = 16, fontface = "bold"))
)

# Save FCH4 figure (commented out)
# ggsave("figures/FCH4_latent_heat_relationship.png",
#        plot = fch4_figure,
#        width = 8, height = 6, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# INDIVIDUAL HIGH-RESOLUTION FIGURES
# ----------------------------------------------------------------------------

cat("=== Individual figures ready to save ===\n")
cat("Uncomment ggsave commands below to save individual plots\n\n")

# Individual saves (commented out - uncomment as needed)
# ggsave("figures/FC_air_temp.png", plot = p1, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_soil_temp.png", plot = p2, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_VPD.png", plot = p3, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_RH.png", plot = p4, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_latent_heat.png", plot = p5, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FCH4_latent_heat.png", plot = p6, width = 7, height = 5, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# PRINT SUMMARY TABLE
# ----------------------------------------------------------------------------

cat("\n=== SUMMARY OF RELATIONSHIPS ===\n\n")

summary_df <- data.frame(
  Relationship = c("FC ~ Air Temp", "FC ~ Soil Temp", "FC ~ VPD", 
                   "FC ~ RH", "FC ~ Latent Heat", "FCH4 ~ Latent Heat"),
  Method = c("GLS with AR(1)", "Linear Regression", "GLS with AR(1)",
             "GLS with AR(1)", "Linear Regression", "GLS with AR(1)"),
  Line_Color = c("Green", "Blue", "Green", "Green", "Blue", "Green"),
  Status = rep("Significant", 6)
)

print(summary_df)

cat("\n=== FIGURE CREATION COMPLETE ===\n")
cat("\nFigures are ready to view and save!\n")
cat("- Combined 3x2 figure: combined_figure\n")
cat("- CO2 only figure: fc_figure\n")
cat("- CH4 only figure: fch4_figure\n")
cat("- Individual plots: p1, p2, p3, p4, p5, p6\n\n")

cat("Uncomment ggsave() lines to save figures to disk.\n")
```
#adjusting 
```{r}
# ============================================================================
# Publication-Quality Figures: Significant Monotonic Flux Relationships
# ============================================================================
# Purpose: Create final figures showing significant relationships between
# CO2/CH4 fluxes and meteorological variables with appropriate statistics
#
# Author: [Your name]
# Date: October 25, 2025
# ============================================================================

library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)

# Define custom year colors (consistent with all analyses)
year_colors <- c(
  "2017" = "#E41A1C",  # Red
  "2018" = "#377EB8",  # Blue
  "2019" = "#4DAF4A",  # Green
  "2020" = "#984EA3",  # Purple
  "2021" = "#FF7F00",  # Orange
  "2022" = "#A65628"   # Brown
)

# ----------------------------------------------------------------------------
# FUNCTION: Create publication-quality plot with stats
# ----------------------------------------------------------------------------

create_flux_plot <- function(data, flux_var, met_var, 
                             flux_label, met_label, met_units,
                             model_type = "lm",
                             show_legend = TRUE) {
  
  # Prepare data
  plot_data <- data %>%
    select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    filter(complete.cases(.)) %>%
    arrange(year, month) %>%
    mutate(year = as.factor(year))
  
  # -------------------------------------------------------------------------
  # Fit appropriate model and extract statistics
  # -------------------------------------------------------------------------
  
  if(model_type == "lm") {
    # Linear regression (OLS)
    model <- lm(flux ~ met, data = plot_data)
    slope <- coef(model)[2]
    p_value <- summary(model)$coefficients[2, 4]
    r_squared <- summary(model)$r.squared
    model_name <- "Linear Regression"
    line_color <- "#377EB8"  # Blue for linear regression
    
    # Get predictions with SE for confidence bands
    pred_grid <- data.frame(met = seq(min(plot_data$met), 
                                      max(plot_data$met), 
                                      length.out = 100))
    predictions <- predict(model, newdata = pred_grid, se.fit = TRUE)
    pred_grid$fitted <- predictions$fit
    pred_grid$se <- predictions$se.fit
    pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
    pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
    
  } else if(model_type == "gls") {
    # GLS with AR(1) correlation structure
    model <- gls(flux ~ met, 
                 data = plot_data,
                 correlation = corAR1(form = ~ 1),
                 method = "REML")
    slope <- coef(model)[2]
    p_value <- summary(model)$tTable[2, 4]
    
    # Calculate pseudo-R² for GLS (correlation-based)
    fitted_vals <- fitted(model)
    r_squared <- cor(plot_data$flux, fitted_vals)^2
    
    model_name <- "GLS with AR(1)"
    line_color <- "#4DAF4A"  # Green for GLS
    
    # Get predictions with SE for confidence bands
    pred_grid <- data.frame(met = seq(min(plot_data$met), 
                                      max(plot_data$met), 
                                      length.out = 100))
    predictions <- predict(model, newdata = pred_grid, se.fit = TRUE)
    pred_grid$fitted <- predictions
    
    # Calculate SE from the variance-covariance matrix
    X <- model.matrix(~ met, data = pred_grid)
    vcov_matrix <- vcov(model)
    pred_grid$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
    pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
    pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
    
  } else {
    stop("model_type must be 'lm' or 'gls'")
  }
  
  # -------------------------------------------------------------------------
  # Create the plot
  # -------------------------------------------------------------------------
  
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    
    # Add confidence band (95% CI)
    geom_ribbon(data = pred_grid, 
                aes(x = met, ymin = lower, ymax = upper),
                fill = line_color, alpha = 0.2, inherit.aes = FALSE) +
    
    # Add fitted line
    geom_line(data = pred_grid,
              aes(x = met, y = fitted), 
              color = line_color, linewidth = 1.2,
              inherit.aes = FALSE) +
    
    # Add points colored by year
    geom_point(aes(color = year), size = 3, alpha = 0.8) +
    
    # Apply custom year colors
    scale_color_manual(
      values = year_colors,
      name = "Year"
    ) +
    
    # Labels
    labs(
      x = paste0(met_label, " (", met_units, ")"),
      y = flux_label
    ) +
    
    # Theme
    theme_bw(base_size = 13) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = if(show_legend) c(0.85, 0.85) else "none",
      legend.background = if(show_legend) element_rect(fill = "white", color = "black", linewidth = 0.3) else element_blank(),
      legend.title = element_text(size = 11, face = "bold"),
      legend.text = element_text(size = 9),
      legend.key.size = unit(0.7, "lines"),
      plot.margin = margin(10, 10, 10, 10),
      axis.title = element_text(size = 12, face = "bold"),
      axis.text = element_text(size = 11)
    )
  
  # -------------------------------------------------------------------------
  # Add statistics box in upper left
  # -------------------------------------------------------------------------
  
  # Format p-value
  if(p_value < 0.001) {
    p_text <- "p < 0.001"
  } else if(p_value < 0.01) {
    p_text <- sprintf("p = %.3f", p_value)
  } else {
    p_text <- sprintf("p = %.2f", p_value)
  }
  
  # Create statistics text
  stats_text <- paste0(
    model_name, "\n",
    "R² = ", sprintf("%.3f", r_squared), "\n",
    "Slope = ", sprintf("%.4f", slope), "\n",
    p_text
  )
  
  # Add text annotation in upper left corner
  # Find good position based on data range
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  x_pos <- x_range[1] + 0.05 * diff(x_range)
  y_pos <- y_range[2] - 0.05 * diff(y_range)
  
  p <- p +
    annotate("text", 
             x = x_pos, 
             y = y_pos, 
             label = stats_text,
             hjust = 0,
             vjust = 1,
             size = 3.5,
             fontface = "plain",
             color = "black",
             lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# CREATE ALL PLOTS
# ----------------------------------------------------------------------------

cat("\n=== Creating publication-quality figures ===\n\n")

# FC ~ Air Temperature (GLS with AR1)
cat("1. FC ~ Air Temperature (GLS with AR1)\n")
p1 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TA_gapfilled",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Air Temperature",
  met_units = "°C",
  model_type = "gls",
  show_legend = FALSE  # No legend in individual plots for combined figure
)

# FC ~ Soil Temperature (Linear Regression)
cat("2. FC ~ Soil Temperature (Linear Regression)\n")
p2 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TS_3_gapfilled",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Soil Temperature",
  met_units = "°C",
  model_type = "lm",
  show_legend = FALSE
)

# FC ~ VPD (GLS with AR1)
cat("3. FC ~ VPD (GLS with AR1)\n")
p3 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "VPD",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "VPD",
  met_units = "hPa",
  model_type = "gls",
  show_legend = FALSE
)

# FC ~ RH (GLS with AR1)
cat("4. FC ~ RH (GLS with AR1)\n")
p4 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "RH",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Relative Humidity",
  met_units = "%",
  model_type = "gls",
  show_legend = FALSE
)

# FC ~ Latent Heat (Linear Regression)
cat("5. FC ~ Latent Heat (Linear Regression)\n")
p5 <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "LE",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Latent Heat Flux",
  met_units = "W m⁻²",
  model_type = "lm",
  show_legend = FALSE
)

# FCH4 ~ Latent Heat (GLS with AR1)
cat("6. FCH4 ~ Latent Heat (GLS with AR1)\n")
p6 <- create_flux_plot(
  data = df_monthly_FCH4,
  flux_var = "FCH4",
  met_var = "LE",
  flux_label = expression(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")")),
  met_label = "Latent Heat Flux",
  met_units = "W m⁻²",
  model_type = "gls",
  show_legend = FALSE
)

# Create a separate plot WITH legend for extraction
cat("7. Creating shared legend...\n")
p_with_legend <- create_flux_plot(
  data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TA_gapfilled",
  flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
  met_label = "Air Temperature",
  met_units = "°C",
  model_type = "gls",
  show_legend = TRUE  # Keep legend for extraction
)

cat("\nAll plots created successfully!\n\n")

# ----------------------------------------------------------------------------
# COMBINE INTO MULTI-PANEL FIGURE WITH SHARED LEGEND
# ----------------------------------------------------------------------------

# Option 1: 3x2 grid for all 6 relationships with shared legend on right
cat("=== Creating combined figure (3x2 grid) with shared legend ===\n")

# Extract the legend from our plot with legend
library(cowplot)
shared_legend <- get_legend(p_with_legend)

# Arrange the 6 plots in a grid
plots_grid <- grid.arrange(
  p1, p2,
  p3, p4,
  p5, p6,
  ncol = 2,
  nrow = 3,
  top = textGrob("Significant Monotonic Relationships: Monthly Mean Fluxes vs Meteorological Variables",
                 gp = gpar(fontsize = 16, fontface = "bold"))
)

# Combine the grid with the legend on the right
combined_figure <- grid.arrange(
  plots_grid,
  shared_legend,
  ncol = 2,
  widths = c(10, 1.5)  # Plots take most space, legend on right
)

# Save combined figure (commented out)
# To save properly, need to create as grob first
# combined_grob <- arrangeGrob(plots_grid, shared_legend, ncol = 2, widths = c(10, 1.5))
# ggsave("figures/flux_meteorological_relationships_combined.png",
#        plot = combined_grob,
#        width = 14, height = 16, dpi = 300, bg = "white")
# 
# ggsave("figures/flux_meteorological_relationships_combined.pdf",
#        plot = combined_grob,
#        width = 14, height = 16, device = "pdf")

# ----------------------------------------------------------------------------
# SEPARATE FIGURES FOR CO2 AND CH4 WITH SHARED LEGENDS
# ----------------------------------------------------------------------------

cat("=== Creating separate figures for CO2 and CH4 with shared legends ===\n")

# CO2 relationships only (5 plots in layout with shared legend)
fc_plots_grid <- grid.arrange(
  p1, p2,
  p3, p4,
  p5, 
  ncol = 2,
  nrow = 3,
  top = textGrob(expression(paste("CO"[2], " Flux Relationships with Meteorological Variables")),
                 gp = gpar(fontsize = 16, fontface = "bold"))
)

# Add legend to FC figure
fc_figure <- grid.arrange(
  fc_plots_grid,
  shared_legend,
  ncol = 2,
  widths = c(10, 1.5)
)

# Save FC figure (commented out)
# fc_grob <- arrangeGrob(fc_plots_grid, shared_legend, ncol = 2, widths = c(10, 1.5))
# ggsave("figures/FC_meteorological_relationships.png",
#        plot = fc_grob,
#        width = 14, height = 14, dpi = 300, bg = "white")

# CH4 relationship (single plot with legend on right)
fch4_figure <- grid.arrange(
  p6,
  shared_legend,
  ncol = 2,
  widths = c(8, 1.5),
  top = textGrob(expression(paste("CH"[4], " Flux Relationship with Latent Heat")),
                 gp = gpar(fontsize = 16, fontface = "bold"))
)

# Save FCH4 figure (commented out)
# fch4_grob <- arrangeGrob(p6, shared_legend, ncol = 2, widths = c(8, 1.5),
#                          top = textGrob(expression(paste("CH"[4], " Flux Relationship with Latent Heat")),
#                                        gp = gpar(fontsize = 16, fontface = "bold")))
# ggsave("figures/FCH4_latent_heat_relationship.png",
#        plot = fch4_grob,
#        width = 10, height = 6, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# INDIVIDUAL HIGH-RESOLUTION FIGURES
# ----------------------------------------------------------------------------

cat("=== Individual figures ready to save ===\n")
cat("Uncomment ggsave commands below to save individual plots\n\n")

# Individual saves (commented out - uncomment as needed)
# ggsave("figures/FC_air_temp.png", plot = p1, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_soil_temp.png", plot = p2, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_VPD.png", plot = p3, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_RH.png", plot = p4, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FC_latent_heat.png", plot = p5, width = 7, height = 5, dpi = 300, bg = "white")
# ggsave("figures/FCH4_latent_heat.png", plot = p6, width = 7, height = 5, dpi = 300, bg = "white")

# ----------------------------------------------------------------------------
# PRINT SUMMARY TABLE
# ----------------------------------------------------------------------------

cat("\n=== SUMMARY OF RELATIONSHIPS ===\n\n")

summary_df <- data.frame(
  Relationship = c("FC ~ Air Temp", "FC ~ Soil Temp", "FC ~ VPD", 
                   "FC ~ RH", "FC ~ Latent Heat", "FCH4 ~ Latent Heat"),
  Method = c("GLS with AR(1)", "Linear Regression", "GLS with AR(1)",
             "GLS with AR(1)", "Linear Regression", "GLS with AR(1)"),
  Line_Color = c("Green", "Blue", "Green", "Green", "Blue", "Green"),
  Status = rep("Significant", 6)
)

print(summary_df)

cat("\n=== FIGURE CREATION COMPLETE ===\n")
cat("\nFigures are ready to view and save!\n")
cat("- Combined 3x2 figure: combined_figure\n")
cat("- CO2 only figure: fc_figure\n")
cat("- CH4 only figure: fch4_figure\n")
cat("- Individual plots: p1, p2, p3, p4, p5, p6\n\n")

cat("Uncomment ggsave() lines to save figures to disk.\n")
```
#adjustment 2
```{r}


library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)
library(cowplot)

# Define custom year colors (consistent with all analyses)
year_colors <- c(
  "2017" = "#E41A1C",  # Red
  "2018" = "#377EB8",  # Blue
  "2019" = "#4DAF4A",  # Green
  "2020" = "#984EA3",  # Purple
  "2021" = "#FF7F00",  # Orange
  "2022" = "#A65628"   # Brown
)

# ----------------------------------------------------------------------------
# FUNCTION: Create publication-quality plot with stats
# ----------------------------------------------------------------------------

create_flux_plot <- function(input_data, flux_var, met_var, 
                             flux_label, met_label, met_units,
                             model_type = "lm",
                             show_legend = TRUE,
                             stats_position = "bottom") {
  
  # Prepare data
  plot_data <- input_data %>%
    dplyr::select(year, month, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::filter(complete.cases(.)) %>%
    dplyr::arrange(year, month) %>%
    dplyr::mutate(year = as.factor(year))
  
  # -------------------------------------------------------------------------
  # Fit appropriate model and extract statistics
  # -------------------------------------------------------------------------
  
  if(model_type == "lm") {
    # Linear regression (OLS)
    model <- lm(flux ~ met, data = plot_data)
    slope <- coef(model)[2]
    p_value <- summary(model)$coefficients[2, 4]
    r_squared <- summary(model)$r.squared
    model_name <- "Linear Regression"
    line_color <- "#377EB8"  # Blue
    
    # Get predictions with SE
    pred_grid <- data.frame(met = seq(min(plot_data$met), 
                                      max(plot_data$met), 
                                      length.out = 100))
    predictions <- predict(model, newdata = pred_grid, se.fit = TRUE)
    pred_grid$fitted <- predictions$fit
    pred_grid$se <- predictions$se.fit
    pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
    pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
    
  } else if(model_type == "gls") {
    # GLS with AR(1)
    model <- gls(flux ~ met, 
                 data = plot_data,
                 correlation = corAR1(form = ~ 1),
                 method = "REML")
    slope <- coef(model)[2]
    p_value <- summary(model)$tTable[2, 4]
    
    # Pseudo-R²
    fitted_vals <- fitted(model)
    r_squared <- cor(plot_data$flux, fitted_vals)^2
    
    model_name <- "GLS with AR(1)"
    line_color <- "#4DAF4A"  # Green
    
    # Get predictions with SE
    pred_grid <- data.frame(met = seq(min(plot_data$met), 
                                      max(plot_data$met), 
                                      length.out = 100))
    predictions <- predict(model, newdata = pred_grid, se.fit = TRUE)
    pred_grid$fitted <- predictions
    
    # SE from variance-covariance matrix
    X <- model.matrix(~ met, data = pred_grid)
    vcov_matrix <- vcov(model)
    pred_grid$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
    pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
    pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
    
  } else {
    stop("model_type must be 'lm' or 'gls'")
  }
  
  # -------------------------------------------------------------------------
  # Create plot
  # -------------------------------------------------------------------------
  
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    
    # Confidence band
    geom_ribbon(data = pred_grid, 
                aes(x = met, ymin = lower, ymax = upper),
                fill = line_color, alpha = 0.2, inherit.aes = FALSE) +
    
    # Fitted line
    geom_line(data = pred_grid,
              aes(x = met, y = fitted), 
              color = line_color, linewidth = 1.2,
              inherit.aes = FALSE) +
    
    # Points by year
    geom_point(aes(color = year), size = 3, alpha = 0.8) +
    
    scale_color_manual(values = year_colors, name = "Year") +
    
    labs(x = paste0(met_label, " (", met_units, ")"),
         y = flux_label) +
    
    theme_bw(base_size = 27) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = if(show_legend) "right" else "none",
      legend.background = element_rect(fill = "white", color = "black", linewidth = 0.5),
      legend.title = element_text(size = 25, face = "bold"),
      legend.text = element_text(size = 25),
      legend.key.size = unit(3, "lines"),
      plot.margin = margin(10, 10, 10, 10),
      axis.title = element_text(size = 25, face = "bold"),
      axis.text = element_text(size = 25)
    )
  
  # -------------------------------------------------------------------------
  # Add statistics
  # -------------------------------------------------------------------------
  
  if(p_value < 0.001) {
    p_text <- "p < 0.001"
  } else if(p_value < 0.01) {
    p_text <- sprintf("p = %.3f", p_value)
  } else {
    p_text <- sprintf("p = %.2f", p_value)
  }
  
  stats_text <- paste0(
    model_name, "\n",
    "R² = ", sprintf("%.3f", r_squared), "\n",
    "Slope = ", sprintf("%.4f", slope), "\n",
    p_text
  )
  
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  if(stats_position == "bottom") {
    x_pos <- x_range[1] + 0.05 * diff(x_range)
    y_pos <- y_range[1] + 0.05 * diff(y_range)
    vjust_val <- 0
  } else {
    x_pos <- x_range[1] + 0.05 * diff(x_range)
    y_pos <- y_range[2] - 0.05 * diff(y_range)
    vjust_val <- 1
  }
  
  p <- p +
    annotate("text", x = x_pos, y = y_pos, label = stats_text,
             hjust = 0, vjust = vjust_val, size = 6,
             fontface = "plain", color = "black", lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# CREATE ALL PLOTS
# ----------------------------------------------------------------------------

cat("\n=== Creating figures ===\n\n")

p1 <- create_flux_plot(
  input_data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TA_gapfilled",
  flux_label = expression(bold(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")"))),
  met_label = "Air Temperature",
  met_units = "°C",
  model_type = "gls",
  show_legend = FALSE,
  stats_position = "bottom" 

)

p2 <- create_flux_plot(
  input_data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TS_3_gapfilled",
 flux_label = expression(bold(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")"))),
  met_label = "Soil Temperature",
  met_units = "°C",
  model_type = "lm",
  show_legend = FALSE,
  stats_position = "bottom"
)

p3 <- create_flux_plot(
  input_data = df_monthly_FC,
  flux_var = "FC",
  met_var = "VPD",
  flux_label = expression(bold(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")"))),
  met_label = "VPD",
  met_units = "hPa",
  model_type = "gls",
  show_legend = FALSE,
  stats_position = "bottom"
)

p4 <- create_flux_plot(
  input_data = df_monthly_FC,
  flux_var = "FC",
  met_var = "RH",
 flux_label = expression(bold(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")"))),
  met_label = "Relative Humidity",
  met_units = "%",
  model_type = "gls",
  show_legend = FALSE,
  stats_position = "bottom"
)

p5 <- create_flux_plot(
  input_data = df_monthly_FC,
  flux_var = "FC",
  met_var = "LE",
 flux_label = expression(bold(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")"))),
  met_label = "Latent Heat Flux",
  met_units = "W m⁻²",
  model_type = "lm",
  show_legend = FALSE,
  stats_position = "bottom"
)

p6 <- create_flux_plot(
  input_data = df_monthly_FCH4,
  flux_var = "FCH4",
  met_var = "LE",
 flux_label = expression(bold(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")"))),
  met_label = "Latent Heat Flux",
  met_units = "W m⁻²",
  model_type = "gls",
  show_legend = FALSE,
  stats_position = "top"
)

# Plot with legend for extraction
p_with_legend <- create_flux_plot(
  input_data = df_monthly_FC,
  flux_var = "FC",
  met_var = "TA_gapfilled",
  flux_label = expression(bold(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")"))),
  met_label = "Air Temperature",
  met_units = "°C",
  model_type = "gls",
  show_legend = TRUE,
  stats_position = "bottom"
)

cat("All plots created!\n\n")

# ----------------------------------------------------------------------------
# COMBINED FIGURE WITH SHARED LEGEND
# ----------------------------------------------------------------------------

cat("=== Creating combined figure ===\n")

shared_legend <- get_legend(p_with_legend)

main_title <- textGrob(
  "Significant Monotonic Relationships",
  gp = gpar(fontsize = 28, fontface = "bold")
)

plots_grid <- arrangeGrob(
  p1, p2, p3, p4, p5, p6,
  ncol = 2, nrow = 3, top = main_title
)

combined_figure <- arrangeGrob(
  plots_grid, shared_legend,
  ncol = 2, widths = c(10, 1.8)
)

grid.newpage()
grid.draw(combined_figure)

cat("\nCombined figure complete!\n\n")

# Save (uncomment to use)
# ggsave("figures/flux_relationships_combined.png",
#        plot = combined_figure,
#        width = 16, height = 18, dpi = 300, bg = "white")

cat("=== DONE ===\n")
```


#save
```{r}
# Save combined figure (commented out)
# To save properly, need to create as grob first
# combined_grob <- arrangeGrob(plots_grid, shared_legend, ncol = 2, widths = c(10, 1.5))


  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Monthly_Sig_Mono_Flux_Met_Relationships2.png", combined_figure,
         width = 18, height = 20, dpi = 600) 
```

#Trying to resolve autocorr in seasonal 
```{r}

# ============================================================================
# Within-Season Analysis: Flux-Meteorological Variable Relationships
# ============================================================================
# Purpose: Analyze relationships between CO2/CH4 fluxes and meteorological
# variables separately within winter, growing season, and fall senescence
# to account for seasonal differences in ecological processes


library(tidyverse)
library(nlme)
library(lmtest)
library(car)  # For Levene's test

# ----------------------------------------------------------------------------
# FUNCTION: Comprehensive within-season relationship analysis
# ----------------------------------------------------------------------------

analyze_within_season <- function(input_data, flux_var, met_var, season_name,
                                 flux_label, met_label) {
  
  cat("\n========================================\n")
  cat("Analyzing:", flux_label, "~", met_label, "in", season_name, "\n")
  cat("========================================\n\n")
  
  # Filter for this season only
  season_data <- input_data %>%
    dplyr::filter(!is.na(!!sym(flux_var)), !is.na(!!sym(met_var))) %>%
    dplyr::select(year, DOY, season, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::arrange(year, DOY)
  
  n_obs <- nrow(season_data)
  
  if(n_obs < 15) {
    cat("Insufficient data (n =", n_obs, "). Skipping.\n")
    return(NULL)
  }
  
  cat("Number of observations:", n_obs, "\n\n")
  
  # -------------------------------------------------------------------------
  # STEP 1: Visual inspection - plot the relationship
  # -------------------------------------------------------------------------
  
  cat("STEP 1: Visual Inspection\n")
  
  visual_plot <- ggplot(season_data, aes(x = met, y = flux)) +
    geom_point(aes(color = as.factor(year)), size = 2, alpha = 0.7) +
    geom_smooth(method = "loess", se = TRUE, color = "black") +
    geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +
    labs(title = paste(flux_label, "~", met_label, "-", season_name),
         x = met_label, y = flux_label, color = "Year") +
    theme_bw()
  
  print(visual_plot)
  
  # Assess if relationship appears monotonic
  cat("\n→ Visually assess: Is relationship monotonic? (Check plot)\n\n")
  
  # -------------------------------------------------------------------------
  # STEP 2: Fit linear model and check assumptions
  # -------------------------------------------------------------------------
  
  cat("STEP 2: Linear Model Assumptions\n\n")
  
  lm_model <- lm(flux ~ met, data = season_data)
  residuals_vals <- residuals(lm_model)
  
  # 2a. Normality (Shapiro-Wilk)
  # Shapiro test only works with n between 3 and 5000
  if(length(residuals_vals) >= 3 && length(residuals_vals) <= 5000) {
    shapiro_test <- shapiro.test(residuals_vals)
    shapiro_p <- shapiro_test$p.value
    normal <- shapiro_p > 0.05
    
    cat(sprintf("  Shapiro-Wilk (normality):     p = %.4f", shapiro_p))
    if(normal) {
      cat(" ✓ Normal\n")
    } else {
      cat(" ✗ Non-normal\n")
    }
  } else {
    cat("  Shapiro-Wilk: Sample size out of range (n =", length(residuals_vals), ")\n")
    shapiro_p <- NA
    normal <- NA  # Can't determine
  }
  
  # 2b. Homogeneity of variance (Breusch-Pagan)
  bp_test <- bptest(lm_model)
  bp_p <- bp_test$p.value
  homosced <- bp_p > 0.05
  
  cat(sprintf("  Breusch-Pagan (homoscedast.): p = %.4f", bp_p))
  if(homosced) {
    cat(" ✓ Homoscedastic\n")
  } else {
    cat(" ✗ Heteroscedastic\n")
  }
  
  # 2c. Levene's test (alternative to BP)
  # Group by year for Levene's test
  levene_test <- leveneTest(flux ~ as.factor(year), data = season_data)
  levene_p <- levene_test$`Pr(>F)`[1]
  
  cat(sprintf("  Levene's test (homoscedast.): p = %.4f\n", levene_p))
  
  # QQ plot for visual normality check
  cat("\n  QQ Plot created (check visual output)\n\n")
  
  qq_plot <- ggplot(data.frame(resid = residuals_vals), aes(sample = resid)) +
    stat_qq() +
    stat_qq_line(color = "red") +
    labs(title = paste("QQ Plot:", season_name)) +
    theme_bw()
  
  print(qq_plot)
  
  lm_assumptions_met <- !is.na(normal) && normal && homosced
  
  # -------------------------------------------------------------------------
  # STEP 3: Check for autocorrelation
  # -------------------------------------------------------------------------
  
  cat("\nSTEP 3: Autocorrelation Check\n\n")
  
  dw_test <- dwtest(lm_model)
  dw_stat <- as.numeric(dw_test$statistic)
  dw_p <- dw_test$p.value
  autocorr_detected <- dw_p < 0.05
  
  cat(sprintf("  Durbin-Watson test:           DW = %.4f, p = %.4f", dw_stat, dw_p))
  if(autocorr_detected) {
    cat(" ✗ Autocorrelation detected\n\n")
  } else {
    cat(" ✓ No autocorrelation\n\n")
  }
  
  # -------------------------------------------------------------------------
  # STEP 4-6: Apply decision tree
  # -------------------------------------------------------------------------
  
  cat("DECISION TREE:\n\n")
  
  lm_slope <- coef(lm_model)[2]
  lm_p <- summary(lm_model)$coefficients[2, 4]
  lm_r2 <- summary(lm_model)$r.squared
  
  # Initialize result variables
  kendall_tau <- NA
  kendall_p <- NA
  gls_ar1_slope <- NA
  gls_ar1_p <- NA
  gls_ar1_autocorr_resolved <- NA
  gls_ar2_slope <- NA
  gls_ar2_p <- NA
  gls_ar2_autocorr_resolved <- NA
  weighted_gls_slope <- NA
  weighted_gls_p <- NA
  weighted_gls_autocorr_resolved <- NA
  lme_slope <- NA
  lme_p <- NA
  lme_autocorr_resolved <- NA
  
  # DECISION PATH 1: Assumptions met, no autocorrelation → Linear regression
  if(lm_assumptions_met && !autocorr_detected) {
    
    cat("✓ Path 1: All assumptions met, no autocorrelation\n")
    cat("  → Using Linear Regression\n\n")
    
    recommended_method <- "Linear Regression"
    recommended_stat <- lm_slope
    recommended_p <- lm_p
    recommended_r2 <- lm_r2
    
    cat(sprintf("  Slope: %.6f\n", lm_slope))
    cat(sprintf("  P-value: %.4f\n", lm_p))
    cat(sprintf("  R²: %.4f\n", lm_r2))
    
  # DECISION PATH 2: Assumptions violated, no autocorrelation → Kendall's tau
  } else if(!lm_assumptions_met && !autocorr_detected) {
    
    cat("⚠ Path 2: Assumptions violated, but no autocorrelation\n")
    cat("  → Using Kendall's tau\n\n")
    
    kendall_test <- cor.test(season_data$met, season_data$flux, method = "kendall")
    kendall_tau <- kendall_test$estimate
    kendall_p <- kendall_test$p.value
    
    recommended_method <- "Kendall's tau"
    recommended_stat <- kendall_tau
    recommended_p <- kendall_p
    recommended_r2 <- NA
    
    cat(sprintf("  Tau: %.4f\n", kendall_tau))
    cat(sprintf("  P-value: %.4f\n", kendall_p))
    
  # DECISION PATH 3: Assumptions violated + autocorrelation → GLS with AR structures
  } else if(!lm_assumptions_met && autocorr_detected) {
    
    cat("⚠ Path 3: Assumptions violated AND autocorrelation detected\n")
    cat("  → Trying GLS with AR(1)\n\n")
    
    # Try GLS AR(1)
    tryCatch({
      gls_ar1 <- gls(flux ~ met, 
                     data = season_data,
                     correlation = corAR1(form = ~ 1),
                     method = "REML")
      
      gls_ar1_slope <- coef(gls_ar1)[2]
      gls_ar1_p <- summary(gls_ar1)$tTable[2, 4]
      
      # Check autocorrelation
      gls_ar1_resid <- residuals(gls_ar1, type = "normalized")
      gls_ar1_dw <- dwtest(gls_ar1_resid ~ 1)
      gls_ar1_autocorr_resolved <- gls_ar1_dw$p.value > 0.05
      
      cat(sprintf("  AR(1) Slope: %.6f, p = %.4f\n", gls_ar1_slope, gls_ar1_p))
      cat(sprintf("  Autocorr resolved: %s (DW p = %.4f)\n\n", 
                  ifelse(gls_ar1_autocorr_resolved, "YES", "NO"),
                  gls_ar1_dw$p.value))
      
      if(!gls_ar1_autocorr_resolved) {
        # Try AR(2)
        cat("  → Autocorrelation persists, trying AR(2)\n\n")
        
        tryCatch({
          gls_ar2 <- gls(flux ~ met, 
                         data = season_data,
                         correlation = corARMA(form = ~ 1, p = 2, q = 0),
                         method = "REML")
          
          gls_ar2_slope <- coef(gls_ar2)[2]
          gls_ar2_p <- summary(gls_ar2)$tTable[2, 4]
          
          # Check autocorrelation
          gls_ar2_resid <- residuals(gls_ar2, type = "normalized")
          gls_ar2_dw <- dwtest(gls_ar2_resid ~ 1)
          gls_ar2_autocorr_resolved <- gls_ar2_dw$p.value > 0.05
          
          cat(sprintf("  AR(2) Slope: %.6f, p = %.4f\n", gls_ar2_slope, gls_ar2_p))
          cat(sprintf("  Autocorr resolved: %s (DW p = %.4f)\n\n",
                      ifelse(gls_ar2_autocorr_resolved, "YES", "NO"),
                      gls_ar2_dw$p.value))
          
          if(!gls_ar2_autocorr_resolved) {
            # Try weighted GLS
            cat("  → Trying Weighted GLS (varIdent by year)\n\n")
            
            tryCatch({
              weighted_gls <- gls(flux ~ met,
                                 data = season_data,
                                 weights = varIdent(form = ~ 1 | year),
                                 correlation = corAR1(form = ~ 1),
                                 method = "REML")
              
              weighted_gls_slope <- coef(weighted_gls)[2]
              weighted_gls_p <- summary(weighted_gls)$tTable[2, 4]
              
              weighted_gls_resid <- residuals(weighted_gls, type = "normalized")
              weighted_gls_dw <- dwtest(weighted_gls_resid ~ 1)
              weighted_gls_autocorr_resolved <- weighted_gls_dw$p.value > 0.05
              
              cat(sprintf("  Weighted GLS Slope: %.6f, p = %.4f\n", 
                         weighted_gls_slope, weighted_gls_p))
              cat(sprintf("  Autocorr resolved: %s\n\n",
                         ifelse(weighted_gls_autocorr_resolved, "YES", "NO")))
              
              recommended_method <- "Weighted GLS"
              recommended_stat <- weighted_gls_slope
              recommended_p <- weighted_gls_p
              
            }, error = function(e) {
              cat("  Weighted GLS failed\n\n")
              recommended_method <<- "GLS AR(2) (autocorr persists)"
              recommended_stat <<- gls_ar2_slope
              recommended_p <<- gls_ar2_p
            })
            
          } else {
            recommended_method <- "GLS with AR(2)"
            recommended_stat <- gls_ar2_slope
            recommended_p <- gls_ar2_p
          }
          
        }, error = function(e) {
          cat("  AR(2) failed, using AR(1)\n\n")
          recommended_method <<- "GLS with AR(1)"
          recommended_stat <<- gls_ar1_slope
          recommended_p <<- gls_ar1_p
        })
        
      } else {
        recommended_method <- "GLS with AR(1)"
        recommended_stat <- gls_ar1_slope
        recommended_p <- gls_ar1_p
      }
      
    }, error = function(e) {
      cat("  GLS AR(1) failed, using Kendall's tau\n\n")
      
      kendall_test <- cor.test(season_data$met, season_data$flux, method = "kendall")
      kendall_tau <<- kendall_test$estimate
      kendall_p <<- kendall_test$p.value
      
      recommended_method <<- "Kendall's tau (GLS failed, autocorr warning)"
      recommended_stat <<- kendall_tau
      recommended_p <<- kendall_p
    })
    
    recommended_r2 <- NA
    
  # DECISION PATH 4: Assumptions met, but autocorrelation → GLS AR structures
  } else {
    
    cat("⚠ Path 4: Assumptions met, but autocorrelation detected\n")
    cat("  → Trying GLS with AR(1)\n\n")
    
    # Same GLS approach as Path 3
    tryCatch({
      gls_ar1 <- gls(flux ~ met, 
                     data = season_data,
                     correlation = corAR1(form = ~ 1),
                     method = "REML")
      
      gls_ar1_slope <- coef(gls_ar1)[2]
      gls_ar1_p <- summary(gls_ar1)$tTable[2, 4]
      gls_ar1_resid <- residuals(gls_ar1, type = "normalized")
      gls_ar1_dw <- dwtest(gls_ar1_resid ~ 1)
      gls_ar1_autocorr_resolved <- gls_ar1_dw$p.value > 0.05
      
      cat(sprintf("  AR(1) Slope: %.6f, p = %.4f\n", gls_ar1_slope, gls_ar1_p))
      cat(sprintf("  Autocorr resolved: %s\n\n",
                  ifelse(gls_ar1_autocorr_resolved, "YES", "NO")))
      
      if(gls_ar1_autocorr_resolved) {
        recommended_method <- "GLS with AR(1)"
        recommended_stat <- gls_ar1_slope
        recommended_p <- gls_ar1_p
      } else {
        # Try AR(2) if AR(1) didn't work
        cat("  → Trying AR(2)\n\n")
        gls_ar2 <- gls(flux ~ met, 
                       data = season_data,
                       correlation = corARMA(form = ~ 1, p = 2, q = 0),
                       method = "REML")
        
        gls_ar2_slope <- coef(gls_ar2)[2]
        gls_ar2_p <- summary(gls_ar2)$tTable[2, 4]
        
        recommended_method <- "GLS with AR(2)"
        recommended_stat <- gls_ar2_slope
        recommended_p <- gls_ar2_p
      }
      
    }, error = function(e) {
      cat("  GLS failed, using linear regression with caution\n\n")
      recommended_method <<- "Linear Regression (autocorr detected)"
      recommended_stat <<- lm_slope
      recommended_p <<- lm_p
    })
    
    recommended_r2 <- NA
  }
  
  # -------------------------------------------------------------------------
  # Compile results
  # -------------------------------------------------------------------------
  
  result <- data.frame(
    flux_variable = flux_label,
    met_variable = met_label,
    season = season_name,
    n_obs = n_obs,
    
    # Assumptions
    shapiro_p = shapiro_p,
    normal = normal,
    bp_p = bp_p,
    homoscedastic = homosced,
    levene_p = levene_p,
    dw_stat = dw_stat,
    dw_p = dw_p,
    autocorr_detected = autocorr_detected,
    lm_assumptions_met = lm_assumptions_met,
    
    # Model results
    lm_slope = lm_slope,
    lm_p = lm_p,
    lm_r2 = lm_r2,
    
    kendall_tau = kendall_tau,
    kendall_p = kendall_p,
    
    gls_ar1_slope = gls_ar1_slope,
    gls_ar1_p = gls_ar1_p,
    gls_ar1_autocorr_resolved = gls_ar1_autocorr_resolved,
    
    gls_ar2_slope = gls_ar2_slope,
    gls_ar2_p = gls_ar2_p,
    gls_ar2_autocorr_resolved = gls_ar2_autocorr_resolved,
    
    weighted_gls_slope = weighted_gls_slope,
    weighted_gls_p = weighted_gls_p,
    weighted_gls_autocorr_resolved = weighted_gls_autocorr_resolved,
    
    # Recommendation
    recommended_method = recommended_method,
    recommended_stat = recommended_stat,
    recommended_p = recommended_p,
    recommended_r2 = ifelse(is.na(recommended_r2), NA, recommended_r2),
    significant = ifelse(recommended_p < 0.05, 
                        paste0("Yes (", recommended_method, ")"),
                        "No"),
    
    stringsAsFactors = FALSE
  )
  
  cat("\n========================================\n")
  cat("FINAL RECOMMENDATION:", recommended_method, "\n")
  cat(sprintf("Statistic: %.4f, P-value: %.4f\n", recommended_stat, recommended_p))
  cat("========================================\n\n")
  
  return(result)
}

# ----------------------------------------------------------------------------
# RUN ANALYSIS FOR ALL SEASONS AND VARIABLES
# ----------------------------------------------------------------------------

# Define met variables to test
met_vars <- list(
  list(var = "TA_gapfilled", label = "Air Temp"),
  list(var = "TS_3_gapfilled", label = "Soil Temp"),
  list(var = "SWC_3_1_1", label = "Soil Moisture"),
  list(var = "VPD", label = "VPD"),
  list(var = "RH", label = "RH"),
  list(var = "LE", label = "Latent Heat"),
  list(var = "H", label = "Sensible Heat"),
  list(var = "G_1_1_1", label = "Soil Heat Flux")
)

# Get unique seasons from FC data (excluding NA)
seasons <- unique(df_avg_FC$season)
seasons <- seasons[!is.na(seasons)]

cat("\nSeasons found:", paste(seasons, collapse = ", "), "\n\n")

cat("\n############################################################\n")
cat("# WITHIN-SEASON ANALYSIS: CO2 FLUX\n")
cat("############################################################\n")

fc_results <- list()

for(season_name in seasons) {
  for(met in met_vars) {
    
    # Filter for this season
    season_subset <- df_avg_FC %>% dplyr::filter(season == season_name)
    
    result <- analyze_within_season(
      input_data = season_subset,
      flux_var = "FC",  # Measured CO2 flux (not gapfilled)
      met_var = met$var,
      season_name = season_name,
      flux_label = "CO2 Flux",
      met_label = met$label
    )
    
    if(!is.null(result)) {
      fc_results[[paste(season_name, met$label, sep = "_")]] <- result
    }
  }
}

fc_results_df <- do.call(rbind, fc_results)
rownames(fc_results_df) <- NULL

cat("\n############################################################\n")
cat("# WITHIN-SEASON ANALYSIS: CH4 FLUX\n")
cat("############################################################\n")

fch4_results <- list()

for(season_name in seasons) {
  for(met in met_vars) {
    
    # Filter for this season
    season_subset <- df_avg_FCH4 %>% dplyr::filter(season == season_name)
    
    result <- analyze_within_season(
      input_data = season_subset,
      flux_var = "FCH4",  # Measured CH4 flux (not gapfilled)
      met_var = met$var,
      season_name = season_name,
      flux_label = "CH4 Flux",
      met_label = met$label
    )
    
    if(!is.null(result)) {
      fch4_results[[paste(season_name, met$label, sep = "_")]] <- result
    }
  }
}

fch4_results_df <- do.call(rbind, fch4_results)
rownames(fch4_results_df) <- NULL

# ----------------------------------------------------------------------------
# SUMMARY TABLES
# ----------------------------------------------------------------------------

cat("\n############################################################\n")
cat("# SUMMARY: SIGNIFICANT RELATIONSHIPS\n")
cat("############################################################\n\n")

# CO2 significant relationships
cat("=== CO2 FLUX ===\n")
fc_sig <- fc_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::select(season, met_variable, recommended_method, 
                recommended_stat, recommended_p, significant)

if(nrow(fc_sig) > 0) {
  print(fc_sig)
} else {
  cat("No significant relationships found\n")
}

cat("\n=== CH4 FLUX ===\n")
fch4_sig <- fch4_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::select(season, met_variable, recommended_method,
                recommended_stat, recommended_p, significant)

if(nrow(fch4_sig) > 0) {
  print(fch4_sig)
} else {
  cat("No significant relationships found\n")
}

# Save results (commented out)
# write.csv(fc_results_df, "results/within_season_FC_results.csv", row.names = FALSE)
# write.csv(fch4_results_df, "results/within_season_FCH4_results.csv", row.names = FALSE)

cat("\n############################################################\n")
cat("# ANALYSIS COMPLETE\n")
cat("############################################################\n")
```

#Seasonal figs 
```{r}
# ============================================================================
# Figures for Significant Within-Season Relationships
# ============================================================================


library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)
library(cowplot)

# Define year colors
year_colors <- c(
  "2017" = "#E41A1C", "2018" = "#377EB8", "2019" = "#4DAF4A",
  "2020" = "#984EA3", "2021" = "#FF7F00", "2022" = "#A65628"
)

# Define units for met variables
met_units <- list(
  "Air Temp" = "°C",
  "Soil Temp" = "°C",
  "Soil Moisture" = "%",
  "VPD" = "hPa",
  "RH" = "%",
  "Latent Heat" = "W/m²",
  "Sensible Heat" = "W/m²",
  "Soil Heat Flux" = "W/m²"
)

# ----------------------------------------------------------------------------
# FUNCTION: Create within-season plot with stats
# ----------------------------------------------------------------------------

create_season_plot <- function(input_data, flux_var, met_var, season_name,
                               flux_label, met_label, 
                               gls_slope, gls_p, gls_r2,
                               show_legend = FALSE) {
  
  # Get data for this season
  plot_data <- input_data %>%
    dplyr::filter(season == season_name) %>%
    dplyr::filter(!is.na(!!sym(flux_var)), !is.na(!!sym(met_var))) %>%
    dplyr::select(year, DOY, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::mutate(year = as.factor(year))
  
  # Fit GLS AR(1) model
  gls_model <- gls(flux ~ met,
                   data = plot_data,
                   correlation = corAR1(form = ~ 1),
                   method = "REML")
  
  # Create prediction grid
  pred_grid <- data.frame(
    met = seq(min(plot_data$met), max(plot_data$met), length.out = 100)
  )
  
  predictions <- predict(gls_model, newdata = pred_grid, se.fit = TRUE)
  pred_grid$fitted <- predictions
  
  # Calculate SE
  X <- model.matrix(~ met, data = pred_grid)
  vcov_matrix <- vcov(gls_model)
  pred_grid$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
  pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
  pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
  
  # Get units
  met_unit <- met_units[[met_label]]
  if(is.null(met_unit)) met_unit <- ""
  
  # Create plot
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    
    # Confidence band
    geom_ribbon(data = pred_grid,
                aes(x = met, ymin = lower, ymax = upper),
                fill = "#4DAF4A", alpha = 0.2, inherit.aes = FALSE) +
    
    # Fitted line (green for GLS)
    geom_line(data = pred_grid,
              aes(x = met, y = fitted),
              color = "#4DAF4A", linewidth = 1,
              inherit.aes = FALSE) +
    
    # Points by year
    geom_point(aes(color = year), size = 2, alpha = 0.7) +
    
    scale_color_manual(values = year_colors, name = "Year") +
    
    labs(
      x = if(met_unit != "") paste0(met_label, " (", met_unit, ")") else met_label,
      y = flux_label,
      title = paste(season_name)
    ) +
    
    theme_bw(base_size = 12) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = if(show_legend) "right" else "none",
      legend.background = element_rect(fill = "white", color = "black"),
      plot.title = element_text(size = 11, face = "bold", hjust = 0.5),
      axis.title = element_text(size = 10, face = "bold"),
      axis.text = element_text(size = 9)
    )
  
  # Add stats in upper right
  if(gls_p < 0.001) {
    p_text <- "p < 0.001"
  } else if(gls_p < 0.01) {
    p_text <- sprintf("p = %.3f", gls_p)
  } else {
    p_text <- sprintf("p = %.2f", gls_p)
  }
  
  stats_text <- paste0(
    "GLS with AR(1)\n",
    "R² = ", sprintf("%.3f", gls_r2), "\n",
    "Slope = ", sprintf("%.4f", gls_slope), "\n",
    p_text
  )
  
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  # Upper right position
  x_pos <- x_range[2] - 0.05 * diff(x_range)
  y_pos <- y_range[2] - 0.05 * diff(y_range)
  
  p <- p +
    annotate("text",
             x = x_pos, y = y_pos,
             label = stats_text,
             hjust = 1, vjust = 1,
             size = 3, fontface = "plain",
             color = "black", lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# EXTRACT SIGNIFICANT RELATIONSHIPS AND CREATE FIGURES
# ----------------------------------------------------------------------------

cat("\n=== Creating figures for significant relationships ===\n\n")

# Filter for significant relationships using GLS AR(1)
fc_sig <- fc_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

fch4_sig <- fch4_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

cat("CO2 significant relationships:", nrow(fc_sig), "\n")
cat("CH4 significant relationships:", nrow(fch4_sig), "\n\n")

# ----------------------------------------------------------------------------
# CREATE PLOTS FOR EACH FLUX × SEASON COMBINATION
# ----------------------------------------------------------------------------

# Get unique seasons
seasons <- unique(c(fc_sig$season, fch4_sig$season))

# CO2 plots by season
fc_plots_by_season <- list()

for(season_name in seasons) {
  
  season_data <- fc_sig %>% dplyr::filter(season == season_name)
  
  if(nrow(season_data) == 0) next
  
  cat("Creating CO2 plots for", season_name, ":", nrow(season_data), "relationships\n")
  
  plots <- list()
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    
    # Map met_variable to column name
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    # Calculate pseudo R² from slope and data
    season_subset <- df_avg_FC %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FC), !is.na(!!sym(met_col))) %>%
      dplyr::select(FC, met = !!sym(met_col))
    
    gls_temp <- gls(FC ~ met,
                    data = season_subset,
                    correlation = corAR1(form = ~ 1),
                    method = "REML")
    
    fitted_vals <- fitted(gls_temp)
    gls_r2 <- cor(season_subset$FC, fitted_vals)^2
    
    p <- create_season_plot(
      input_data = df_avg_FC,
      flux_var = "FC",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE
    )
    
    plots[[row$met_variable]] <- p
  }
  
  fc_plots_by_season[[season_name]] <- plots
}

# CH4 plots by season
fch4_plots_by_season <- list()

for(season_name in seasons) {
  
  season_data <- fch4_sig %>% dplyr::filter(season == season_name)
  
  if(nrow(season_data) == 0) next
  
  cat("Creating CH4 plots for", season_name, ":", nrow(season_data), "relationships\n")
  
  plots <- list()
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    
    # Map met_variable to column name
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    # Calculate pseudo R²
    season_subset <- df_avg_FCH4 %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FCH4), !is.na(!!sym(met_col))) %>%
      dplyr::select(FCH4, met = !!sym(met_col))
    
    gls_temp <- gls(FCH4 ~ met,
                    data = season_subset,
                    correlation = corAR1(form = ~ 1),
                    method = "REML")
    
    fitted_vals <- fitted(gls_temp)
    gls_r2 <- cor(season_subset$FCH4, fitted_vals)^2
    
    p <- create_season_plot(
      input_data = df_avg_FCH4,
      flux_var = "FCH4",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE
    )
    
    plots[[row$met_variable]] <- p
  }
  
  fch4_plots_by_season[[season_name]] <- plots
}

# ----------------------------------------------------------------------------
# CREATE COMBINED FIGURES BY SEASON
# ----------------------------------------------------------------------------

cat("\n=== Creating combined figures ===\n\n")

# Extract legend
if(length(fc_plots_by_season) > 0 && length(fc_plots_by_season[[1]]) > 0) {
  p_legend_temp <- create_season_plot(
    input_data = df_avg_FC,
    flux_var = "FC",
    met_var = "TA_gapfilled",
    season_name = names(fc_plots_by_season)[1],
    flux_label = expression(paste("CO"[2], " Flux")),
    met_label = "Air Temp",
    gls_slope = 0, gls_p = 0.05, gls_r2 = 0.5,
    show_legend = TRUE
  )
  shared_legend <- get_legend(p_legend_temp)
}

# CO2 combined figures
fc_combined_figures <- list()

for(season_name in names(fc_plots_by_season)) {
  
  plots <- fc_plots_by_season[[season_name]]
  n_plots <- length(plots)
  
  if(n_plots == 0) next
  
  # Determine grid layout
  ncols <- min(3, n_plots)
  nrows <- ceiling(n_plots / ncols)
  
  # Create title
  title <- textGrob(
    paste0("CO₂ Flux - ", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  # Arrange plots
  plots_grid <- arrangeGrob(
    grobs = plots,
    ncol = ncols,
    nrow = nrows,
    top = title
  )
  
  # Add legend
  combined <- arrangeGrob(
    plots_grid,
    shared_legend,
    ncol = 2,
    widths = c(10, 1)
  )
  
  fc_combined_figures[[season_name]] <- combined
  
  # Display
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CO2 figure for", season_name, "\n")
}

# CH4 combined figures
fch4_combined_figures <- list()

for(season_name in names(fch4_plots_by_season)) {
  
  plots <- fch4_plots_by_season[[season_name]]
  n_plots <- length(plots)
  
  if(n_plots == 0) next
  
  ncols <- min(3, n_plots)
  nrows <- ceiling(n_plots / ncols)
  
  title <- textGrob(
    paste0("CH₄ Flux - ", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  plots_grid <- arrangeGrob(
    grobs = plots,
    ncol = ncols,
    nrow = nrows,
    top = title
  )
  
  combined <- arrangeGrob(
    plots_grid,
    shared_legend,
    ncol = 2,
    widths = c(10, 1)
  )
  
  fch4_combined_figures[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CH4 figure for", season_name, "\n")
}

cat("\n=== All figures created! ===\n\n")

# ----------------------------------------------------------------------------
# SAVE FIGURES (commented out)
# ----------------------------------------------------------------------------

# Save CO2 figures
# for(season_name in names(fc_combined_figures)) {
#   filename <- paste0("figures/FC_", gsub(" ", "_", season_name), "_significant.png")
#   ggsave(filename,
#          plot = fc_combined_figures[[season_name]],
#          width = 14, height = ceiling(length(fc_plots_by_season[[season_name]]) / 3) * 4,
#          dpi = 300, bg = "white")
# }

# Save CH4 figures
# for(season_name in names(fch4_combined_figures)) {
#   filename <- paste0("figures/FCH4_", gsub(" ", "_", season_name), "_significant.png")
#   ggsave(filename,
#          plot = fch4_combined_figures[[season_name]],
#          width = 14, height = ceiling(length(fch4_plots_by_season[[season_name]]) / 3) * 4,
#          dpi = 300, bg = "white")
# }

cat("To save figures, uncomment the ggsave() sections at the end.\n")
```

#multivariate test exploration 
```{r}
# Start with ecological rationale
gls(FC ~ TA_gapfilled + TS_3_gapfilled + SWC_3_1_1,  # Temperature + moisture controls
    data = df_avg_FC,
    correlation = corAR1(form = ~ 1),
    method = "REML")

#check vif 
```


#adjusting seasonal figs 
```{r}
# ============================================================================
# Customizable Within-Season Figures (Individual + Combined)
# ============================================================================
# Purpose: Create individual figures with easy customization for stats placement
# and combined figures with legend in empty grid space
#
# Author: [Your name]
# Date: October 27, 2025
# ============================================================================

library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)
library(cowplot)

# Year colors
year_colors <- c(
  "2017" = "#E41A1C", "2018" = "#377EB8", "2019" = "#4DAF4A",
  "2020" = "#984EA3", "2021" = "#FF7F00", "2022" = "#A65628"
)

# Met variable units
met_units <- list(
  "Air Temp" = "°C", "Soil Temp" = "°C", "Soil Moisture" = "%",
  "VPD" = "hPa", "RH" = "%", "Latent Heat" = "W/m²",
  "Sensible Heat" = "W/m²", "Soil Heat Flux" = "W/m²"
)

# ----------------------------------------------------------------------------
# FUNCTION: Create individual plot with customizable stats position
# ----------------------------------------------------------------------------

create_custom_plot <- function(input_data, flux_var, met_var, season_name,
                               flux_label, met_label,
                               gls_slope, gls_p, gls_r2,
                               show_legend = FALSE,
                               show_title = TRUE,
                               stats_x_pos = 0.95,  # 0-1, fraction of x-range from left
                               stats_y_pos = 0.95,  # 0-1, fraction of y-range from bottom
                               stats_hjust = 1,     # 0=left, 0.5=center, 1=right
                               stats_vjust = 1) {   # 0=bottom, 0.5=center, 1=top
  
  # Get data
  plot_data <- input_data %>%
    dplyr::filter(season == season_name) %>%
    dplyr::filter(!is.na(!!sym(flux_var)), !is.na(!!sym(met_var))) %>%
    dplyr::select(year, DOY, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::mutate(year = as.factor(year))
  
  # Fit GLS AR(1)
  gls_model <- gls(flux ~ met, data = plot_data,
                   correlation = corAR1(form = ~ 1), method = "REML")
  
  # Predictions
  pred_grid <- data.frame(met = seq(min(plot_data$met), max(plot_data$met), length.out = 100))
  pred_grid$fitted <- predict(gls_model, newdata = pred_grid)
  
  X <- model.matrix(~ met, data = pred_grid)
  vcov_matrix <- vcov(gls_model)
  pred_grid$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
  pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
  pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
  
  # Get units
  met_unit <- met_units[[met_label]]
  if(is.null(met_unit)) met_unit <- ""
  
  # Create plot
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    geom_ribbon(data = pred_grid, aes(x = met, ymin = lower, ymax = upper),
                fill = "#4DAF4A", alpha = 0.2, inherit.aes = FALSE) +
    geom_line(data = pred_grid, aes(x = met, y = fitted),
              color = "#4DAF4A", linewidth = 1, inherit.aes = FALSE) +
    geom_point(aes(color = year), size = 2, alpha = 0.7) +
    scale_color_manual(values = year_colors, name = "Year") +
    labs(
      x = if(met_unit != "") paste0(met_label, " (", met_unit, ")") else met_label,
      y = flux_label,
      title = if(show_title) season_name else NULL
    ) +
    theme_bw(base_size = 12) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = if(show_legend) "right" else "none",
      legend.background = element_rect(fill = "white", color = "black"),
      plot.title = if(show_title) element_text(size = 11, face = "bold", hjust = 0.5) else element_blank(),
      axis.title = element_text(size = 10, face = "bold"),
      axis.text = element_text(size = 9)
    )
  
  # ========================================================================
  # CUSTOMIZABLE STATS ANNOTATION
  # ========================================================================
  # Adjust these parameters to move stats text:
  # - stats_x_pos: 0 (left) to 1 (right)
  # - stats_y_pos: 0 (bottom) to 1 (top)
  # - stats_hjust: 0 (left-align), 0.5 (center), 1 (right-align)
  # - stats_vjust: 0 (bottom-align), 0.5 (middle), 1 (top-align)
  # ========================================================================
  
  if(gls_p < 0.001) {
    p_text <- "p < 0.001"
  } else if(gls_p < 0.01) {
    p_text <- sprintf("p = %.3f", gls_p)
  } else {
    p_text <- sprintf("p = %.2f", gls_p)
  }
  
  stats_text <- paste0(
    "R² = ", sprintf("%.3f", gls_r2), "\n",
    "Slope = ", sprintf("%.4f", gls_slope), "\n",
    p_text
  )
  
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  x_pos <- x_range[1] + stats_x_pos * diff(x_range)
  y_pos <- y_range[1] + stats_y_pos * diff(y_range)
  
  p <- p +
    annotate("text", x = x_pos, y = y_pos, label = stats_text,
             hjust = stats_hjust, vjust = stats_vjust,
             size = 3, fontface = "plain", color = "black", lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# GET SIGNIFICANT RELATIONSHIPS
# ----------------------------------------------------------------------------

fc_sig <- fc_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

fch4_sig <- fch4_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

# Get seasons
seasons <- unique(c(fc_sig$season, fch4_sig$season))

cat("\n=== Creating individual figures ===\n\n")

# ----------------------------------------------------------------------------
# CREATE INDIVIDUAL CO2 PLOTS
# ----------------------------------------------------------------------------

fc_individual_plots <- list()
plot_counter <- 1

for(season_name in seasons) {
  
  season_data <- fc_sig %>% dplyr::filter(season == season_name)
  if(nrow(season_data) == 0) next
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    # Calculate R²
    season_subset <- df_avg_FC %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FC), !is.na(!!sym(met_col))) %>%
      dplyr::select(FC, met = !!sym(met_col))
    
    gls_temp <- gls(FC ~ met, data = season_subset,
                    correlation = corAR1(form = ~ 1), method = "REML")
    gls_r2 <- cor(season_subset$FC, fitted(gls_temp))^2
    
    # Create plot name
    plot_name <- paste0("fc_", gsub(" ", "_", tolower(season_name)), "_",
                       gsub(" ", "_", tolower(row$met_variable)))
    
    # Create plot (no title for combined plots, will add overall title)
    p <- create_custom_plot(
      input_data = df_avg_FC,
      flux_var = "FC",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE,
      show_title = FALSE,  # No individual titles for combined plots
      # CUSTOMIZE THESE FOR EACH PLOT:
      stats_x_pos = 0.95,   # Try 0.05 for left, 0.95 for right
      stats_y_pos = 0.95,   # Try 0.05 for bottom, 0.95 for top
      stats_hjust = 1,      # 1=right-align, 0=left-align
      stats_vjust = 1       # 1=top-align, 0=bottom-align
    )
    
    fc_individual_plots[[plot_name]] <- p
    
    cat("Created:", plot_name, "\n")
  }
}

# ----------------------------------------------------------------------------
# CREATE INDIVIDUAL CH4 PLOTS
# ----------------------------------------------------------------------------

fch4_individual_plots <- list()

for(season_name in seasons) {
  
  season_data <- fch4_sig %>% dplyr::filter(season == season_name)
  if(nrow(season_data) == 0) next
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    season_subset <- df_avg_FCH4 %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FCH4), !is.na(!!sym(met_col))) %>%
      dplyr::select(FCH4, met = !!sym(met_col))
    
    gls_temp <- gls(FCH4 ~ met, data = season_subset,
                    correlation = corAR1(form = ~ 1), method = "REML")
    gls_r2 <- cor(season_subset$FCH4, fitted(gls_temp))^2
    
    plot_name <- paste0("fch4_", gsub(" ", "_", tolower(season_name)), "_",
                       gsub(" ", "_", tolower(row$met_variable)))
    
    p <- create_custom_plot(
      input_data = df_avg_FCH4,
      flux_var = "FCH4",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE,
      show_title = FALSE,
      stats_x_pos = 0.95,
      stats_y_pos = 0.95,
      stats_hjust = 1,
      stats_vjust = 1
    )
    
    fch4_individual_plots[[plot_name]] <- p
    
    cat("Created:", plot_name, "\n")
  }
}

cat("\n=== Individual plots created ===\n")
cat("Access them with: fc_individual_plots$plot_name or fch4_individual_plots$plot_name\n\n")

# ----------------------------------------------------------------------------
# CREATE COMBINED FIGURES WITH LEGEND IN EMPTY SPACE
# ----------------------------------------------------------------------------

cat("\n=== Creating combined figures ===\n\n")

# Create a plot with legend for extraction
if(length(fc_individual_plots) > 0) {
  p_legend_source <- create_custom_plot(
    input_data = df_avg_FC, flux_var = "FC", met_var = "TA_gapfilled",
    season_name = seasons[1],
    flux_label = expression(paste("CO"[2])), met_label = "Air Temp",
    gls_slope = 0, gls_p = 0.05, gls_r2 = 0.5,
    show_legend = TRUE, show_title = FALSE
  )
  shared_legend <- get_legend(p_legend_source)
}

# CO2 Combined Figures
fc_combined_by_season <- list()

for(season_name in seasons) {
  
  # Get plots for this season
  season_plots <- fc_individual_plots[grepl(paste0("fc_", gsub(" ", "_", tolower(season_name))), 
                                            names(fc_individual_plots))]
  
  if(length(season_plots) == 0) next
  
  n_plots <- length(season_plots)
  ncols <- 3
  nrows <- ceiling(n_plots / ncols)
  total_spaces <- ncols * nrows
  
  # Create title with proper subscript
  title <- textGrob(
    paste("CO2 Flux -", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  # Add empty grobs to fill grid + legend
  all_grobs <- season_plots
  empty_spaces <- total_spaces - n_plots
  
  # If there's exactly 1 empty space, put legend there
  if(empty_spaces == 1) {
    all_grobs[[n_plots + 1]] <- shared_legend
    
    combined <- arrangeGrob(
      grobs = all_grobs,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
  } else {
    # Multiple empty spaces or none - legend on side
    plots_grid <- arrangeGrob(
      grobs = season_plots,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
    
    combined <- arrangeGrob(
      plots_grid, shared_legend,
      ncol = 2, widths = c(10, 1.5)
    )
  }
  
  fc_combined_by_season[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CO2 combined figure for", season_name, "\n")
}

# CH4 Combined Figures
fch4_combined_by_season <- list()

for(season_name in seasons) {
  
  season_plots <- fch4_individual_plots[grepl(paste0("fch4_", gsub(" ", "_", tolower(season_name))),
                                              names(fch4_individual_plots))]
  
  if(length(season_plots) == 0) next
  
  n_plots <- length(season_plots)
  ncols <- 3
  nrows <- ceiling(n_plots / ncols)
  total_spaces <- ncols * nrows
  
  title <- textGrob(
    paste("CH4 Flux -", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  all_grobs <- season_plots
  empty_spaces <- total_spaces - n_plots
  
  if(empty_spaces == 1 && season_name != "Winter") {
    # Put legend in empty space (except for Winter per your request)
    all_grobs[[n_plots + 1]] <- shared_legend
    
    combined <- arrangeGrob(
      grobs = all_grobs,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
  } else {
    # Legend on side (including Winter)
    plots_grid <- arrangeGrob(
      grobs = season_plots,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
    
    combined <- arrangeGrob(
      plots_grid, shared_legend,
      ncol = 2, widths = c(10, 1.5)
    )
  }
  
  fch4_combined_by_season[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CH4 combined figure for", season_name, "\n")
}

cat("\n=== All combined figures created! ===\n\n")

# ----------------------------------------------------------------------------
# SAVE INDIVIDUAL PLOTS (examples - customize as needed)
# ----------------------------------------------------------------------------

# Example: Save a specific individual plot
# ggsave("figures/fc_growing_season_air_temp.png",
#        plot = fc_individual_plots$fc_growing_season_air_temp,
#        width = 6, height = 5, dpi = 300, bg = "white")

# Save all individual FC plots
# for(plot_name in names(fc_individual_plots)) {
#   filename <- paste0("figures/", plot_name, ".png")
#   ggsave(filename, plot = fc_individual_plots[[plot_name]],
#          width = 6, height = 5, dpi = 300, bg = "white")
# }

#Save combined figures
for(season_name in names(fc_combined_by_season)) {
  filename <- paste0("figures/FC_", gsub(" ", "_", season_name), "_combined.png")
  ggsave(filename, plot = fc_combined_by_season[[season_name]],
         width = 14, height = ceiling(length(grep(tolower(gsub(" ", "_", season_name)),
                                                  names(fc_individual_plots))) / 3) * 4,
         dpi = 300, bg = "white")
}

cat("To customize individual plots:\n")
cat("1. Find plot name: names(fc_individual_plots) or names(fch4_individual_plots)\n")
cat("2. Adjust stats position in create_custom_plot() call\n")
cat("3. Re-run to regenerate that specific plot\n")
```


#adj 2
```{r}
# ============================================================================
# Customizable Within-Season Figures (Individual + Combined)
# ============================================================================
# Purpose: Create individual figures with easy customization for stats placement
# and combined figures with legend in empty grid space
#
# Author: [Your name]
# Date: October 27, 2025
# ============================================================================

library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)
library(cowplot)

# Year colors
year_colors <- c(
  "2017" = "#E41A1C", "2018" = "#377EB8", "2019" = "#4DAF4A",
  "2020" = "#984EA3", "2021" = "#FF7F00", "2022" = "#A65628"
)

# Met variable units
met_units <- list(
  "Air Temp" = "°C", "Soil Temp" = "°C", "Soil Moisture" = "%",
  "VPD" = "hPa", "RH" = "%", "Latent Heat" = "W/m²",
  "Sensible Heat" = "W/m²", "Soil Heat Flux" = "W/m²"
)

# ----------------------------------------------------------------------------
# FUNCTION: Create individual plot with customizable stats position
# ----------------------------------------------------------------------------

create_custom_plot <- function(input_data, flux_var, met_var, season_name,
                               flux_label, met_label,
                               gls_slope, gls_p, gls_r2,
                               show_legend = FALSE,
                               show_title = TRUE,
                               stats_x_pos = 0.95,  # 0-1, fraction of x-range from left
                               stats_y_pos = 0.95,  # 0-1, fraction of y-range from bottom
                               stats_hjust = 1,     # 0=left, 0.5=center, 1=right
                               stats_vjust = 1) {   # 0=bottom, 0.5=center, 1=top
  
  # Get data
  plot_data <- input_data %>%
    dplyr::filter(season == season_name) %>%
    dplyr::filter(!is.na(!!sym(flux_var)), !is.na(!!sym(met_var))) %>%
    dplyr::select(year, DOY, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::mutate(year = as.factor(year))
  
  # Fit GLS AR(1)
  gls_model <- gls(flux ~ met, data = plot_data,
                   correlation = corAR1(form = ~ 1), method = "REML")
  
  # Predictions
  pred_grid <- data.frame(met = seq(min(plot_data$met), max(plot_data$met), length.out = 100))
  pred_grid$fitted <- predict(gls_model, newdata = pred_grid)
  
  X <- model.matrix(~ met, data = pred_grid)
  vcov_matrix <- vcov(gls_model)
  pred_grid$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
  pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
  pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
  
  # Get units
  met_unit <- met_units[[met_label]]
  if(is.null(met_unit)) met_unit <- ""
  
  # Create plot
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    geom_ribbon(data = pred_grid, aes(x = met, ymin = lower, ymax = upper),
                fill = "#4DAF4A", alpha = 0.2, inherit.aes = FALSE) +
    geom_line(data = pred_grid, aes(x = met, y = fitted),
              color = "#4DAF4A", linewidth = 1, inherit.aes = FALSE) +
    geom_point(aes(color = year), size = 2, alpha = 0.7) +
    scale_color_manual(values = year_colors, name = "Year") +
    labs(
      x = if(met_unit != "") paste0(met_label, " (", met_unit, ")") else met_label,
      y = flux_label,
      title = if(show_title) season_name else NULL
    ) +
    theme_bw(base_size = 12) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = if(show_legend) "right" else "none",
      legend.background = element_rect(fill = "white", color = "black"),
      plot.title = if(show_title) element_text(size = 11, face = "bold", hjust = 0.5) else element_blank(),
      axis.title = element_text(size = 10, face = "bold"),
      axis.text = element_text(size = 9)
    )
  
  # ========================================================================
  # CUSTOMIZABLE STATS ANNOTATION
  # ========================================================================
  # Adjust these parameters to move stats text:
  # - stats_x_pos: 0 (left) to 1 (right)
  # - stats_y_pos: 0 (bottom) to 1 (top)
  # - stats_hjust: 0 (left-align), 0.5 (center), 1 (right-align)
  # - stats_vjust: 0 (bottom-align), 0.5 (middle), 1 (top-align)
  # ========================================================================
  
  if(gls_p < 0.001) {
    p_text <- "p < 0.001"
  } else if(gls_p < 0.01) {
    p_text <- sprintf("p = %.3f", gls_p)
  } else {
    p_text <- sprintf("p = %.2f", gls_p)
  }
  
  stats_text <- paste0(
    "R² = ", sprintf("%.3f", gls_r2), "\n",
    "Slope = ", sprintf("%.4f", gls_slope), "\n",
    p_text
  )
  
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  x_pos <- x_range[1] + stats_x_pos * diff(x_range)
  y_pos <- y_range[1] + stats_y_pos * diff(y_range)
  
  p <- p +
    annotate("text", x = x_pos, y = y_pos, label = stats_text,
             hjust = stats_hjust, vjust = stats_vjust,
             size = 3, fontface = "plain", color = "black", lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# GET SIGNIFICANT RELATIONSHIPS
# ----------------------------------------------------------------------------

fc_sig <- fc_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

fch4_sig <- fch4_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

# Get seasons
seasons <- unique(c(fc_sig$season, fch4_sig$season))

cat("\n=== Creating individual figures ===\n\n")

# ----------------------------------------------------------------------------
# CREATE INDIVIDUAL CO2 PLOTS
# ----------------------------------------------------------------------------

fc_individual_plots <- list()
plot_counter <- 1

for(season_name in seasons) {
  
  season_data <- fc_sig %>% dplyr::filter(season == season_name)
  if(nrow(season_data) == 0) next
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    # Calculate R²
    season_subset <- df_avg_FC %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FC), !is.na(!!sym(met_col))) %>%
      dplyr::select(FC, met = !!sym(met_col))
    
    gls_temp <- gls(FC ~ met, data = season_subset,
                    correlation = corAR1(form = ~ 1), method = "REML")
    gls_r2 <- cor(season_subset$FC, fitted(gls_temp))^2
    
    # Create plot name
    plot_name <- paste0("fc_", gsub(" ", "_", tolower(season_name)), "_",
                       gsub(" ", "_", tolower(row$met_variable)))
    
    # Create plot (no title for combined plots, will add overall title)
    p <- create_custom_plot(
      input_data = df_avg_FC,
      flux_var = "FC",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE,
      show_title = FALSE,  # No individual titles for combined plots
      # CUSTOMIZE THESE FOR EACH PLOT:
      stats_x_pos = 0.95,   # Try 0.05 for left, 0.95 for right
      stats_y_pos = 0.95,   # Try 0.05 for bottom, 0.95 for top
      stats_hjust = 1,      # 1=right-align, 0=left-align
      stats_vjust = 1       # 1=top-align, 0=bottom-align
    )
    
    fc_individual_plots[[plot_name]] <- p
    
    cat("Created:", plot_name, "\n")
  }
}

# ----------------------------------------------------------------------------
# CREATE INDIVIDUAL CH4 PLOTS
# ----------------------------------------------------------------------------

fch4_individual_plots <- list()

for(season_name in seasons) {
  
  season_data <- fch4_sig %>% dplyr::filter(season == season_name)
  if(nrow(season_data) == 0) next
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    season_subset <- df_avg_FCH4 %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FCH4), !is.na(!!sym(met_col))) %>%
      dplyr::select(FCH4, met = !!sym(met_col))
    
    gls_temp <- gls(FCH4 ~ met, data = season_subset,
                    correlation = corAR1(form = ~ 1), method = "REML")
    gls_r2 <- cor(season_subset$FCH4, fitted(gls_temp))^2
    
    plot_name <- paste0("fch4_", gsub(" ", "_", tolower(season_name)), "_",
                       gsub(" ", "_", tolower(row$met_variable)))
    
    p <- create_custom_plot(
      input_data = df_avg_FCH4,
      flux_var = "FCH4",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE,
      show_title = FALSE,
      stats_x_pos = 0.95,
      stats_y_pos = 0.95,
      stats_hjust = 1,
      stats_vjust = 1
    )
    
    fch4_individual_plots[[plot_name]] <- p
    
    cat("Created:", plot_name, "\n")
  }
}

cat("\n=== Individual plots created ===\n")
cat("Access them with: fc_individual_plots$plot_name or fch4_individual_plots$plot_name\n\n")

# ----------------------------------------------------------------------------
# CREATE COMBINED FIGURES WITH LEGEND IN EMPTY SPACE
# ----------------------------------------------------------------------------

cat("\n=== Creating combined figures ===\n\n")

# Create a plot with legend for extraction
if(length(fc_individual_plots) > 0) {
  p_legend_source <- create_custom_plot(
    input_data = df_avg_FC, flux_var = "FC", met_var = "TA_gapfilled",
    season_name = seasons[1],
    flux_label = expression(paste("CO"[2])), met_label = "Air Temp",
    gls_slope = 0, gls_p = 0.05, gls_r2 = 0.5,
    show_legend = TRUE, show_title = FALSE
  )
  shared_legend <- get_legend(p_legend_source)
}

# CO2 Combined Figures
fc_combined_by_season <- list()

for(season_name in seasons) {
  
  # Get plots for this season
  season_plots <- fc_individual_plots[grepl(paste0("fc_", gsub(" ", "_", tolower(season_name))), 
                                            names(fc_individual_plots))]
  
  if(length(season_plots) == 0) next
  
  n_plots <- length(season_plots)
  ncols <- 3
  nrows <- ceiling(n_plots / ncols)
  total_spaces <- ncols * nrows
  
  # Create title with proper subscript
  title <- textGrob(
    paste("CO2 Flux -", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  # Add empty grobs to fill grid + legend
  all_grobs <- season_plots
  empty_spaces <- total_spaces - n_plots
  
  # If there's exactly 1 empty space, put legend there
  if(empty_spaces == 1) {
    all_grobs[[n_plots + 1]] <- shared_legend
    
    combined <- arrangeGrob(
      grobs = all_grobs,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
  } else {
    # Multiple empty spaces or none - legend on side
    plots_grid <- arrangeGrob(
      grobs = season_plots,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
    
    combined <- arrangeGrob(
      plots_grid, shared_legend,
      ncol = 2, widths = c(10, 1.5)
    )
  }
  
  fc_combined_by_season[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CO2 combined figure for", season_name, "\n")
}

# CH4 Combined Figures
fch4_combined_by_season <- list()

for(season_name in seasons) {
  
  season_plots <- fch4_individual_plots[grepl(paste0("fch4_", gsub(" ", "_", tolower(season_name))),
                                              names(fch4_individual_plots))]
  
  if(length(season_plots) == 0) next
  
  n_plots <- length(season_plots)
  ncols <- 3
  nrows <- ceiling(n_plots / ncols)
  total_spaces <- ncols * nrows
  
  title <- textGrob(
    paste("CH4 Flux -", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  all_grobs <- season_plots
  empty_spaces <- total_spaces - n_plots
  
  if(empty_spaces == 1 && season_name != "Winter") {
    # Put legend in empty space (except for Winter per your request)
    all_grobs[[n_plots + 1]] <- shared_legend
    
    combined <- arrangeGrob(
      grobs = all_grobs,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
  } else {
    # Legend on side (including Winter)
    plots_grid <- arrangeGrob(
      grobs = season_plots,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
    
    combined <- arrangeGrob(
      plots_grid, shared_legend,
      ncol = 2, widths = c(10, 1.5)
    )
  }
  
  fch4_combined_by_season[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CH4 combined figure for", season_name, "\n")
}

cat("\n=== All combined figures created! ===\n\n")

# ----------------------------------------------------------------------------
# SAVE INDIVIDUAL AND COMBINED PLOTS
# ----------------------------------------------------------------------------

cat("\n=== Ready to save plots ===\n\n")

# ----------------------------------------------------------------------------
# SAVE INDIVIDUAL PLOTS (examples)
# ----------------------------------------------------------------------------

# Example: Save a specific individual plot
# ggsave("figures/fc_growing_season_air_temp.png",
#        plot = fc_individual_plots$fc_growing_season_air_temp,
#        width = 6, height = 5, dpi = 300, bg = "white")

# Save all individual FC plots
# for(plot_name in names(fc_individual_plots)) {
#   filename <- paste0("figures/individual/", plot_name, ".png")
#   ggsave(filename, plot = fc_individual_plots[[plot_name]],
#          width = 6, height = 5, dpi = 300, bg = "white")
# }

# Save all individual FCH4 plots
# for(plot_name in names(fch4_individual_plots)) {
#   filename <- paste0("figures/individual/", plot_name, ".png")
#   ggsave(filename, plot = fch4_individual_plots[[plot_name]],
#          width = 6, height = 5, dpi = 300, bg = "white")
# }

# ----------------------------------------------------------------------------
# SAVE COMBINED FIGURES - ONE AT A TIME WITH CUSTOM SIZING
# ----------------------------------------------------------------------------

# CO2 - Growing Season
# Adjust width/height based on number of plots in grid
# if("Growing Season" %in% names(fc_combined_by_season)) {
#   ggsave("figures/combined/FC_Growing_Season_combined.png",
#          plot = fc_combined_by_season[["Growing Season"]],
#          width = 14, height = 8, dpi = 300, bg = "white")
# }

# CO2 - Fall Senescence
# if("Fall Senescence" %in% names(fc_combined_by_season)) {
#   ggsave("figures/combined/FC_Fall_Senescence_combined.png",
#          plot = fc_combined_by_season[["Fall Senescence"]],
#          width = 14, height = 8, dpi = 300, bg = "white")
# }

# CO2 - Winter
# if("Winter" %in% names(fc_combined_by_season)) {
#   ggsave("figures/combined/FC_Winter_combined.png",
#          plot = fc_combined_by_season[["Winter"]],
#          width = 14, height = 8, dpi = 300, bg = "white")
# }

# CH4 - Growing Season
# if("Growing Season" %in% names(fch4_combined_by_season)) {
#   ggsave("figures/combined/FCH4_Growing_Season_combined.png",
#          plot = fch4_combined_by_season[["Growing Season"]],
#          width = 14, height = 6, dpi = 300, bg = "white")
# }

# CH4 - Fall Senescence
# if("Fall Senescence" %in% names(fch4_combined_by_season)) {
#   ggsave("figures/combined/FCH4_Fall_Senescence_combined.png",
#          plot = fch4_combined_by_season[["Fall Senescence"]],
#          width = 14, height = 6, dpi = 300, bg = "white")
# }

# CH4 - Winter
# if("Winter" %in% names(fch4_combined_by_season)) {
#   ggsave("figures/combined/FCH4_Winter_combined.png",
#          plot = fch4_combined_by_season[["Winter"]],
#          width = 14, height = 6, dpi = 300, bg = "white")
# }

# ----------------------------------------------------------------------------
# QUICK REFERENCE
# ----------------------------------------------------------------------------

cat("QUICK REFERENCE:\n\n")

cat("View available plots:\n")
cat("  names(fc_individual_plots)\n")
cat("  names(fch4_individual_plots)\n")
cat("  names(fc_combined_by_season)\n")
cat("  names(fch4_combined_by_season)\n\n")

cat("Save a specific combined plot:\n")
cat('  ggsave("my_figure.png", plot = fc_combined_by_season[["Growing Season"]],\n')
cat('         width = 14, height = 8, dpi = 300, bg = "white")\n\n')

cat("Sizing guidelines:\n")
cat("  - 1 row of 3 plots: height = 5-6\n")
cat("  - 2 rows of plots: height = 8-10\n")
cat("  - 3 rows of plots: height = 12-14\n")
cat("  - Width usually 14 for combined plots\n\n")

cat("To customize stats position:\n")
cat("  1. Find plot creation section above\n")
cat("  2. Adjust stats_x_pos, stats_y_pos, stats_hjust, stats_vjust\n")
cat("  3. Re-run to regenerate\n\n")

# Print what's available to save
cat("Available combined figures:\n")
if(length(fc_combined_by_season) > 0) {
  cat("  CO2:\n")
  for(season in names(fc_combined_by_season)) {
    n_plots <- length(grep(tolower(gsub(" ", "_", season)), names(fc_individual_plots), value = TRUE))
    cat(sprintf("    - %s (%d plots)\n", season, n_plots))
  }
}
if(length(fch4_combined_by_season) > 0) {
  cat("  CH4:\n")
  for(season in names(fch4_combined_by_season)) {
    n_plots <- length(grep(tolower(gsub(" ", "_", season)), names(fch4_individual_plots), value = TRUE))
    cat(sprintf("    - %s (%d plots)\n", season, n_plots))
  }
}

cat("\nUncomment the ggsave() sections above to save!\n")
```

#adjusting figs 3
```{r}
# ============================================================================
# Customizable Within-Season Figures (Individual + Combined)
# ============================================================================


library(tidyverse)
library(nlme)
library(gridExtra)
library(grid)
library(cowplot)

# Year colors
year_colors <- c(
  "2017" = "#E41A1C", "2018" = "#377EB8", "2019" = "#4DAF4A",
  "2020" = "#984EA3", "2021" = "#FF7F00", "2022" = "#A65628"
)

# Met variable units
met_units <- list(
  "Air Temp" = "°C", "Soil Temp" = "°C", "Soil Moisture" = "%",
  "VPD" = "hPa", "RH" = "%", "Latent Heat" = "W/m²",
  "Sensible Heat" = "W/m²", "Soil Heat Flux" = "W/m²"
)

# ----------------------------------------------------------------------------
# FUNCTION: Create individual plot with customizable stats position
# ----------------------------------------------------------------------------

create_custom_plot <- function(input_data, flux_var, met_var, season_name,
                               flux_label, met_label,
                               gls_slope, gls_p, gls_r2,
                               show_legend = FALSE,
                               show_title = TRUE,
                               stats_x_pos = 0.95,  # 0-1, fraction of x-range from left
                               stats_y_pos = 0.95,  # 0-1, fraction of y-range from bottom
                               stats_hjust = 1,     # 0=left, 0.5=center, 1=right
                               stats_vjust = 1) {   # 0=bottom, 0.5=center, 1=top
  
  # Get data
  plot_data <- input_data %>%
    dplyr::filter(season == season_name) %>%
    dplyr::filter(!is.na(!!sym(flux_var)), !is.na(!!sym(met_var))) %>%
    dplyr::select(year, DOY, flux = !!sym(flux_var), met = !!sym(met_var)) %>%
    dplyr::mutate(year = as.factor(year))
  
  # Fit GLS AR(1)
  gls_model <- gls(flux ~ met, data = plot_data,
                   correlation = corAR1(form = ~ 1), method = "REML")
  
  # Predictions
  pred_grid <- data.frame(met = seq(min(plot_data$met), max(plot_data$met), length.out = 100))
  pred_grid$fitted <- predict(gls_model, newdata = pred_grid)
  
  X <- model.matrix(~ met, data = pred_grid)
  vcov_matrix <- vcov(gls_model)
  pred_grid$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
  pred_grid$lower <- pred_grid$fitted - 1.96 * pred_grid$se
  pred_grid$upper <- pred_grid$fitted + 1.96 * pred_grid$se
  
  # Get units
  met_unit <- met_units[[met_label]]
  if(is.null(met_unit)) met_unit <- ""
  
  # Create plot
  p <- ggplot(plot_data, aes(x = met, y = flux)) +
    geom_ribbon(data = pred_grid, aes(x = met, ymin = lower, ymax = upper),
                fill = "#4DAF4A", alpha = 0.2, inherit.aes = FALSE) +
    geom_line(data = pred_grid, aes(x = met, y = fitted),
              color = "#4DAF4A", linewidth = 1, inherit.aes = FALSE) +
    geom_point(aes(color = year), size = 2, alpha = 0.7) +
    scale_color_manual(values = year_colors, name = "Year") +
    labs(
      x = if(met_unit != "") paste0(met_label, " (", met_unit, ")") else met_label,
      y = flux_label,
      title = if(show_title) season_name else NULL
    ) +
    theme_bw(base_size = 12) +
    theme(
      panel.grid.minor = element_blank(),
      legend.position = if(show_legend) "right" else "none",
      legend.background = element_rect(fill = "white", color = "black"),
      plot.title = if(show_title) element_text(size = 11, face = "bold", hjust = 0.5) else element_blank(),
      axis.title = element_text(size = 10, face = "bold"),
      axis.text = element_text(size = 9)
    )
  
  # ========================================================================
  # CUSTOMIZABLE STATS ANNOTATION
  # ========================================================================
  # Adjust these parameters to move stats text:
  # - stats_x_pos: 0 (left) to 1 (right)
  # - stats_y_pos: 0 (bottom) to 1 (top)
  # - stats_hjust: 0 (left-align), 0.5 (center), 1 (right-align)
  # - stats_vjust: 0 (bottom-align), 0.5 (middle), 1 (top-align)
  # ========================================================================
  
  if(gls_p < 0.001) {
    p_text <- "p < 0.001"
  } else if(gls_p < 0.01) {
    p_text <- sprintf("p = %.3f", gls_p)
  } else {
    p_text <- sprintf("p = %.2f", gls_p)
  }
  
  stats_text <- paste0(
    "R² = ", sprintf("%.3f", gls_r2), "\n",
    "Slope = ", sprintf("%.4f", gls_slope), "\n",
    p_text
  )
  
  x_range <- range(plot_data$met)
  y_range <- range(plot_data$flux)
  
  x_pos <- x_range[1] + stats_x_pos * diff(x_range)
  y_pos <- y_range[1] + stats_y_pos * diff(y_range)
  
  p <- p +
    annotate("text", x = x_pos, y = y_pos, label = stats_text,
             hjust = stats_hjust, vjust = stats_vjust,
             size = 3, fontface = "plain", color = "black", lineheight = 0.9)
  
  return(p)
}

# ----------------------------------------------------------------------------
# GET SIGNIFICANT RELATIONSHIPS
# ----------------------------------------------------------------------------

fc_sig <- fc_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

fch4_sig <- fch4_results_df %>%
  dplyr::filter(grepl("Yes", significant)) %>%
  dplyr::filter(grepl("GLS", recommended_method)) %>%
  dplyr::mutate(
    gls_slope_use = ifelse(!is.na(gls_ar1_slope), gls_ar1_slope, gls_ar2_slope),
    gls_p_use = ifelse(!is.na(gls_ar1_p), gls_ar1_p, gls_ar2_p)
  )

# Get seasons
seasons <- unique(c(fc_sig$season, fch4_sig$season))

cat("\n=== Creating individual figures ===\n\n")

# ----------------------------------------------------------------------------
# CREATE INDIVIDUAL CO2 PLOTS
# ----------------------------------------------------------------------------

fc_individual_plots <- list()
plot_counter <- 1

for(season_name in seasons) {
  
  season_data <- fc_sig %>% dplyr::filter(season == season_name)
  if(nrow(season_data) == 0) next
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    # Calculate R²
    season_subset <- df_avg_FC %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FC), !is.na(!!sym(met_col))) %>%
      dplyr::select(FC, met = !!sym(met_col))
    
    gls_temp <- gls(FC ~ met, data = season_subset,
                    correlation = corAR1(form = ~ 1), method = "REML")
    gls_r2 <- cor(season_subset$FC, fitted(gls_temp))^2
    
    # Create plot name
    plot_name <- paste0("fc_", gsub(" ", "_", tolower(season_name)), "_",
                       gsub(" ", "_", tolower(row$met_variable)))
    
    # Create plot (no title for combined plots, will add overall title)
    p <- create_custom_plot(
      input_data = df_avg_FC,
      flux_var = "FC",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CO"[2], " Flux (µmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE,
      show_title = FALSE,  # No individual titles for combined plots
      # CUSTOMIZE THESE FOR EACH PLOT:
      stats_x_pos = 0.95,   # Try 0.05 for left, 0.95 for right
      stats_y_pos = 0.95,   # Try 0.05 for bottom, 0.95 for top
      stats_hjust = 1,      # 1=right-align, 0=left-align
      stats_vjust = 1       # 1=top-align, 0=bottom-align
    )
    
    fc_individual_plots[[plot_name]] <- p
    
    cat("Created:", plot_name, "\n")
  }
}

# ----------------------------------------------------------------------------
# CREATE INDIVIDUAL CH4 PLOTS
# ----------------------------------------------------------------------------

fch4_individual_plots <- list()

for(season_name in seasons) {
  
  season_data <- fch4_sig %>% dplyr::filter(season == season_name)
  if(nrow(season_data) == 0) next
  
  for(i in 1:nrow(season_data)) {
    
    row <- season_data[i, ]
    met_col <- met_vars[[which(sapply(met_vars, function(x) x$label == row$met_variable))]]$var
    
    season_subset <- df_avg_FCH4 %>%
      dplyr::filter(season == season_name) %>%
      dplyr::filter(!is.na(FCH4), !is.na(!!sym(met_col))) %>%
      dplyr::select(FCH4, met = !!sym(met_col))
    
    gls_temp <- gls(FCH4 ~ met, data = season_subset,
                    correlation = corAR1(form = ~ 1), method = "REML")
    gls_r2 <- cor(season_subset$FCH4, fitted(gls_temp))^2
    
    plot_name <- paste0("fch4_", gsub(" ", "_", tolower(season_name)), "_",
                       gsub(" ", "_", tolower(row$met_variable)))
    
    p <- create_custom_plot(
      input_data = df_avg_FCH4,
      flux_var = "FCH4",
      met_var = met_col,
      season_name = season_name,
      flux_label = expression(paste("CH"[4], " Flux (nmol m"^-2, " s"^-1, ")")),
      met_label = row$met_variable,
      gls_slope = row$gls_slope_use,
      gls_p = row$gls_p_use,
      gls_r2 = gls_r2,
      show_legend = FALSE,
      show_title = FALSE,
      stats_x_pos = 0.95,
      stats_y_pos = 0.95,
      stats_hjust = 1,
      stats_vjust = 1
    )
    
    fch4_individual_plots[[plot_name]] <- p
    
    cat("Created:", plot_name, "\n")
  }
}

cat("\n=== Individual plots created ===\n")
cat("Access them with: fc_individual_plots$plot_name or fch4_individual_plots$plot_name\n\n")

# ----------------------------------------------------------------------------
# CREATE COMBINED FIGURES WITH LEGEND IN EMPTY SPACE
# ----------------------------------------------------------------------------

cat("\n=== Creating combined figures ===\n\n")

# Create a plot with legend for extraction
if(length(fc_individual_plots) > 0) {
  p_legend_source <- create_custom_plot(
    input_data = df_avg_FC, flux_var = "FC", met_var = "TA_gapfilled",
    season_name = seasons[1],
    flux_label = expression(paste("CO"[2])), met_label = "Air Temp",
    gls_slope = 0, gls_p = 0.05, gls_r2 = 0.5,
    show_legend = TRUE, show_title = FALSE
  )
  shared_legend <- get_legend(p_legend_source)
}

# CO2 Combined Figures
fc_combined_by_season <- list()

for(season_name in seasons) {
  
  # Get plots for this season
  season_plots <- fc_individual_plots[grepl(paste0("fc_", gsub(" ", "_", tolower(season_name))), 
                                            names(fc_individual_plots))]
  
  if(length(season_plots) == 0) next
  
  n_plots <- length(season_plots)
  ncols <- 3
  nrows <- ceiling(n_plots / ncols)
  total_spaces <- ncols * nrows
  
  # Create title with proper subscript
  title <- textGrob(
    paste("CO2 Flux -", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  # Add empty grobs to fill grid + legend
  all_grobs <- season_plots
  empty_spaces <- total_spaces - n_plots
  
  # If there's exactly 1 empty space, put legend there
  if(empty_spaces == 1) {
    all_grobs[[n_plots + 1]] <- shared_legend
    
    combined <- arrangeGrob(
      grobs = all_grobs,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
  } else {
    # Multiple empty spaces or none - legend on side
    plots_grid <- arrangeGrob(
      grobs = season_plots,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
    
    combined <- arrangeGrob(
      plots_grid, shared_legend,
      ncol = 2, widths = c(10, 1.5)
    )
  }
  
  fc_combined_by_season[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CO2 combined figure for", season_name, "\n")
}

# CH4 Combined Figures
fch4_combined_by_season <- list()

for(season_name in seasons) {
  
  season_plots <- fch4_individual_plots[grepl(paste0("fch4_", gsub(" ", "_", tolower(season_name))),
                                              names(fch4_individual_plots))]
  
  if(length(season_plots) == 0) next
  
  n_plots <- length(season_plots)
  ncols <- 3
  nrows <- ceiling(n_plots / ncols)
  total_spaces <- ncols * nrows
  
  title <- textGrob(
    paste("CH4 Flux -", season_name, ": Significant Relationships"),
    gp = gpar(fontsize = 16, fontface = "bold")
  )
  
  all_grobs <- season_plots
  empty_spaces <- total_spaces - n_plots
  
  if(empty_spaces == 1 && season_name != "Winter") {
    # Put legend in empty space (except for Winter per your request)
    all_grobs[[n_plots + 1]] <- shared_legend
    
    combined <- arrangeGrob(
      grobs = all_grobs,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
  } else {
    # Legend on side (including Winter)
    plots_grid <- arrangeGrob(
      grobs = season_plots,
      ncol = ncols,
      nrow = nrows,
      top = title
    )
    
    combined <- arrangeGrob(
      plots_grid, shared_legend,
      ncol = 2, widths = c(10, 1.5)
    )
  }
  
  fch4_combined_by_season[[season_name]] <- combined
  
  grid.newpage()
  grid.draw(combined)
  
  cat("Created CH4 combined figure for", season_name, "\n")
}

cat("\n=== All combined figures created! ===\n\n")

# ----------------------------------------------------------------------------
# SAVE INDIVIDUAL AND COMBINED PLOTS
# ----------------------------------------------------------------------------

cat("\n=== Ready to save plots ===\n\n")

# ----------------------------------------------------------------------------
# SAVE INDIVIDUAL PLOTS (examples)
# ----------------------------------------------------------------------------

# Example: Save a specific individual plot
# ggsave("figures/fc_growing_season_air_temp.png",
#        plot = fc_individual_plots$fc_growing_season_air_temp,
#        width = 6, height = 5, dpi = 300, bg = "white")

# Save all individual FC plots
# for(plot_name in names(fc_individual_plots)) {
#   filename <- paste0("figures/individual/", plot_name, ".png")
#   ggsave(filename, plot = fc_individual_plots[[plot_name]],
#          width = 6, height = 5, dpi = 300, bg = "white")
# }

# Save all individual FCH4 plots
# for(plot_name in names(fch4_individual_plots)) {
#   filename <- paste0("figures/individual/", plot_name, ".png")
#   ggsave(filename, plot = fch4_individual_plots[[plot_name]],
#          width = 6, height = 5, dpi = 300, bg = "white")
# }

# ----------------------------------------------------------------------------
# SAVE COMBINED FIGURES - ONE AT A TIME WITH CUSTOM SIZING
# ----------------------------------------------------------------------------

# CO2 - Growing Season
# Adjust width/height based on number of plots in grid
if("Growing Season" %in% names(fc_combined_by_season)) {
  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Seasonal_FC_Met_Relationships_Growing_Season_combined.png",
         plot = fc_combined_by_season[["Growing Season"]],
         width = 14, height = 8, dpi = 300, bg = "white")
}

# CO2 - Fall Senescence
# if("Fall Senescence" %in% names(fc_combined_by_season)) {
#   ggsave("figures/combined/FC_Fall_Senescence_combined.png",
#          plot = fc_combined_by_season[["Fall Senescence"]],
#          width = 14, height = 8, dpi = 300, bg = "white")
# }

# CO2 - Winter
# if("Winter" %in% names(fc_combined_by_season)) {
#   ggsave("figures/combined/FC_Winter_combined.png",
#          plot = fc_combined_by_season[["Winter"]],
#          width = 14, height = 8, dpi = 300, bg = "white")
# }

#CH4 - Growing Season
if("Growing Season" %in% names(fch4_combined_by_season)) {
  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Seasonal_FCH4_Met_Relationships_Growing_Season_combined.png",
         plot = fch4_combined_by_season[["Growing Season"]],
         width = 14, height = 6, dpi = 300, bg = "white")
}

# CH4 - Fall Senescence
# if("Fall Senescence" %in% names(fch4_combined_by_season)) {
#   ggsave("figures/combined/FCH4_Fall_Senescence_combined.png",
#          plot = fch4_combined_by_season[["Fall Senescence"]],
#          width = 14, height = 6, dpi = 300, bg = "white")
# }

# CH4 - Winter
# if("Winter" %in% names(fch4_combined_by_season)) {
#   ggsave("figures/combined/FCH4_Winter_combined.png",
#          plot = fch4_combined_by_season[["Winter"]],
#          width = 14, height = 6, dpi = 300, bg = "white")
# }

# ----------------------------------------------------------------------------
# QUICK REFERENCE
# ----------------------------------------------------------------------------

cat("QUICK REFERENCE:\n\n")

cat("View available plots:\n")
cat("  names(fc_individual_plots)\n")
cat("  names(fch4_individual_plots)\n")
cat("  names(fc_combined_by_season)\n")
cat("  names(fch4_combined_by_season)\n\n")

cat("Save a specific combined plot:\n")
cat('  ggsave("my_figure.png", plot = fc_combined_by_season[["Growing Season"]],\n')
cat('         width = 14, height = 8, dpi = 300, bg = "white")\n\n')

cat("Sizing guidelines:\n")
cat("  - 1 row of 3 plots: height = 5-6\n")
cat("  - 2 rows of plots: height = 8-10\n")
cat("  - 3 rows of plots: height = 12-14\n")
cat("  - Width usually 14 for combined plots\n\n")

cat("To customize stats position:\n")
cat("  1. Find plot creation section above\n")
cat("  2. Adjust stats_x_pos, stats_y_pos, stats_hjust, stats_vjust\n")
cat("  3. Re-run to regenerate\n\n")

# Print what's available to save
cat("Available combined figures:\n")
if(length(fc_combined_by_season) > 0) {
  cat("  CO2:\n")
  for(season in names(fc_combined_by_season)) {
    n_plots <- length(grep(tolower(gsub(" ", "_", season)), names(fc_individual_plots), value = TRUE))
    cat(sprintf("    - %s (%d plots)\n", season, n_plots))
  }
}
if(length(fch4_combined_by_season) > 0) {
  cat("  CH4:\n")
  for(season in names(fch4_combined_by_season)) {
    n_plots <- length(grep(tolower(gsub(" ", "_", season)), names(fch4_individual_plots), value = TRUE))
    cat(sprintf("    - %s (%d plots)\n", season, n_plots))
  }
}

cat("\nUncomment the ggsave() sections above to save!\n")
```

#Growing Season only 

###Create datasets for FC and FCH4 with only growing season 
```{r}
df_avg_FC_growing <- df_avg_FC %>%
  filter(season == "Growing Season")

df_avg_FCH4_growing <- df_avg_FCH4 %>%
  filter(season == "Growing Season")

# Define year colors for consistency across all plots
year_colors <- c(
  "2017" = "#E41A1C", "2018" = "#377EB8", "2019" = "#4DAF4A",
  "2020" = "#984EA3", "2021" = "#FF7F00", "2022" = "#A65628"
)
```



###FCH4 - individual plots 
```{r}
# Load required libraries
library(tidyverse)  # For data manipulation and ggplot2
library(nlme)       # For GLS models with AR(1) correlation structure

# Set global theme for all plots (optional - makes text bigger by default)
theme_set(theme_bw(base_size = 14))


# ============================================================================
# METHANE (CH4) FLUX RELATIONSHIPS - GROWING SEASON (DAILY AVERAGES)
# ============================================================================

# ----------------------------------------------------------------------------
# Plot 1: CH4 Flux vs Soil Moisture
# ----------------------------------------------------------------------------

# First, fit the GLS model with AR(1) autocorrelation structure
# AR(1) accounts for temporal correlation in time series data

model_CH4_SWC <- gls(FCH4 ~ SWC_3_1_1, 
                     data = df_avg_FCH4_growing,
                     correlation = corAR1(form = ~ 1),  # AR(1) correlation
                     na.action = na.omit)

# Extract model statistics for the plot
slope_CH4_SWC <- summary(model_CH4_SWC)$tTable["SWC_3_1_1", "Value"]  # Slope
p_CH4_SWC <- summary(model_CH4_SWC)$tTable["SWC_3_1_1", "p-value"]  # P-value

# Calculate pseudo R-squared for GLS (correlation between observed and fitted)
# This gives us an R² equivalent for GLS models
fitted_vals <- fitted(model_CH4_SWC)
observed_vals <- df_avg_FCH4_growing$FCH4[!is.na(df_avg_FCH4_growing$FCH4) & 
                                            !is.na(df_avg_FCH4_growing$SWC_3_1_1)]
r2_pseudo_CH4_SWC <- cor(observed_vals, fitted_vals)^2

# Create prediction data for the fitted line
# This spans the range of soil moisture values in your data
pred_data_CH4_SWC <- data.frame(
  SWC_3_1_1 = seq(min(df_avg_FCH4_growing$SWC_3_1_1, na.rm = TRUE),
                  max(df_avg_FCH4_growing$SWC_3_1_1, na.rm = TRUE),
                  length.out = 100)  # 100 points for smooth line
)

# Get predictions from the GLS model
# For GLS, predict() returns a simple vector of fitted values
pred_vals_CH4_SWC <- predict(model_CH4_SWC, newdata = pred_data_CH4_SWC)
pred_data_CH4_SWC$fit <- pred_vals_CH4_SWC

# Calculate proper SE using the variance-covariance matrix
X <- model.matrix(~ SWC_3_1_1, data = pred_data_CH4_SWC)
vcov_matrix <- vcov(model_CH4_SWC)
pred_data_CH4_SWC$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_CH4_SWC$lower <- pred_data_CH4_SWC$fit - 1.96 * pred_data_CH4_SWC$se
pred_data_CH4_SWC$upper <- pred_data_CH4_SWC$fit + 1.96 * pred_data_CH4_SWC$se


# Create the plot
plot_CH4_SWC <- ggplot(df_avg_FCH4_growing, aes(x = SWC_3_1_1, y = FCH4)) +
  # Add confidence interval ribbon (semi-transparent)
  geom_ribbon(data = pred_data_CH4_SWC, 
              aes(x = SWC_3_1_1, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  # Add fitted line
  geom_line(data = pred_data_CH4_SWC, 
            aes(x = SWC_3_1_1, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  # Add data points colored by year (smaller points since we have many more now!)
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  # Add statistics text box in upper left corner
  annotate("text", 
           x = min(df_avg_FCH4_growing$SWC_3_1_1, na.rm = TRUE) + 
             0.05 * diff(range(df_avg_FCH4_growing$SWC_3_1_1, na.rm = TRUE)),
           y = max(df_avg_FCH4_growing$FCH4, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np = %.3f", 
                          r2_pseudo_CH4_SWC, slope_CH4_SWC, p_CH4_SWC),
           hjust = 0, vjust = 1, size = 5, fontface = "bold") +
  # Axis labels with proper formatting
  labs(x = "Soil Moisture (%)", 
       y = expression(bold("CH"[4]*" Flux (nmol m"^-2*" s"^-1*")")),
       color = "Year") +
  # Use custom year colors
  scale_color_manual(values = year_colors) +
  # Clean theme with larger text
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()  # Remove minor gridlines for cleaner look
  )

# Display the plot
print(plot_CH4_SWC)



# ----------------------------------------------------------------------------
# Plot 2: CH4 Flux vs VPD (Vapor Pressure Deficit)
# ----------------------------------------------------------------------------


model_CH4_VPD <- gls(FCH4 ~ VPD, 
                     data = df_avg_FCH4_growing,
                     correlation = corAR1(form = ~ 1),
                     na.action = na.omit)

slope_CH4_VPD <- summary(model_CH4_VPD)$tTable["VPD", "Value"]
p_CH4_VPD <- summary(model_CH4_VPD)$tTable["VPD", "p-value"]

fitted_vals <- fitted(model_CH4_VPD)
observed_vals <- df_avg_FCH4_growing$FCH4[!is.na(df_avg_FCH4_growing$FCH4) & 
                                            !is.na(df_avg_FCH4_growing$VPD)]
r2_pseudo_CH4_VPD <- cor(observed_vals, fitted_vals)^2

pred_data_CH4_VPD <- data.frame(
  VPD = seq(min(df_avg_FCH4_growing$VPD, na.rm = TRUE),
            max(df_avg_FCH4_growing$VPD, na.rm = TRUE),
            length.out = 100)
)



pred_vals_CH4_VPD <- predict(model_CH4_VPD, newdata = pred_data_CH4_VPD)
pred_data_CH4_VPD$fit <- pred_vals_CH4_VPD
#SE for line 
X <- model.matrix(~ VPD, data = pred_data_CH4_VPD)
vcov_matrix <- vcov(model_CH4_VPD)
pred_data_CH4_VPD$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_CH4_VPD$lower <- pred_data_CH4_VPD$fit - 1.96 * pred_data_CH4_VPD$se
pred_data_CH4_VPD$upper <- pred_data_CH4_VPD$fit + 1.96 * pred_data_CH4_VPD$se

#Plot
plot_CH4_VPD <- ggplot(df_avg_FCH4_growing, aes(x = VPD, y = FCH4)) +
  geom_ribbon(data = pred_data_CH4_VPD, 
              aes(x = VPD, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_CH4_VPD, 
            aes(x = VPD, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FCH4_growing$VPD, na.rm = TRUE) + 
             0.05 * diff(range(df_avg_FCH4_growing$VPD, na.rm = TRUE)),
           y = max(df_avg_FCH4_growing$FCH4, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np = %.3f", 
                          r2_pseudo_CH4_VPD, slope_CH4_VPD, p_CH4_VPD),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = "VPD (hPa)", 
       y = expression(bold("CH"[4]*" Flux (nmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_CH4_VPD)


# ----------------------------------------------------------------------------
# Plot 3: CH4 Flux vs RH (Relative Humidity)
# ----------------------------------------------------------------------------


model_CH4_RH <- gls(FCH4 ~ RH, 
                    data = df_avg_FCH4_growing,
                    correlation = corAR1(form = ~ 1),
                    na.action = na.omit)

slope_CH4_RH <- summary(model_CH4_RH)$tTable["RH", "Value"]
p_CH4_RH <- summary(model_CH4_RH)$tTable["RH", "p-value"]

fitted_vals <- fitted(model_CH4_RH)
observed_vals <- df_avg_FCH4_growing$FCH4[!is.na(df_avg_FCH4_growing$FCH4) & 
                                            !is.na(df_avg_FCH4_growing$RH)]
r2_pseudo_CH4_RH <- cor(observed_vals, fitted_vals)^2

pred_data_CH4_RH <- data.frame(
  RH = seq(min(df_avg_FCH4_growing$RH, na.rm = TRUE),
           max(df_avg_FCH4_growing$RH, na.rm = TRUE),
           length.out = 100)
)

pred_vals_CH4_RH <- predict(model_CH4_RH, newdata = pred_data_CH4_RH)
pred_data_CH4_RH$fit <- pred_vals_CH4_RH

#SE for line 
X <- model.matrix(~ RH, data = pred_data_CH4_RH)
vcov_matrix <- vcov(model_CH4_RH)
pred_data_CH4_RH$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_CH4_RH$lower <- pred_data_CH4_RH$fit - 1.96 * pred_data_CH4_RH$se
pred_data_CH4_RH$upper <- pred_data_CH4_RH$fit + 1.96 * pred_data_CH4_RH$se

#Plot
plot_CH4_RH <- ggplot(df_avg_FCH4_growing, aes(x = RH, y = FCH4)) +
  geom_ribbon(data = pred_data_CH4_RH, 
              aes(x = RH, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_CH4_RH, 
            aes(x = RH, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = min(df_avg_FCH4_growing$RH, na.rm = TRUE) + 
             0.05 * diff(range(df_avg_FCH4_growing$RH, na.rm = TRUE)),
           y = max(df_avg_FCH4_growing$FCH4, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np < 0.001", 
                          r2_pseudo_CH4_RH, slope_CH4_RH),
           hjust = 0, vjust = 1, size = 5, fontface = "bold") +
  labs(x = "RH (%)", 
       y = expression(bold("CH"[4]*" Flux (nmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_CH4_RH)


# ----------------------------------------------------------------------------
# Plot 4: CH4 Flux vs Sensible Heat Flux (H)
# ----------------------------------------------------------------------------

model_CH4_H <- gls(FCH4 ~ H, 
                   data = df_avg_FCH4_growing,
                   correlation = corAR1(form = ~ 1),
                   na.action = na.omit)

slope_CH4_H <- summary(model_CH4_H)$tTable["H", "Value"]
p_CH4_H <- summary(model_CH4_H)$tTable["H", "p-value"]

fitted_vals <- fitted(model_CH4_H)
observed_vals <- df_avg_FCH4_growing$FCH4[!is.na(df_avg_FCH4_growing$FCH4) & 
                                            !is.na(df_avg_FCH4_growing$H)]
r2_pseudo_CH4_H <- cor(observed_vals, fitted_vals)^2

pred_data_CH4_H <- data.frame(
  H = seq(min(df_avg_FCH4_growing$H, na.rm = TRUE),
          max(df_avg_FCH4_growing$H, na.rm = TRUE),
          length.out = 100)
)

pred_vals_CH4_H <- predict(model_CH4_H, newdata = pred_data_CH4_H)
pred_data_CH4_H$fit <- pred_vals_CH4_H

#SE for line
X <- model.matrix(~ H, data = pred_data_CH4_H)
vcov_matrix <- vcov(model_CH4_H)
pred_data_CH4_H$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_CH4_H$lower <- pred_data_CH4_H$fit - 1.96 * pred_data_CH4_H$se
pred_data_CH4_H$upper <- pred_data_CH4_H$fit + 1.96 * pred_data_CH4_H$se

#plot
plot_CH4_H <- ggplot(df_avg_FCH4_growing, aes(x = H, y = FCH4)) +
  geom_ribbon(data = pred_data_CH4_H, 
              aes(x = H, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_CH4_H, 
            aes(x = H, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FCH4_growing$H, na.rm = TRUE) + 
             0.05 * diff(range(df_avg_FCH4_growing$H, na.rm = TRUE)),
           y = max(df_avg_FCH4_growing$FCH4, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np = %.3f", 
                          r2_pseudo_CH4_H, slope_CH4_H, p_CH4_H),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = expression(bold("Sensible Heat Flux (W m"^-2*")")), 
       y = expression(bold("CH"[4]*" Flux (nmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_CH4_H)




# ----------------------------------------------------------------------------
# Plot 5: CH4 Flux vs Soil Heat Flux (G)
# ----------------------------------------------------------------------------

model_CH4_G <- gls(FCH4 ~ G_1_1_1, 
                   data = df_avg_FCH4_growing,
                   correlation = corAR1(form = ~ 1),
                   na.action = na.omit)

slope_CH4_G <- summary(model_CH4_G)$tTable["G_1_1_1", "Value"]
p_CH4_G <- summary(model_CH4_G)$tTable["G_1_1_1", "p-value"]

fitted_vals <- fitted(model_CH4_G)
observed_vals <- df_avg_FCH4_growing$FCH4[!is.na(df_avg_FCH4_growing$FCH4) & 
                                            !is.na(df_avg_FCH4_growing$G_1_1_1)]
r2_pseudo_CH4_G <- cor(observed_vals, fitted_vals)^2

pred_data_CH4_G <- data.frame(
  G_1_1_1 = seq(min(df_avg_FCH4_growing$G_1_1_1, na.rm = TRUE),
                max(df_avg_FCH4_growing$G_1_1_1, na.rm = TRUE),
                length.out = 100)
)

pred_vals_CH4_G <- predict(model_CH4_G, newdata = pred_data_CH4_G)
pred_data_CH4_G$fit <- pred_vals_CH4_G

#SE for line
X <- model.matrix(~ G_1_1_1, data = pred_data_CH4_G)
vcov_matrix <- vcov(model_CH4_G)
pred_data_CH4_G$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_CH4_G$lower <- pred_data_CH4_G$fit - 1.96 * pred_data_CH4_G$se
pred_data_CH4_G$upper <- pred_data_CH4_G$fit + 1.96 * pred_data_CH4_G$se


#Make legend large here, this is the legend you'll extract for the combined plot 
plot_CH4_G <- ggplot(df_avg_FCH4_growing, aes(x = G_1_1_1, y = FCH4)) +
  geom_ribbon(data = pred_data_CH4_G, 
              aes(x = G_1_1_1, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_CH4_G, 
            aes(x = G_1_1_1, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FCH4_growing$G_1_1_1, na.rm = TRUE) + 
             0.05 * diff(range(df_avg_FCH4_growing$G_1_1_1, na.rm = TRUE)),
           y = max(df_avg_FCH4_growing$FCH4, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np = %.3f", 
                          r2_pseudo_CH4_G, slope_CH4_G, p_CH4_G),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = expression(bold("Soil Heat Flux (W m"^-2*")")), #have to bold within expression as when you use expressions, bolding the axis titles won't work 
       y = expression(bold("CH"[4]*" Flux (nmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  guides(color = guide_legend(override.aes = list(size = 5)))+
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 18, face = "bold"),
    legend.text = element_text(size = 16, face = "bold"),
    legend.position = "right",
    legend.key.size = unit(1.2, "cm"),  # NEW LINE - makes boxes bigger
    panel.grid.minor = element_blank()
  )

print(plot_CH4_G)


```
#### FCH4 combined fig
```{r}
library(gridExtra)
library(grid)

# First, extract the legend from one of the plots
get_legend <- function(myplot) {
  tmp <- ggplot_gtable(ggplot_build(myplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}

# Extract legend from one plot
legend_plot <- get_legend(plot_CH4_G)


# Remove legends from all individual plots
plot_CH4_SWC_no_leg <- plot_CH4_SWC + theme(legend.position = "none")
plot_CH4_VPD_no_leg <- plot_CH4_VPD + theme(legend.position = "none")
plot_CH4_RH_no_leg <- plot_CH4_RH + theme(legend.position = "none")
plot_CH4_H_no_leg <- plot_CH4_H + theme(legend.position = "none")
plot_CH4_G_no_leg <- plot_CH4_G + theme(legend.position = "none")

# Combine plots with legend in 6th position (3 columns x 2 rows)
combined_CH4 <- grid.arrange(
  plot_CH4_SWC_no_leg, 
  plot_CH4_VPD_no_leg, 
  plot_CH4_RH_no_leg,
  plot_CH4_H_no_leg, 
  plot_CH4_G_no_leg, 
  legend_plot,
  ncol = 3, 
  nrow = 2,
  top = textGrob(expression(bold("CH"[4]*" Flux - Growing Season: Significant Relationships")), 
                 gp = gpar(fontsize = 20))

)

# Display
print(combined_CH4)


```

#Save combined_CH4
```{r}
  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Seasonal_FCH4_Met_Relationships_Growing_Season_combined2.png", combined_CH4,
         width = 14, height = 8, dpi = 600) 
```


#### FC - individual plots 

```{r}
# Define year colors for consistency across all plots
year_colors <- c(
  "2017" = "#E41A1C", "2018" = "#377EB8", "2019" = "#4DAF4A",
  "2020" = "#984EA3", "2021" = "#FF7F00", "2022" = "#A65628"
)

# ============================================================================
# CO2 FLUX RELATIONSHIPS - GROWING SEASON (DAILY AVERAGES)
# ============================================================================
# Note: Negative FC values = CO2 uptake (photosynthesis)
# All relationships show more negative values (more uptake) with higher met variables

# ----------------------------------------------------------------------------
# Plot 1: CO2 Flux vs Air Temperature
# ----------------------------------------------------------------------------


model_FC_TA <- gls(FC ~ TA_gapfilled, 
                   data = df_avg_FC_growing,
                   correlation = corAR1(form = ~ 1),
                   na.action = na.omit)

slope_FC_TA <- summary(model_FC_TA)$tTable["TA_gapfilled", "Value"]
p_FC_TA <- summary(model_FC_TA)$tTable["TA_gapfilled", "p-value"]

fitted_vals <- fitted(model_FC_TA)
observed_vals <- df_avg_FC_growing$FC[!is.na(df_avg_FC_growing$FC) & 
                                       !is.na(df_avg_FC_growing$TA_gapfilled)]
r2_pseudo_FC_TA <- cor(observed_vals, fitted_vals)^2

pred_data_FC_TA <- data.frame(
  TA_gapfilled = seq(min(df_avg_FC_growing$TA_gapfilled, na.rm = TRUE),
                     max(df_avg_FC_growing$TA_gapfilled, na.rm = TRUE),
                     length.out = 100)
)

pred_vals_FC_TA <- predict(model_FC_TA, newdata = pred_data_FC_TA)
pred_data_FC_TA$fit <- pred_vals_FC_TA

#SE for line 
X <- model.matrix(~ TA_gapfilled, data = pred_data_FC_TA)
vcov_matrix <- vcov(model_FC_TA)
pred_data_FC_TA$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_FC_TA$lower <- pred_data_FC_TA$fit - 1.96 * pred_data_FC_TA$se
pred_data_FC_TA$upper <- pred_data_FC_TA$fit + 1.96 * pred_data_FC_TA$se

#Plot
plot_FC_TA <- ggplot(df_avg_FC_growing, aes(x = TA_gapfilled, y = FC)) +
  geom_ribbon(data = pred_data_FC_TA, 
              aes(x = TA_gapfilled, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_FC_TA, 
            aes(x = TA_gapfilled, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FC_growing$TA_gapfilled, na.rm = TRUE) - 
             0.05 * diff(range(df_avg_FC_growing$TA_gapfilled, na.rm = TRUE)),
           y = max(df_avg_FC_growing$FC, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np = %.3f", 
                          r2_pseudo_FC_TA, slope_FC_TA, p_FC_TA),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = "Air Temp GF (°C)", 
       y = expression(bold("CO"[2]*" Flux (µmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_FC_TA)




# ----------------------------------------------------------------------------
# Plot 2: CO2 Flux vs Soil Temperature
# ----------------------------------------------------------------------------
# Negative relationship - warmer soil = more CO2 uptake

model_FC_TS <- gls(FC ~ TS_3_gapfilled, 
                   data = df_avg_FC_growing,
                   correlation = corAR1(form = ~ 1),
                   na.action = na.omit)

slope_FC_TS <- summary(model_FC_TS)$tTable["TS_3_gapfilled", "Value"]
p_FC_TS <- summary(model_FC_TS)$tTable["TS_3_gapfilled", "p-value"]

fitted_vals <- fitted(model_FC_TS)
observed_vals <- df_avg_FC_growing$FC[!is.na(df_avg_FC_growing$FC) & 
                                       !is.na(df_avg_FC_growing$TS_3_gapfilled)]
r2_pseudo_FC_TS <- cor(observed_vals, fitted_vals)^2

pred_data_FC_TS <- data.frame(
  TS_3_gapfilled = seq(min(df_avg_FC_growing$TS_3_gapfilled, na.rm = TRUE),
                       max(df_avg_FC_growing$TS_3_gapfilled, na.rm = TRUE),
                       length.out = 100)
)

pred_vals_FC_TS <- predict(model_FC_TS, newdata = pred_data_FC_TS)
pred_data_FC_TS$fit <- pred_vals_FC_TS

#SE for line
X <- model.matrix(~ TS_3_gapfilled, data = pred_data_FC_TS)
vcov_matrix <- vcov(model_FC_TS)
pred_data_FC_TS$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_FC_TS$lower <- pred_data_FC_TS$fit - 1.96 * pred_data_FC_TS$se
pred_data_FC_TS$upper <- pred_data_FC_TS$fit + 1.96 * pred_data_FC_TS$se

#Plot
plot_FC_TS <- ggplot(df_avg_FC_growing, aes(x = TS_3_gapfilled, y = FC)) +
  geom_ribbon(data = pred_data_FC_TS, 
              aes(x = TS_3_gapfilled, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_FC_TS, 
            aes(x = TS_3_gapfilled, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FC_growing$TS_3_gapfilled, na.rm = TRUE) - 
             0.05 * diff(range(df_avg_FC_growing$TS_3_gapfilled, na.rm = TRUE)),
           y = max(df_avg_FC_growing$FC, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np < 0.001", 
                          r2_pseudo_FC_TS, slope_FC_TS),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = "Soil Temp GF (°C)", 
        y = expression(bold("CO"[2]*" Flux (µmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_FC_TS)



# ----------------------------------------------------------------------------
# Plot 3: CO2 Flux vs Latent Heat Flux (LE)
# ----------------------------------------------------------------------------

model_FC_LE <- gls(FC ~ LE, 
                   data = df_avg_FC_growing,
                   correlation = corAR1(form = ~ 1),
                   na.action = na.omit)

slope_FC_LE <- summary(model_FC_LE)$tTable["LE", "Value"]
p_FC_LE <- summary(model_FC_LE)$tTable["LE", "p-value"]

fitted_vals <- fitted(model_FC_LE)
observed_vals <- df_avg_FC_growing$FC[!is.na(df_avg_FC_growing$FC) & 
                                       !is.na(df_avg_FC_growing$LE)]
r2_pseudo_FC_LE <- cor(observed_vals, fitted_vals)^2

pred_data_FC_LE <- data.frame(
  LE = seq(min(df_avg_FC_growing$LE, na.rm = TRUE),
           max(df_avg_FC_growing$LE, na.rm = TRUE),
           length.out = 100)
)

pred_vals_FC_LE <- predict(model_FC_LE, newdata = pred_data_FC_LE)
pred_data_FC_LE$fit <- pred_vals_FC_LE

#SE for line
X <- model.matrix(~ LE, data = pred_data_FC_LE)
vcov_matrix <- vcov(model_FC_LE)
pred_data_FC_LE$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_FC_LE$lower <- pred_data_FC_LE$fit - 1.96 * pred_data_FC_LE$se
pred_data_FC_LE$upper <- pred_data_FC_LE$fit + 1.96 * pred_data_FC_LE$se

#plot
plot_FC_LE <- ggplot(df_avg_FC_growing, aes(x = LE, y = FC)) +
  geom_ribbon(data = pred_data_FC_LE, 
              aes(x = LE, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_FC_LE, 
            aes(x = LE, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FC_growing$LE, na.rm = TRUE) - 
             0.05 * diff(range(df_avg_FC_growing$LE, na.rm = TRUE)),
           y = max(df_avg_FC_growing$FC, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np < 0.001", 
                          r2_pseudo_FC_LE, slope_FC_LE),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = expression(bold("Latent Heat (W m"^-2*")")), 
    y = expression(bold("CO"[2]*" Flux (µmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_FC_LE)




# ----------------------------------------------------------------------------
# Plot 4: CO2 Flux vs Sensible Heat Flux (H)
# ----------------------------------------------------------------------------


model_FC_H <- gls(FC ~ H, 
                  data = df_avg_FC_growing,
                  correlation = corAR1(form = ~ 1),
                  na.action = na.omit)

slope_FC_H <- summary(model_FC_H)$tTable["H", "Value"]
p_FC_H <- summary(model_FC_H)$tTable["H", "p-value"]

fitted_vals <- fitted(model_FC_H)
observed_vals <- df_avg_FC_growing$FC[!is.na(df_avg_FC_growing$FC) & 
                                       !is.na(df_avg_FC_growing$H)]
r2_pseudo_FC_H <- cor(observed_vals, fitted_vals)^2

pred_data_FC_H <- data.frame(
  H = seq(min(df_avg_FC_growing$H, na.rm = TRUE),
          max(df_avg_FC_growing$H, na.rm = TRUE),
          length.out = 100)
)

pred_vals_FC_H <- predict(model_FC_H, newdata = pred_data_FC_H)
pred_data_FC_H$fit <- pred_vals_FC_H

#SE for line
X <- model.matrix(~ H, data = pred_data_FC_H)
vcov_matrix <- vcov(model_FC_H)
pred_data_FC_H$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_FC_H$lower <- pred_data_FC_H$fit - 1.96 * pred_data_FC_H$se
pred_data_FC_H$upper <- pred_data_FC_H$fit + 1.96 * pred_data_FC_H$se

#plot

plot_FC_H <- ggplot(df_avg_FC_growing, aes(x = H, y = FC)) +
  geom_ribbon(data = pred_data_FC_H, 
              aes(x = H, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_FC_H, 
            aes(x = H, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FC_growing$H, na.rm = TRUE) - 
             0.05 * diff(range(df_avg_FC_growing$H, na.rm = TRUE)),
           y = max(df_avg_FC_growing$FC, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.2f\nSlope = %.2f\np < 0.001", 
                          r2_pseudo_FC_H, slope_FC_H),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = expression(bold("Sensible Heat Flux (W m"^-2*")")), 
      y = expression(bold("CO"[2]*" Flux (µmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    panel.grid.minor = element_blank()
  )

print(plot_FC_H)




# ----------------------------------------------------------------------------
# Plot 5: CO2 Flux vs Soil Heat Flux (G)
# ----------------------------------------------------------------------------


model_FC_G <- gls(FC ~ G_1_1_1, 
                  data = df_avg_FC_growing,
                  correlation = corAR1(form = ~ 1),
                  na.action = na.omit)

slope_FC_G <- summary(model_FC_G)$tTable["G_1_1_1", "Value"]
p_FC_G <- summary(model_FC_G)$tTable["G_1_1_1", "p-value"]

fitted_vals <- fitted(model_FC_G)
observed_vals <- df_avg_FC_growing$FC[!is.na(df_avg_FC_growing$FC) & 
                                       !is.na(df_avg_FC_growing$G_1_1_1)]
r2_pseudo_FC_G <- cor(observed_vals, fitted_vals)^2

pred_data_FC_G <- data.frame(
  G_1_1_1 = seq(min(df_avg_FC_growing$G_1_1_1, na.rm = TRUE),
                max(df_avg_FC_growing$G_1_1_1, na.rm = TRUE),
                length.out = 100)
)

pred_vals_FC_G <- predict(model_FC_G, newdata = pred_data_FC_G)
pred_data_FC_G$fit <- pred_vals_FC_G

#SE for line
X <- model.matrix(~ G_1_1_1, data = pred_data_FC_G)
vcov_matrix <- vcov(model_FC_G)
pred_data_FC_G$se <- sqrt(diag(X %*% vcov_matrix %*% t(X)))
pred_data_FC_G$lower <- pred_data_FC_G$fit - 1.96 * pred_data_FC_G$se
pred_data_FC_G$upper <- pred_data_FC_G$fit + 1.96 * pred_data_FC_G$se


#Make legend big here, to use for the combined plot 
plot_FC_G <- ggplot(df_avg_FC_growing, aes(x = G_1_1_1, y = FC)) +
  geom_ribbon(data = pred_data_FC_G, 
              aes(x = G_1_1_1, y = fit, ymin = lower, ymax = upper),
              fill = "darkgreen", alpha = 0.2, inherit.aes = FALSE) +
  geom_line(data = pred_data_FC_G, 
            aes(x = G_1_1_1, y = fit),
            color = "darkgreen", size = 1.2, inherit.aes = FALSE) +
  geom_point(aes(color = factor(year)), size = 2, alpha = 0.5) +
  annotate("text", 
           x = max(df_avg_FC_growing$G_1_1_1, na.rm = TRUE) - 
             0.05 * diff(range(df_avg_FC_growing$G_1_1_1, na.rm = TRUE)),
           y = max(df_avg_FC_growing$FC, na.rm = TRUE) * 0.95,
           label = sprintf("R² = %.3f\nSlope = %.4f\np < 0.001", 
                          r2_pseudo_FC_G, slope_FC_G),
           hjust = 1, vjust = 1, size = 5, fontface = "bold") +
  labs(x = expression(bold("Soil Heat Flux (W m"^-2*")")), 
        y = expression(bold("CO"[2]*" Flux (µmol m"^-2*" s"^-1*")")),
       color = "Year") +
  scale_color_manual(values = year_colors) +
  guides(color = guide_legend(override.aes = list(size = 7)))+
  theme_bw(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 14, face = "bold"),
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14, face = "bold"),
    legend.position = "right",
    legend.key.size = unit(1.4, "cm"),
    panel.grid.minor = element_blank()
  )

print(plot_FC_G)


```


#### FC combined fig
```{r}
# ============================================================================
# COMBINING PLOTS WITH GRIDEXTRA (SHARED LEGEND)
# ============================================================================

# Function to extract legend from a ggplot
get_legend <- function(myplot) {
  tmp <- ggplot_gtable(ggplot_build(myplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}

# Extract legend from one plot
legend_plot <- get_legend(plot_FC_G)

# Remove legends from all FC plots
plot_FC_TA_no_leg <- plot_FC_TA + theme(legend.position = "none")
plot_FC_TS_no_leg <- plot_FC_TS + theme(legend.position = "none")
plot_FC_LE_no_leg <- plot_FC_LE + theme(legend.position = "none")
plot_FC_H_no_leg <- plot_FC_H + theme(legend.position = "none")
plot_FC_G_no_leg <- plot_FC_G + theme(legend.position = "none")

# Combine FC plots (3 columns x 2 rows, legend in 6th position)
combined_FC <- grid.arrange(
  plot_FC_TA_no_leg, 
  plot_FC_TS_no_leg, 
  plot_FC_LE_no_leg,
  plot_FC_H_no_leg, 
  plot_FC_G_no_leg, 
  legend_plot,
  ncol = 3, 
  nrow = 2,
  top = textGrob(expression(bold("CO"[2]*" Flux - Growing Season: Significant Relationships")), 
                 gp = gpar(fontsize = 20))
)

# Display combined FC figure
print(combined_FC)

```

#Save combined_CH4
```{r}
  ggsave("C:/Users/kkent/Documents/Github Flux Network/Council_Flux_Analysis_Paper/Council Figures/Seasonal_FC_Met_Relationships_Growing_Season_combined2.png", combined_FC,
         width = 14, height = 10, dpi = 600) 
```

#end script 



