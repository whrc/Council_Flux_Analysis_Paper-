---
title: "Council CH4 and temp / moisture" #playing around with empirical model using soil temp and soil moisture for methane 
output: html_document
date: "2024-12-26"
#Notes on SWC and temp:

#Lit & the incMSE results seems to say moisture might be more important than soil temp 

#SWC
#SWC also broken up by location, just like temp 
#  SWC_1_1_1 % Soil water content (15cm depth) – margin pond
# SWC_2_1_1 % Soil water content (15cm depth) – lichen/berries
# SWC_3_1_1 % Soil water content (15cm depth) - tussock ***** switch to using this one ** (used SWC1 before, by margin pond, switching to SWC3, tussock)

#Temp
#quick look at the different temp profiles (all at 15 cm depth, diff locations)
# sum(is.na(df$TS_1_1_1)) #60277 NA's in temp by margin pond 
# sum(is.na(df$TS_2_1_1)) #48729 NA's in temp  by lichen/berries  
# sum(is.na(df$TS_3_1_1)) #50445 NA's in temp by tussock 
# sum(is.na(df$TS_4_1_1)) #52796 NA's in temp by foot of EC tower
# sum(is.na(df$TS_5_1_1)) #new temp in latest upload with 2023 data, don't have info on what it is yet** 
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include=FALSE}
rm(list = ls())

library(data.table)
library(ggplot2)
library(cowplot)
library(openair)
library(plotrix)
library(signal)
library(svMisc)
library(zoo)
library(stringr)
library(plyr)
library(viridis)
library(lubridate)
library(tidyverse)
library(gridExtra)
library(plotly)
library(RColorBrewer)
library(pracma)
library(dplyr)


Sys.setenv(TZ='UTC')
```

# Set working directory and then Load data

TO DO: re-running all these with SWC_3 (tussock) version of dataset - KK 1/7/2025 **use the era dataset** 

```{r}
#Initially ran all these models on the gapfilled data to explore; ERA5 datasets included below 

#changed to "council_gapfilled_clean_2017_2023_for analysis.2.csv" --> .2 indicates updated dataset with SWC_3 tussock 

#half-hourly dataframe --> gapfilled 
#df = fread('C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_gapfilled_clean_2017_2023_for analysis.2.csv',na.strings = c('-9999','NA','NaN','NAN','-7999'))


#daily avg dataframe --> gapfilled 
#df_avg = fread('C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_AVG_gapfilled_clean_2017_2023_for analysis.2.csv',na.strings = c('-9999','NA','NaN','NAN','-7999'))


```

#ERA dataset 
####Prepping the era dataset to use to train RF too -- calc vpd and RF for SWC gapfilling, just like in the processing steps 
```{r}
#ERA-5 dataset for RF training - just like in step 2 of the processing code -- uses the same dataset used in the beginning of step 2 
df_era = fread("C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_2016_2023_era.csv") #using the re-cleaned df from Dani 

#subset out by which has complete air t data 
df_era = df_era[complete.cases(df_era$airt.eramod),]

#create subset of the variables wanted for training RF 
df_era2 = data.frame(df_era$date,df_era$FC.c,df_era$FCH4.c,
                 df_era$airt.eramod, df_era$wd, df_era$cardinal_direction, df_era$rh.eramod,df_era$rad.eramod,
                 df_era$ws.eramod,df_era$tsoil.eramod,#df_era$SWC_1_1_1.c,df_era$SWC_2_1_1.c, 
                 df_era$SWC_3_1_1.c, #SWC 3 = the tussock location 
                 df_era$h.eramod,df_era$le.eramod)

#rename for easier names
names(df_era2) = c('date','nee',"fch4",'tair', 'wd', 'cardDir','rh','rg','ws','tsoil','swc','h','le')

#make card dir as factor - 8 levels 
df_era2$cardDir <- as.factor(df_era2$cardDir)

#calculate VPD from air t and RH
svp = 610.7*10^((7.5*df_era2$tair)/(237.3+df_era2$tair))
df_era2$vpd = ((100 - df_era2$rh)/100)*svp  

#Train RF to fill in SWC (using SWC3, tussocklocation*)

set.seed(123)#sets the start point of models, good for repeatability
cc = df_era2[complete.cases(df_era2$swc),]#create a gap free data set of the target variable

#use 80% of data set as training set and 20% as test set
sample = sample(c(TRUE, FALSE), nrow(cc), replace=TRUE, prob=c(0.8,0.2))
train  = cc[sample, ]
test   = cc[!sample, ]

#compare to ensure all data sets are representative of total data
hist(cc$swc)
hist(train$swc)
hist(test$swc)

#run random forest to predict missing SWC values ################################################
library(randomForest)

rf.swc = randomForest(formula = swc ~ tair + rh + rg + ws + wd + tsoil + vpd + le + h,data = train,ntree = 150)
#tried various tree numbers, no sig improvement after 300....very minimal diff between 150 and 300, and 150 looks slightly better.

#predict it on the full data set
swc.rf = predict(object = rf.swc,newdata = df_era2)
df_era2$swc.rf = swc.rf 

#time series plot of gap filled vs real
ggplot(data = df_era2)+
  geom_point(aes(date,swc.rf*100,col='RF'))+
  geom_point(aes(date,swc*100,col='Measured'))+
  scale_y_continuous("SWC (%)")


#validation dataset from only test data
val = merge(test,df_era2,by = "date",all.x = T)

ggplot(data = val,aes(swc.rf,swc.x))+theme_bw()+geom_abline(slope = 1,intercept = 0,col='red')+
  geom_point(alpha=0.1)+
  scale_x_continuous(limits = c(0,70),"RF SWC (%)")+
  scale_y_continuous(limits = c(0,70),"Measured SWC (%)")

#summary stats on gap filling
summary(lm(val$swc.x ~ val$swc.rf)) #R2 = 0.97, slope = 1.02

#create final gap free soil moisture
df_era2$swc = ifelse(is.na(df_era2$swc),df_era2$swc.rf,df_era2$swc)

```

#Seasonal delineations for all years 
```{r}
# First create DOY from date
df_era2$DOY <- as.numeric(format(df_era2$date, "%j"))

# add year column if not already present
df_era2 <- df_era2 %>%
  mutate(year = format(date, "%Y"))


# Create seasonal assignments using both year and DOY
df_era2 <- df_era2%>%
  mutate(
    season = case_when(
      # 2017 seasons
      year == "2017" & (DOY >= 258 & DOY <= 290) ~ 'Fall Senescence',
      year == "2017" & (DOY >= 131 & DOY <= 257) ~ 'Growing Season',
      year == "2017" & (DOY >= 291 | DOY <= 130) ~ 'Winter',
      
      
      # 2018 seasons
      year == "2018" &  (DOY >= 257 & DOY <= 300) ~ 'Fall Senescence',
      year == "2018" & (DOY >= 152 & DOY <= 256) ~ 'Growing Season',
      year == "2018" & (DOY >= 301 | DOY <= 151) ~ 'Winter',
      
      # 2019 seasons
      year == "2019" & (DOY >= 246 & DOY <= 284) ~ 'Fall Senescence',
      year == "2019" & (DOY >= 145 & DOY <= 245) ~ 'Growing Season',
      year == "2019" & (DOY >= 285 | DOY <= 144) ~ 'Winter',
      
      # 2020 seasons
      year == "2020" & (DOY >= 252 & DOY <= 299) ~ 'Fall Senescence',
      year == "2020" & (DOY >= 136 & DOY <= 251) ~ 'Growing Season',
      year == "2020" & (DOY >= 300 | DOY <= 135) ~ 'Winter',
      
      # 2021 seasons
      year == "2021" & (DOY >= 260 & DOY <= 283) ~ 'Fall Senescence',
      year == "2021" &(DOY >= 142 & DOY <= 259) ~ 'Growing Season',
      year == "2021" &(DOY >= 284 | DOY <= 141) ~ 'Winter',
      
      # 2022 seasons
      year == "2022" & (DOY >= 245 & DOY <= 281) ~ 'Fall Senescence',
      year == "2022" & (DOY >= 144 & DOY <= 244) ~ 'Growing Season',
      year == "2022" & (DOY >= 282 | DOY <= 143) ~ 'Winter',
      
      # not doing one for 2023 ** incomplete year 
      TRUE ~ NA_character_
    )
  )

#Will have some NAs as 2023 is incomplete --> maybe go in and see if any seasonal delineations can be made for 2023? (KK 1/16/'25)

sum(is.na(df_era2$season))

```

#Correlations - measured data 
#Here I use original SWC_3 and soil Temp_3 data and the original FCH4 data (not gapfilled)  


#calculate the correlations between FCH4, TS_3_1_1, and SWC_3_1_1:
#### correlation coefficients explain the strength and direction of a correlation --> **not the magnitude of change (like the slope from an lm analysis does) and not the goodness of fit of the model (R2)
```{r}
#these TS and SWC are measurements from tussock area of site 

# Calculate correlations of FCH4 and soil temp, SWC
cor(df$FCH4, df$TS_3_1_1, use = "complete.obs") #uses only rows with no missing values in any of the variables being correlated, as specified by the equation 
cor(df$FCH4, df$SWC_3_1_1, use = "complete.obs")

# Interaction term of soil temp and SWC 
df$interaction_tuss <- df$TS_3_1_1 * df$SWC_3_1_1
cor(df$FCH4, df$interaction_tuss, use = "complete.obs")

#Results: no strong correlations - all very weak pos but interaction a bit better of a fit 
# [1]  0.1981594 FCH4 vs temp
# [1] 0.153488FCH4 vs SWC
# [1] 0.2642889 FCH4 vs interaction of temp and SWC


#Now testing corr between temp and SWC from other locations: 


#measurements from margin pond for both temp and SWC 

# Calculate correlations of FCH4 and soil temp, SWC
cor(df$FCH4, df$TS_1_1_1, use = "complete.obs") 
cor(df$FCH4, df$SWC_1_1_1, use = "complete.obs")

# Interaction term of soil temp and SWC 
df$interaction_pond <- df$TS_1_1_1 * df$SWC_1_1_1
cor(df$FCH4, df$interaction_pond, use = "complete.obs")
#Results:
# [1] 0.2358536 FCH4 v temp
# [1] 0.232435 FCH4 v SWC
# [1]  0.3072315  FCH4 v interaction --> corr best with interaction btwn temp and SWC


#measurements from lichen/berries for both temp and SWC 

# Calculate correlations of FCH4 and soil temp, SWC
cor(df$FCH4, df$TS_2_1_1, use = "complete.obs") 
cor(df$FCH4, df$SWC_2_1_1, use = "complete.obs")

# Interaction term of soil temp and SWC 
df$interaction_liBer <- df$TS_2_1_1 * df$SWC_2_1_1
cor(df$FCH4, df$interaction_liBer, use = "complete.obs")
#Results:
# [1] 0.1786063FCH4 v temp
# [1] 0.1145262 FCH4 v SWC
# [1]  0.2269394 FCH4 v interaction --> corr best with interaction btwn temp and SWC

#Note: best correlation between FCH4 and temp/SWC came from margin pond location, and included the interaction of temp and SWC, but corr = 0.307


#There is a temp for EC tower (TS_4), but no corresponding SWC for this location 
cor(df$FCH4, df$TS_4_1_1, use = "complete.obs") 
#Result: 0.200699

#There is a TS_5, but didn't note a notation on what that actually is --> didn't see an updated user guide as of early Dec (? check again*?)******************************
cor(df$FCH4, df$TS_5_1_1, use = "complete.obs") 
#Result: 0.1553307

```

#Plot to visualize 
```{r}
# Scatter plots of correlations - tussock 
ggplot(df, aes(x = TS_3_1_1, y = FCH4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df, aes(x = SWC_3_1_1, y = FCH4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df, aes(x = interaction_tuss, y = FCH4)) + geom_point() + geom_smooth(method = "lm") 


# Scatter plots of correlations - pond margin 
ggplot(df, aes(x = TS_1_1_1, y = FCH4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df, aes(x = SWC_1_1_1, y = FCH4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df, aes(x = interaction_pond, y = FCH4)) + geom_point() + geom_smooth(method = "lm") 

# Scatter plots of correlations - lichen and berries 
ggplot(df, aes(x = TS_2_1_1, y = FCH4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df, aes(x = SWC_2_1_1, y = FCH4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df, aes(x = interaction_liBer, y = FCH4)) + geom_point() + geom_smooth(method = "lm") 

```
#Correlations - era 5 soil temp & swc, and fch4 (not gapfilled methane)
```{r}
#era tsoil and swc 

# Calculate correlations of fch4 and soil temp, SWC
cor(df_era2$fch4, df_era2$tsoil, use = "complete.obs") 
cor(df_era2$fch4, df_era2$swc, use = "complete.obs") 

#Results
# [1] 0.1741951
# [1] 0.153366


# Interaction term of soil temp and SWC 
df_era2$interaction_era <- df_era2$tsoil * df_era2$swc
cor(df_era2$fch4, df_era2$interaction_era, use = "complete.obs") 
#Results: [1] 0.2358751 --> best with interaction 


# Scatter plots of correlations
ggplot(df_era2, aes(x = tsoil, y = fch4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df_era2, aes(x = swc, y = fch4)) + geom_point() + geom_smooth(method = "lm")
ggplot(df_era2, aes(x = interaction_era, y = fch4)) + geom_point() + geom_smooth(method = "lm") 

```
#lm of relationships from dataset; testing era5 tsoil & swc, and all measured soil and SWC locations 
```{r}
#era_5 df 
model_era.temp <-lm(fch4 ~ tsoil, data = df_era2)
summary(model_era.temp) # R2 = 0.03; slope = 0.35; Residual standard error: 9.456 on 25599 degrees of freedom

model_era.swc <-lm(fch4 ~ swc, data = df_era2)
summary(model_era.swc) # R2 = 0.02; slope = 0.077; Residual standard error: 9.489 on 25599 degrees of freedom

#using calculated interaction term
model_era.interaction <-lm(fch4 ~ interaction_era, data = df_era2)
summary(model_era.interaction) # R2 = 0.05; slope = 0.009; Residual standard error: 9.332 on 25599 degrees of freedom

#full interaction model --> probably better than trying to create a static interaction term ** 
model_era.interaction2 <-lm(fch4 ~ tsoil*swc, data = df_era2)
summary(model_era.interaction2) # R2 = 0.11; slope = 0.046; Residual standard error: 9.047 on 25597 degrees of freedom
#Coefficients:
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  4.445198   0.160939  27.620  < 2e-16 ***
# tsoil       -2.075853   0.051266 -40.492  < 2e-16 ***
# swc          0.025811   0.003842   6.719 1.87e-11 ***
# tsoil:swc    0.046281   0.000969  47.760  < 2e-16 ***


###############using measured temp and swc data (not gapfilled)##################################################

#df without NAs 
df_clean <- na.omit(df[, c("FCH4", "TS_3_1_1", "TS_2_1_1", "TS_1_1_1", "TS_4_1_1", "TS_5_1_1", "SWC_1_1_1", "SWC_2_1_1", "SWC_3_1_1" )])
df_clean$interaction_tuss <- df_clean$TS_3_1_1 * df_clean$SWC_3_1_1 #tussock
df_clean$interaction_pond <- df_clean$TS_1_1_1 * df_clean$SWC_1_1_1 #margin pond
df_clean$interaction_liBer <- df_clean$TS_2_1_1 * df_clean$SWC_2_1_1 #lichen/berries 


#these results of using df with or without NA's, just to see  --> was recommended to just use original df, with NAs, rather than exclude all rows with NAs, and let the lm work around NAs 
# model1 <-lm(FCH4 ~ TS_3_1_1, data = df_clean)
# summary(model1) #slope = 0.46; R2 = 0.063; p<0.001

#temp - tussock
model2 <-lm(FCH4 ~ TS_3_1_1, data = df)
summary(model2) #slope = 0.355; R2 = 0.039, p <0.001; Residual standard error: 9.398 on 24735 degrees of freedom


#temp - lichen and berries - orig data with NAs
model3 <-lm(FCH4 ~ TS_2_1_1, data = df)
summary(model3) #slope = 0.36; R2 = 0.03, p <0.001; Residual standard error: 9.453 on 25567 degrees of freedom

#temp - lichen and berries - df_clean
# model3.2 <-lm(FCH4 ~ TS_2_1_1, data = df_clean)
# summary(model3.2) #slope = 0.51; R2 = 0.054, p <0.001; Residual standard error: 9.235 on 21659 degrees of freedom


#temp - pond margin
model4 <-lm(FCH4 ~ TS_1_1_1, data = df)
summary(model4) #slope = 0.35; R2 = 0.05; p <0.001; Residual standard error: 9.304 on 23383 degrees of freedom

#temp - pond margin - df_clean
# model4.2 <-lm(FCH4 ~ TS_1_1_1, data = df_clean)
# summary(model4.2) #slope = 0.339; R2 = 0.053; p <0.001; Residual standard error: 9.237 on 21659 degrees of freedom

#SWC - tussock
model5 <-lm(FCH4 ~ SWC_3_1_1, data = df)
summary(model5) #slope = 0.07; R2 = 0.02; p <0.001; Residual standard error: 9.474 on 24735 degrees of freedom

#SWC - tussock - df_clean
model5.2 <-lm(FCH4 ~ SWC_3_1_1, data = df_clean)
summary(model5.2) #slope = 0.12; R2 = 0.050; p <0.001; Residual standard error: 9.253 on 21659 degrees of freedom

#SWC - lichen and berries
model6 <-(lm(FCH4 ~ SWC_2_1_1, data = df))
summary(model6) #slope = 0.06; R2 = 0.01; p<0.001; Residual standard error: 9.543 on 25574 degrees of freedom


#SWC - lichen and berries - df_clean
model6.2 <-(lm(FCH4 ~ SWC_2_1_1, data = df_clean))
summary(model6.2) #slope = 0.099; R2 = 0.0279; p<0.001; Residual standard error: 9.361 on 21659 degrees of freedom


#SWC - pond margin 
model7 <-lm(FCH4 ~ SWC_1_1_1, data = df)
summary(model7) #slope = 0.12; R2 = 0.05; p<0.001; Residual standard error: 9.312 on 23383 degrees of freedom

#SWC - pond margin - df_clean
model7.2 <-lm(FCH4 ~ SWC_1_1_1, data = df_clean)
summary(model7.2) #slope = 0.11; R2 = 0.05; p<0.001; Residual standard error: 9.249 on 21659 degrees of freedom

#interaction - tussock 
model8 <-lm(FCH4 ~ interaction_tuss, data = df)
summary(model8) #slope = 0.0088; R2 = 0.0698; p<0.001; Residual standard error: 9.247 on 24735 degrees of freedom

#interaction - tussock - df_clean
model8.2 <-lm(FCH4 ~ interaction_tuss, data = df_clean)
summary(model8.2) #slope = 0.0099; R2 = 0.089; p<0.001; Residual standard error: 9.06 on 21659 degrees of freedom

#interaction - pond margin 
model9 <-lm(FCH4 ~ interaction_pond, data = df)
summary(model9) #slope = 0.009; R2 = 0.09; p<0.001; Residual standard error: 9.111 on 23383 degrees of freedom

#interaction - pond margin - df_clean
model9.2 <-lm(FCH4 ~ interaction_pond, data = df_clean)
summary(model9.2) #slope = 0.009; R2 = 0.089; p<0.001; Residual standard error: 9.058 on 21659 degrees of freedom

#interaction - lichen and berries 
model10 <-lm(FCH4 ~ interaction_liBer, data = df)
summary(model10) #slope = 0.01; R2 = 0.05; p<0.001; Residual standard error: 9.357 on 25567 degrees of freedom

#interaction - lichen and berries - df_clean
# model10.2 <-lm(FCH4 ~ interaction_liBer, data = df_clean)
# summary(model10.2) #slope = 0.01; R2 = 0.06; Residual standard error: 9.179 on 21659 degrees of freedom



model11 <-lm(FCH4 ~ TS_3_1_1 + SWC_3_1_1 + interaction_tuss, data = df)
summary(model11) #R2 = 0.11; p<0.001; Residual standard error: 9.014 on 24733 degrees of freedom
# Coefficients:
#                    Estimate Std. Error t value Pr(>|t|)    
# (Intercept)       6.0166656  0.1528678  39.359   <2e-16 ***
# TS_3_1_1         -1.4648912  0.0407837 -35.919   <2e-16 ***
# SWC_3_1_1        -0.0001117  0.0035354  -0.032    0.975    
# interaction_tuss  0.0351855  0.0007784  45.204   <2e-16 ***

# model11.2 <-lm(FCH4 ~ TS_3_1_1 + SWC_3_1_1 + interaction_tuss, data = df_clean)
# summary(model11.2)#R2 = 0.11, p<0.001; Residual standard error: 8.938 on 21657 degrees of freedom
# Coefficients:
#                    Estimate Std. Error t value Pr(>|t|)    
# (Intercept)       4.3219769  0.1917367  22.541  < 2e-16 ***
# TS_3_1_1         -0.9661740  0.0490227 -19.709  < 2e-16 ***
# SWC_3_1_1         0.0311463  0.0041743   7.462 8.87e-14 ***
# interaction_tuss  0.0259342  0.0009284  27.936  < 2e-16 ***



model12 <-lm(FCH4 ~ TS_2_1_1 + SWC_2_1_1 + interaction_liBer, data = df)
summary(model12) #R2 = 0.06, p<0.001; Residual standard error: 9.276 on 25565 degrees of freedom
# Coefficients:
#                     Estimate Std. Error t value Pr(>|t|)    
# (Intercept)        6.9142444  0.1461682  47.303  < 2e-16 ***
# TS_2_1_1          -0.8599749  0.0409944 -20.978  < 2e-16 ***
# SWC_2_1_1         -0.0157729  0.0041144  -3.834 0.000127 ***
# interaction_liBer  0.0290912  0.0009354  31.101  < 2e-16 ***


# model12.2 <-lm(FCH4 ~ TS_2_1_1 + SWC_2_1_1 + interaction_liBer, data = df_clean)
# summary(model12.2) #R2 = 0.068, p<0.001; Residual standard error: 9.164 on 21657 degrees of freedom
# Coefficients:
#                    Estimate Std. Error t value Pr(>|t|)    
# (Intercept)        5.015642   0.181865  27.579  < 2e-16 ***
# TS_2_1_1          -0.262805   0.053300  -4.931 8.26e-07 ***
# SWC_2_1_1          0.023859   0.004734   5.040 4.70e-07 ***
# interaction_liBer  0.016202   0.001194  13.571  < 2e-16 ***



model13 <-lm(FCH4 ~ TS_1_1_1 + SWC_1_1_1 + interaction_pond, data = df)
summary(model13) #R2 = 0.11, p<0.001; Residual standard error: 9.02 on 23381 degrees of freedom
# Coefficients:
#                    Estimate Std. Error t value Pr(>|t|)    
# (Intercept)       4.2040048  0.1734745   24.23   <2e-16 ***
# TS_1_1_1         -0.3445701  0.0259391  -13.28   <2e-16 ***
# SWC_1_1_1         0.0401979  0.0039777   10.11   <2e-16 ***
# interaction_pond  0.0148246  0.0005721   25.91   <2e-16 ***


model13.2 <-lm(FCH4 ~ TS_1_1_1 + SWC_1_1_1 + interaction_pond, data = df_clean)
summary(model13.2) #R2 = 0.106, p<0.001; Residual standard error: 8.973 on 21657 degrees of freedom
# Coefficients:
#                    Estimate Std. Error t value Pr(>|t|)    
# (Intercept)       4.0542518  0.1760912   23.02   <2e-16 ***
# TS_1_1_1         -0.2956529  0.0264095  -11.20   <2e-16 ***
# SWC_1_1_1         0.0424171  0.0040384   10.50   <2e-16 ***
# interaction_pond  0.0137075  0.0005888   23.28   <2e-16 ***


```
#Comprehensive list of LM results of FCH4 and diff temps - measured data 
```{r}
#Had Claude help with setting up a df for comparison of temp and FCH4

# First, let's create a list of all temperature variables
temp_vars <- c("TS_1_1_1", "TS_2_1_1", "TS_3_1_1", "TS_4_1_1", "TS_5_1_1")

# Create empty vectors to store results
r_squared <- numeric(length(temp_vars))
adj_r_squared <- numeric(length(temp_vars))
slopes <- numeric(length(temp_vars))
n_obs <- numeric(length(temp_vars))
p_values <- numeric(length(temp_vars))

# Run models and store results
for(i in seq_along(temp_vars)) {
    # Create formula
    formula <- as.formula(paste("FCH4 ~", temp_vars[i]))
    
    # Fit model
    model <- lm(formula, data = df)
    
    # Store results
    r_squared[i] <- summary(model)$r.squared
    adj_r_squared[i] <- summary(model)$adj.r.squared
    slopes[i] <- coef(model)[2]
    n_obs[i] <- nobs(model)
    p_values[i] <- summary(model)$coefficients[2,4]
}

# Create results dataframe
results <- data.frame(
    Temperature = temp_vars,
    R_squared = round(r_squared, 4),
    Adj_R_squared = round(adj_r_squared, 4),
    Slope = round(slopes, 4),
    N_observations = n_obs,
    P_value = format(p_values, scientific = TRUE),
    stringsAsFactors = FALSE
)

# Sort by R-squared to see which temperature has strongest relationship
results_sorted <- results[order(-results$R_squared),]

# View results
print(results_sorted)

#Shows TS_1 (pond) actually has strongest R2 at 0.05, followed by TS_4 at 0.04
```
#Comprehensive list of LM results of FCH4 and diff SWC locations - measured data 
```{r}
#Had Claude help with setting up a df for comparison of SWC and FCH4

# First, let's create a list of all  temperature variables
swc_vars <- c("SWC_1_1_1", "SWC_2_1_1", "SWC_3_1_1")

# Create empty vectors to store results
r_squared <- numeric(length(swc_vars))
adj_r_squared <- numeric(length(swc_vars))
slopes <- numeric(length(swc_vars))
n_obs <- numeric(length(swc_vars))
p_values <- numeric(length(swc_vars))

# Run models and store results
for(i in seq_along(swc_vars)) {
    # Create formula
    formula <- as.formula(paste("FCH4 ~", swc_vars[i]))
    
    # Fit model
    model <- lm(formula, data = df)
    
    # Store results
    r_squared[i] <- summary(model)$r.squared
    adj_r_squared[i] <- summary(model)$adj.r.squared
    slopes[i] <- coef(model)[2]
    n_obs[i] <- nobs(model)
    p_values[i] <- summary(model)$coefficients[2,4]
}

# Create results dataframe
results <- data.frame(
    SWC = swc_vars,
    R_squared = round(r_squared, 4),
    Adj_R_squared = round(adj_r_squared, 4),
    Slope = round(slopes, 4),
    N_observations = n_obs,
    P_value = format(p_values, scientific = TRUE),
    stringsAsFactors = FALSE
)

# Sort by R-squared to see which swcerature has strongest relationship
results_sorted <- results[order(-results$R_squared),]

# View results
print(results_sorted)

#shows SWC_1 has strongest R2 at 0.05, followed by SWC3 (tussock) at 0.02
```
#Comprehensive list of LM results of FCH4 and temp*SWC interaction only - measured data 
```{r}
# Create paired lists of temperature and SWC variables
temp_vars <- c("TS_1_1_1", "TS_2_1_1", "TS_3_1_1")
swc_vars <- c("SWC_1_1_1", "SWC_2_1_1", "SWC_3_1_1")
locations <- c("pond", "liBer", "tuss")

# Create empty vectors to store results
r_squared <- numeric(length(temp_vars))
adj_r_squared <- numeric(length(temp_vars))
slopes <- numeric(length(temp_vars))
n_obs <- numeric(length(temp_vars))
p_values <- numeric(length(temp_vars))

# First, create the interaction terms
for(i in seq_along(temp_vars)) {
    interaction_name <- paste0("interaction_", locations[i])
    df[[interaction_name]] <- df[[temp_vars[i]]] * df[[swc_vars[i]]]
}

# Run models and store results
for(i in seq_along(locations)) {
    # Get interaction variable name
    int_var <- paste0("interaction_", locations[i])
    
    # Create formula
    formula <- as.formula(paste("FCH4 ~", int_var))
    
    # Fit model
    model <- lm(formula, data = df)
    
    # Store results
    r_squared[i] <- summary(model)$r.squared
    adj_r_squared[i] <- summary(model)$adj.r.squared
    slopes[i] <- coef(model)[2]
    n_obs[i] <- nobs(model)
    p_values[i] <- summary(model)$coefficients[2,4]
}

# Create results dataframe
results <- data.frame(
    Location = locations,
    R_squared = round(r_squared, 4),
    Adj_R_squared = round(adj_r_squared, 4),
    Slope = round(slopes, 4),
    N_observations = n_obs,
    P_value = format(p_values, scientific = TRUE),
    stringsAsFactors = FALSE
)

# Sort by R-squared
results_sorted <- results[order(-results$R_squared),]

# View results
print(results_sorted)
```
#Comprehensive list of full interaction model LM results of FCH4 and temp, SWC, temp*SWC interaction - measured data 
```{r}
#Testing single interaction vs full interaction models 

####Testing for tussock location (T3 and SWC3)

#single interaction - only looking at interaction via interaction term, not each singular variable and the interaction
summary(model8)

# Full interaction model
model_full_tuss <- lm(FCH4 ~ TS_3_1_1 * SWC_3_1_1, data = df)
summary(model_full_tuss)
# This is equivalent to: FCH4 ~ TS_3_1_1 + SWC_3_1_1 + TS_3_1_1:SWC_3_1_1 = full interaction model, which includes singluar effects and interaction effect 


#Results:
# Full Interaction Model (R2 = 0.1161):
# Temperature has a significant negative main effect (-1.4649)
# Soil water content alone isn't significant (p = 0.975)
# The interaction is significantly positive (0.0352) but very weak 
# **effect of temperature on methane flux depends on soil moisture levels
#

# We can add this to our systematic comparison:
model_comparisons <- list()
for(i in seq_along(locations)) {
    formula <- as.formula(paste("FCH4 ~", temp_vars[i], "*", swc_vars[i]))
    model_comparisons[[locations[i]]] <- lm(formula, data = df)
}
#model_comparisons shows:
# Main effect of temperature
# Main effect of soil water content
# Their interaction effect
# Overall model fit via R2, p, and residual std error 
   
   
# View summaries
lapply(model_comparisons, summary)

#Results: R2 all very weak, highest = 0.11; but all p < 0.001 SIG


```
####Visualizing Interaction between tsoil and tsoil from ERA5
```{r}
#For reference, full interaction model from era_5 dataset:

#model_era.interaction2 <-lm(fch4 ~ tsoil*swc, data = df_era2)
 # R2 = 0.11; slope = 0.046; Residual standard error: 9.047 on 25597 degrees of freedom
# Residuals:
#     Min      1Q  Median      3Q     Max 
# -60.829  -5.109  -1.340   3.931  79.130 
#Coefficients:
#              Estimate Std. Error t value Pr(>|t|)    
# (Intercept)  4.445198   0.160939  27.620  < 2e-16 ***
# tsoil       -2.075853   0.051266 -40.492  < 2e-16 ***
# swc          0.025811   0.003842   6.719 1.87e-11 ***
# tsoil:swc    0.046281   0.000969  47.760  < 2e-16 ***


# For better visualization of overall trend of tsoil and interaction
ggplot(df_era2, aes(x = tsoil, y = fch4, color = swc)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "Methane Flux vs Temperature_era",
       subtitle = "Colored by Soil Water Content",
       x = "Temperature",
       y = "Methane Flux")


#This code breaks SWC into 3 even levels (low, intermediate, high) to show the change in temp relationship depending on SWC
ggplot(df_era2, aes(x = tsoil, y = fch4)) +
  geom_point(aes(color = swc), alpha = 0.3) +
  geom_smooth(aes(group = cut(swc, breaks = 3)), method = "lm") +
  theme_minimal() +
  labs(title = "Methane Flux vs Temperature",
       subtitle = "Colored by Soil Water Content",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content")

summary(df_era2$tsoil)
 #   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 # -7.846  -1.972  -0.987   1.521   5.846  16.447 

summary(df_era2$swc)
   # Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
   # 5.00    9.60   25.50   32.72   57.32   71.60 

#Figure & summary takeaways:

# - A wide range of methane flux values (-60 to 79)
#- temp ranges from -7.8 to 16.47 C, and swc ranges from 5% to 71.6%
# -Soil water content (SWC) shown by color gradient (darker = lower, lighter = higher)
# -A slight positive trend overall, but with substantial scatter
# 
# 
# The full interaction model results:
# -Negative main effect of temperature (-2.07) --> p<0.001 --> sig 
# -very weak, pos effect of swc (0.0258) --> p<0.001 --> sig 
# -very slight positive interaction effect (0.046) --> p<0.001 --> sig 


# At low SWC values, increasing temperature might decrease methane flux (negative main effect)
# At high SWC values, increasing temperature increases methane flux (relationship flips from neg to pos)

# Darker points (low SWC): slight downward trend with temperature
# Lighter points (high SWC): upward trend with temperature
# The crossing of trend lines around moderate temperatures --> but lines cross at two different temps/swc indicating perhaps more than a single threshold & different moisture levels may have different "crossover / threshold" temps --> effect of temp on methane varies non-linearly with moisture

#Calculating the threshold of the switch in temp:swc relationship --> here the threshold is higher than when using measured data (~41%) (in code chunks below)
# Temperature effect = -2.076 + (0.046 × SWC)
# At the threshold, this equals zero:
# -2.076 + (0.046 × SWC) = 0
# 0.046 × SWC = 2.076
# SWC = 2.076/0.046 = 45.13% --> but since there seem to be two thresholds, going to try to calc the thresholds at diff temps
```
####Methane and moisture relationship at diff temps - ERA5
```{r}
# Create temperature bins
df_era2$temp_bin <- cut(df_era2$tsoil, 
                       breaks = c(-8, -4, 0, 4, 8, 16.5),  # Changed from 16 to 16.5
                       labels = c("Very Cold (-8 to -4°C)",
                                "Cold (-4 to 0°C)",
                                "Cool (0 to 4°C)",
                                "Warm (4 to 8°C)",
                                "Warmest (8 to 16.5°C)"))

#Code for if you need more flexibility in the bins
# Adjust the breaks to cover the full range
# df_era2$temp_bin <- cut(df_era2$tsoil, 
#                        breaks = c(-Inf, -4, 0, 4, 8, Inf), --> allows for it to scale to the datapoints present 
#                        labels = c("Very Cold (< -4°C)",
#                                 "Cold (-4 to 0°C)",
#                                 "Cool (0 to 4°C)",
#                                 "Warm (4 to 8°C)",
#                                 "Hot (> 8°C)"))

# Create plot for each temperature range
ggplot(df_era2, aes(x = swc, y = fch4, color = tsoil)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = TRUE) +
  facet_wrap(~temp_bin, scales = "free") +
  scale_color_viridis_c() +
  labs(title = "Methane Flux vs Soil Moisture by Temperature Range",
       x = "Soil Water Content (%)",
       y = "Methane Flux",
       color = "Temperature (°C)") +
  theme_minimal()

# Calculate relationships for each bin
temp_bin_models <- df_era2 %>%
  group_by(temp_bin) %>%
  summarise(
    n = n(),
    correlation = cor(swc, fch4, use = "complete.obs"),
    slope = coef(lm(fch4 ~ swc))[2]
  )

#Results:
# Very Cold (-8 to -4°C):
# 
# Relatively flat relationship with moisture
# Less scatter in the data
# Consistent low-level methane emissions
# 
# Cold (-4 to 0°C):
# 
# Slight positive relationship with moisture
# More variability in emissions
# Higher maximum emissions than very cold conditions
# 
# Cool (0 to 4°C):
# 
# Nearly flat relationship
# Increased variability
# Some high emission events
# 
# Warm (4 to 8°C):
# 
# Wider range of moisture conditions
# Slight positive trend
# Much more variability in emissions
# 
# Warmest (8 to 16°C):
# 
# Strongest positive relationship with moisture
# Highest variability
# Highest potential for large emission events
# 
# Key Takeaways:
# 
# Temperature amplifies the moisture effect
# More variability as temperature increases
# Moisture becomes more important in warmer conditions
# Temperature effects may change based on moisture levels
# Moisture effects may become more important at higher temperatures

```
####Relationship stats for each temp bin
```{r}
# Calculate relationship statistics for each bin
temp_bin_stats <- df_era2 %>%
  group_by(temp_bin) %>%
  summarise(
    n = n(),  # number of observations
    correlation = cor(swc, fch4, use = "complete.obs"),  # correlation coefficient
    mean_flux = mean(fch4, na.rm = TRUE),  # mean methane flux
    sd_flux = sd(fch4, na.rm = TRUE),  # standard deviation of flux
    mean_swc = mean(swc, na.rm = TRUE),  # mean soil water content
    # Get linear model coefficients
    slope = coef(lm(fch4 ~ swc))[2],
    r_squared = summary(lm(fch4 ~ swc))$r.squared
  ) %>%
  arrange(temp_bin)

# Print results in a nice format
print(temp_bin_stats)

#Results
#Highest variability in methane flux at coldest temps and warmest temps (also correlates with lowest swc and highest swc)
# all correlations / R2 are weak 
#Mean flux is actually highest at the coldest (and driest) temp bin ***
#Steepest slope occurs at warmest temp (8 - 16.5C) & also has highest R2 (0.085) --> but still very poor fit -->but also least number of observations in very cold temp bin (2314) vs others (ranging from 66795 - 11020), maybe this affected the means 


#Examining the very cold temp bin some more
# Look at very cold conditions in detail
very_cold <- df_era2[df_era2$temp_bin == "Very Cold (-8 to -4°C)", ]

# Create histogram of methane flux in very cold conditions
ggplot(very_cold, aes(x = fch4)) +
  geom_histogram(binwidth = 1) +
  labs(title = "Distribution of Methane Flux in Very Cold Conditions",
       x = "Methane Flux",
       y = "Count") +
  theme_minimal()

# Get more detailed statistics
summary(very_cold$fch4)

# Look at relationship between SWC and flux in very cold conditions
ggplot(very_cold, aes(x = swc, y = fch4)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  labs(title = "Methane Flux vs SWC in Very Cold Conditions",
       x = "Soil Water Content (%)",
       y = "Methane Flux") +
  theme_minimal()

#The few but fairly large outliers in this temp bin are likely inflating the mean methane flux, and there is a large number of NAs in this temp bin --> maybe look at medians? Using medians will help reduce the influence of those extreme values and might give us a more realistic picture of typical methane flux patterns across temperature ranges

# Calculate median statistics for each bin
temp_bin_medians <- df_era2 %>%
  group_by(temp_bin) %>%
  summarise(
    n = n(),
    median_flux = median(fch4, na.rm = TRUE),
    q25_flux = quantile(fch4, 0.25, na.rm = TRUE),  # 25th percentile
    q75_flux = quantile(fch4, 0.75, na.rm = TRUE),  # 75th percentile
    median_swc = median(swc, na.rm = TRUE),
    n_missing = sum(is.na(fch4))  # Count NAs
  ) %>%
  arrange(temp_bin)

print(temp_bin_medians)

#Very cold has highest median flux (18.9) and also lowest swc (6%) --> also has highest proportion of missing data / NAs (~87%) when you compare n to n_missing --> probably have to take this with a grain of salt, though it is interesting to see the highest emission potential to possibly occur at the coldest and driest time? --> talk to Kyle about this? 
#Second highest median flux is warmest/hot (9.8)
#highest median swc (59%) occurs at cool temp bin (0-4C)
#Temperature Progression: Cold - Cool - Warm - Warmest --> Median flux: 4.89 --> 5.77 --> 7.60 --> 9.80
#Sharp divide in median SWC: Cold conditions: 6.35-11.06% vs Cool & Warmer conditions: 57.65-59.30%

```


####Methane and temp relationship at diff SWC - binning - ERA5
```{r}
#Check spread of data to get accurate bins 
summary(df_era2$swc)

# Create SWC bins
df_era2$swc_bin <- cut(df_era2$swc, 
                       breaks = c(0, 20, 40, 60, 80),
                       labels = c("Very Dry (0-20%)",
                                "Dry (20-40%)",
                                "Wet (40-60%)",
                                "Very Wet (60-80%)"))

# Calculate statistics for each SWC bin
swc_bin_stats <- df_era2 %>%
  group_by(swc_bin) %>%
  summarise(
    n = n(),
    median_flux = median(fch4, na.rm = TRUE),
    q25_flux = quantile(fch4, 0.25, na.rm = TRUE),
    q75_flux = quantile(fch4, 0.75, na.rm = TRUE),
    median_temp = median(tsoil, na.rm = TRUE),
    n_missing = sum(is.na(fch4))
  ) %>%
  arrange(swc_bin)

# Create plot for each moisture range
ggplot(df_era2, aes(x = tsoil, y = fch4, color = swc)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm", se = TRUE) +
  facet_wrap(~swc_bin, scales = "free") +
  scale_color_viridis_c() +
  labs(title = "Methane Flux vs Temperature by Moisture Range",
       x = "Soil Temperature (°C)",
       y = "Methane Flux",
       color = "SWC (%)") +
  theme_minimal()

#Results:
#Can clearly see that at dry conditions there is a neg effect of temp on methane; at wetter conditions, there is a pos effect of temp on methane 
```
####Relationship stats for each SWC bin
```{r}
# Calculate relationship statistics for each bin
swc_bin_stats <- df_era2 %>%
  group_by(swc_bin) %>%
  summarise(
    n = n(),  # number of observations
    correlation = cor(tsoil, fch4, use = "complete.obs"),  # correlation coefficient
    mean_flux = mean(fch4, na.rm = TRUE),  # mean methane flux
    sd_flux = sd(fch4, na.rm = TRUE),  # standard deviation of flux
    mean_tsoil = mean(tsoil, na.rm = TRUE),  # mean temp
    # Get linear model coefficients
    slope = coef(lm(fch4 ~ tsoil))[2],
    r_squared = summary(lm(fch4 ~ tsoil))$r.squared
  ) %>%
  arrange(swc_bin)

# Print results in a nice format
print(swc_bin_stats)

#Results
#highest methane flux at very wet (60-80%), at a mean temp of 5.7C 
#negative relationship at very dry swc, positive relationship at wetter swc 
#temp-methane relationship seems to switch around SWC = 40%
#This contrasts with what we saw when we binned by temperature, possibly pointing out how the outliers in the very cold temp bin are skewing the methane fluxes there and need to be taken with a grain of salt...SWC binning is less influenced by extreme temp values (more even distribution of data, large sample sizes i.e., lower proportion of missing data)


```

#### Measured data 
####Interaction between Temp and SWC at tussock location (TS3, SWC3)

```{r}
# For better visualization

ggplot(df, aes(x = TS_3_1_1, y = FCH4, color = SWC_3_1_1)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  theme_minimal() +
  labs(title = "Methane Flux vs Temperature",
       subtitle = "Colored by Soil Water Content",
       x = "Temperature",
       y = "Methane Flux")

#This code break SWC into 3 even levels (low, intermediate, high) to show the change in temp relationship depending on SWC

ggplot(df, aes(x = TS_3_1_1, y = FCH4)) +
  geom_point(aes(color = SWC_3_1_1), alpha = 0.3) +
  geom_smooth(aes(group = cut(SWC_3_1_1, breaks = 3)), method = "lm") +
  theme_minimal() +
  labs(title = "Methane Flux vs Temperature",
       subtitle = "Colored by Soil Water Content",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content")

#Figure takeaways:

# - A wide range of methane flux values (-50 to 100)
# -Temperature range from about -10°C to 20°C
# -Soil water content (SWC) shown by color gradient (darker = lower, lighter = higher)
# -More data points/higher variance in methane flux at higher temperatures
# -A slight positive trend overall, but with substantial scatter
# 
# 
# The full interaction model results:
# -Negative main effect of temperature (-1.4649) --> sig 
# -Non-significant main effect of SWC alone (-0.0001; p=0.97)
# -positive interaction effect (0.0352) --> sig 


# At low SWC values, increasing temperature might decrease methane flux (negative main effect)
# At high SWC values, increasing temperature increases methane flux (positive interaction overcomes negative main effect)
# The relationship between temperature and methane flux gets stronger as soil moisture increases

# The lowest SWC group (darkest points) shows a slightly negative or flat relationship with temperature
# The highest SWC group (lightest points) shows a stronger positive relationship with temperature
# The middle SWC group shows a slightly negative slope

#(Tried this with some guidance from Claude*)
#Trying to calc temp effects / slopes at different SWC using the full interaction model: "model_full_tuss <- lm(FCH4 ~ TS_3_1_1 * SWC_3_1_1, data = df)"
# The effect of temperature on methane flux at any given SWC value is:
# Temperature Effect = β₁ + β₃(SWC value)
# where β₁ is the temperature coefficient (-1.4649) and β₃ is the interaction coefficient (0.0352)


# First, let's look at the distribution of SWC_3_1_1 values
summary(df$SWC_3_1_1)
# Get quantiles of SWC for representative values
quantiles <- quantile(df$SWC_3_1_1, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)

# Calculate temperature effects
low_effect <- -1.4649 + (0.0352 * quantiles[1])
med_effect <- -1.4649 + (0.0352 * quantiles[2])
high_effect <- -1.4649 + (0.0352 * quantiles[3])

# Create results dataframe
results <- data.frame(
   SWC_Level = c("Low (25%)", "Medium (50%)", "High (75%)"),
   SWC_Value = round(quantiles, 2),
   Temp_Effect = round(c(low_effect, med_effect, high_effect), 3)
)

print(results)

#Results:

# how soil moisture modifies the temperature effect on methane flux
# 
# At Low Moisture (13.7%):
#   - Temperature effect is negative (-0.983)
#   -For every 1 C increase in temperature, methane flux decreases by about 0.98 units when soil is dry
# 
# 
# At Medium Moisture (55%):# 
#   -Temperature effect becomes positive (0.471)
#   -For every 1 C increase, methane flux increases by about 0.47 units at median moisture
# 
# 
# At High Moisture (59.4%):# 
#   -Even stronger positive effect (0.626)
#   -For every 1 C increase, methane flux increases by about 0.63 units in wet conditions



#Calc the transtion point: at what soil moisture level does temp start having a pos effect on methane flux?
#Transition = -β₁/β₃ (where β₁ is temp coefficient and β₃ is interaction)
transition_point <- 1.4649/0.0352
print(round(transition_point, 2))
#Result: 41.62 % 

#Below 41.62% soil moisture threshold:
# Temperature increases lead to decreased methane flux
# -->drier conditions limit methanogenic activity
# 
# Above 41.62% soil moisture: 
# Temperature increases lead to increased methane flux
# -->makes sense: methanogens require both warmth and anaerobic (wet) conditions
# 
# matches well with the moisture distribution:
# 
# 25th percentile (13.7%): well below threshold → negative temperature effect
# Median (55%) and 75th percentile (59.4%): well above threshold → positive temperature effect
# Mean (41.16%): very close to transition point 

#-->suggests the site experiences both moisture-limited and temperature-limited methane production (depending on conditions)

```

########Interaction effects at lichen/berries location (TS2, SWC2) 
```{r}
# Calculate transition points for each location
# Transition = -β₁/β₃ (where β₁ is temp coefficient and β₃ is interaction)


# For pond margin (TS_1_1_1 * SWC_1_1_1)
model_full_pond <- lm(FCH4 ~ TS_1_1_1 * SWC_1_1_1, data = df)
summary(model_full_pond)

#Results:
#R2 =  0.1126, p<0.001
#Transition point = 0.3445701/0.0148246 = 23.24% SWC
# All coefficients highly significant
# Positive main effect of SWC (0.0402)

# For lichen/berries (TS_2_1_1 * SWC_2_1_1)
model_full_liber <- lm(FCH4 ~ TS_2_1_1 * SWC_2_1_1, data = df)
summary(model_full_liber)

#Results:
#R2 = 0.0678, p <0.001
#Transition point = 0.8599749/0.0290912 = 29.56% SWC
#all coeffs highly significant 



# Results Comparing all three locations:
# 
# 1. Moisture thresholds for positive temperature effects:
# 
# Tussock: 41.62% SWC (highest threshold)
# Lichen/berries: 29.56% SWC
# Pond margin: 23.24% SWC (lowest threshold)
#  
# 2. Sensitivity to temperature (interaction coefficients):
# 
# Tussock: 0.0352 (strongest)
# Lichen/berries: 0.0291
# Pond margin: 0.0148 (weakest)

#Takeaways: 
# Pond margins respond positively to temperature at lower moisture levels
# Tussocks need higher moisture for positive temperature effects
# Each microsite has its own distinct threshold
# All sites show the moisture-dependent temperature effect, but at different strengths



#Figure for margin pond 
ggplot(df, aes(x = TS_1_1_1, y = FCH4)) +
  geom_point(aes(color = SWC_1_1_1), alpha = 0.3) +
  geom_smooth(aes(group = cut(SWC_1_1_1, breaks = 3)), method = "lm") +
  theme_minimal() +
  labs(title = "Methane Flux vs Temperature at Margin Pond",
       subtitle = "Colored by Soil Water Content",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content")

#Figure for lichen and berries 
ggplot(df, aes(x = TS_2_1_1, y = FCH4)) +
  geom_point(aes(color = SWC_2_1_1), alpha = 0.3) +
  geom_smooth(aes(group = cut(SWC_2_1_1, breaks = 3)), method = "lm") +
  theme_minimal() +
  labs(title = "Methane Flux vs Temperature at Lichen/Berries",
       subtitle = "Colored by Soil Water Content",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content")

# Get SWC distributions for each location
summary(df$SWC_1_1_1)  # pond
summary(df$SWC_2_1_1)  # lichen/berries


```
#Comparative figures
```{r}
# Create the plot with explicit faceting
# Create three separate dataframes for cleaner plotting
tussock_data <- df[!is.na(df$TS_3_1_1) & !is.na(df$SWC_3_1_1) & !is.na(df$FCH4), ]
pond_data <- df[!is.na(df$TS_1_1_1) & !is.na(df$SWC_1_1_1) & !is.na(df$FCH4), ]
liber_data <- df[!is.na(df$TS_2_1_1) & !is.na(df$SWC_2_1_1) & !is.na(df$FCH4), ]

# Create a long format dataset for faceting
plot_data <- rbind(
  data.frame(Temp = tussock_data$TS_3_1_1, SWC = tussock_data$SWC_3_1_1, 
             FCH4 = tussock_data$FCH4, Site = "Tussock"),
  data.frame(Temp = pond_data$TS_1_1_1, SWC = pond_data$SWC_1_1_1, 
             FCH4 = pond_data$FCH4, Site = "Pond Margin"),
  data.frame(Temp = liber_data$TS_2_1_1, SWC = liber_data$SWC_2_1_1, 
             FCH4 = liber_data$FCH4, Site = "Lichen/Berries")
)

# Create the plot with explicit faceting
ggplot(plot_data, aes(x = Temp, y = FCH4, color = SWC)) +
  geom_point(alpha = 0.3) +
  geom_smooth(aes(group = cut(SWC, breaks = 3)), method = "lm") +
  facet_wrap(~Site, ncol = 3) +  # Force 3 columns
  theme_minimal() +
  labs(title = "Temperature Effects on Methane Flux Across Microsites",
       subtitle = "Colored by Soil Water Content (%)",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content (%)") +
  theme(legend.position = "right",
        strip.text = element_text(size = 12, face = "bold"),
        panel.spacing = unit(2, "lines")) +  # Add more space between panels
  scale_color_viridis_c()  # Use viridis color scale for better visibility

# Add vertical lines for transition points
geom_vline(data = data.frame(
    Site = c("Tussock", "Pond Margin", "Lichen/Berries"),
    threshold = c(41.62, 23.24, 29.56)
  ),
  aes(xintercept = threshold),
  linetype = "dashed",
  alpha = 0.5
)


#(With help from Claude*)
#Comparative figure: 
# This should create a panel plot showing all three locations side by side, with:
# 
# Points colored by soil moisture
# Trend lines for different moisture levels
# Vertical lines showing transition points
# Same scale for easy comparison

# First create the faceted plot without the vertical lines
p <- ggplot(plot_data, aes(x = Temp, y = FCH4)) +
  # Points with color by SWC
  geom_point(aes(color = SWC), alpha = 0.3) +
  # Smooth lines with explicit grouping
  geom_smooth(aes(group = cut(SWC, breaks = 3, labels = c("Low", "Medium", "High"))), 
             method = "lm") +
  # Facet by site
  facet_wrap(~Site, ncol = 3) +
  # Theme and labels
  theme_minimal() +
  labs(title = "Temperature Effects on Methane Flux Across Microsites",
       subtitle = "Colored by Soil Water Content (%)",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content (%)") +
  theme(legend.position = "right",
        strip.text = element_text(size = 12, face = "bold")) +
  scale_color_viridis_c()

# Add transition points
thresholds <- data.frame(
  Site = c("Tussock", "Pond Margin", "Lichen/Berries"),
  threshold = c(41.62, 23.24, 29.56)
)

# Add vertical lines to the plot --> shows where temp switches from negative to positive based on SWC
p + geom_vline(data = thresholds, 
               aes(xintercept = threshold), 
               linetype = "dashed", 
               color = "red", 
               alpha = 0.5)

#Fig interpretation
# Lichen/Berries:
# 
# Typically drier (more purple points)
# Transition point at 29.56% SWC (red dashed line)
# More gradual change in temperature effects with moisture
# 
# Pond Margin:
# 
# More variable moisture (mix of colors)
# Earliest transition point at 23.24% SWC
# Most consistent positive temperature effect above the threshold
# Smoother transitions between moisture levels
# 
# Tussock:
# 
# Generally wetter (more yellow/green points)
# Highest transition point at 41.62% SWC
# Shows the most dramatic shift in temperature effects
# Strongest negative effect when dry, strongest positive effect when wet
# 
# 
# **All show the moisture-dependent temperature effect, but with site-specific thresholds



#Adding labels to the thresholds
# Create the base plot as before
# Create thresholds dataframe with better positioned labels
thresholds <- data.frame(
  Site = c("Tussock", "Pond Margin", "Lichen/Berries"),
  threshold = c(41.62, 23.24, 29.56),
  label = sprintf("SWC = %.1f%%", c(41.62, 23.24, 29.56)),
  y = 75  # Lowered from 80 to avoid plot margins
)

# Create the base plot
p <- ggplot(plot_data, aes(x = Temp, y = FCH4)) +
  geom_point(aes(color = SWC), alpha = 0.3) +
  geom_smooth(aes(group = cut(SWC, breaks = 3, labels = c("Low", "Medium", "High"))), 
             method = "lm") +
  facet_wrap(~Site, ncol = 3) +
  theme_minimal() +
  labs(title = "Temperature Effects on Methane Flux Across Microsites",
       subtitle = "Colored by Soil Water Content (%)",
       x = "Temperature (°C)",
       y = "Methane Flux",
       color = "Soil Water Content (%)") +
  theme(legend.position = "right",
        strip.text = element_text(size = 12, face = "bold")) +
  scale_color_viridis_c()
#############################################################################
# Add lines and better positioned labels
# p + 
#   geom_vline(data = thresholds, 
#              aes(xintercept = threshold), 
#              linetype = "dashed", 
#              color = "red", 
#              alpha = 0.5) +
#   geom_label(data = thresholds,  # Changed from geom_text to geom_label
#             aes(x = threshold, y = y, label = label),
#             hjust = -0.1,
#             size = 3,
#             fill = "white",      # Add white background
#             alpha = 0.8,         # Slight transparency
#             label.padding = unit(0.2, "lines"))  # Add padding around text
####################################################################################

#This expands the view so you can see the threshold labels 
p + 
  geom_vline(data = thresholds, 
             aes(xintercept = threshold), 
             linetype = "dashed", 
             color = "red", 
             alpha = 0.5) +
  geom_label(data = thresholds,  
            aes(x = threshold, y = y, label = label),
            hjust = -0.1,
            size = 3,
            fill = "white",      
            alpha = 0.8,         
            label.padding = unit(0.2, "lines")) +
  coord_cartesian(clip = "off")  # Ensure elements outside the plot area are displayed



```
#TO DO: do this also with the era data? or are relationships so low, we can reasonably assume those models won't fit well either, and move on to RF 

#Empirical model experimentation 

###Piecewise model

```{r}
# Since we know the threshold is at 41.62% SWC, we could create a piecewise model
model_tussock_low <- lm(FCH4 ~ TS_3_1_1, data = df[df$SWC_3_1_1 <= 41.62, ])
model_tussock_high <- lm(FCH4 ~ TS_3_1_1, data = df[df$SWC_3_1_1 > 41.62, ])
```

```{r}
# Set a random seed for reproducibility
set.seed(123)  # This ensures we get the same random split every time we run the code

# Create index for random 80% selection
train_index <- sample(1:nrow(df), 0.8 * nrow(df))

# Create training and testing datasets
train_df <- df[train_index, ]
test_df <- df[-train_index, ]  # The [-train_index] selects all rows NOT in train_index


#Break apart the model by low SWC and high SWC, so we can capture the diff temp relationships based on SWC

# create our piecewise model with the training data
# First for low moisture conditions (≤ 41.62% SWC)
model_tussock_low <- lm(FCH4 ~ TS_3_1_1, 
                       data = train_df[train_df$SWC_3_1_1 <= 41.62, ])

# Then for high moisture conditions (> 41.62% SWC)
model_tussock_high <- lm(FCH4 ~ TS_3_1_1, 
                        data = train_df[train_df$SWC_3_1_1 > 41.62, ])

# Let's look at the model summaries
summary(model_tussock_low)
summary(model_tussock_high)

# test the models on our test dataset
# split test data by threshold
test_low <- test_df[test_df$SWC_3_1_1 <= 41.62, ]
test_high <- test_df[test_df$SWC_3_1_1 > 41.62, ]

# Make predictions
predictions_low <- predict(model_tussock_low, newdata = test_low)
predictions_high <- predict(model_tussock_high, newdata = test_high)

# Calculate RMSE (Root Mean Square Error) for each condition
rmse_low <- sqrt(mean((test_low$FCH4 - predictions_low)^2, na.rm = TRUE))
print(rmse_low)
rmse_high <- sqrt(mean((test_high$FCH4 - predictions_high)^2, na.rm = TRUE))
print(rmse_high)

#Results interpretation:
# Low Moisture Conditions (SWC ≤ 41.62%):
# 
# Negative temperature effect: -0.365 units of FCH4 per C
# Baseline (intercept) of 7.055
# R2 = 0.023 (explains 2.3% of variance)
# RMSE = 8.82

# High Moisture Conditions (SWC > 41.62%):
# 
# Positive temperature effect: +0.476 units of FCH4 per C
# Baseline (intercept) of 6.353
# R2 = 0.057 (explains 5.7% of variance)
# RMSE = 9.22

# Takeaways
# 
# The sign flip in temperature effect 
# Low R2 values indicate other factors might be important; this isn't the best model 


#Visualize 

# Create prediction plots
# For low moisture conditions
plot_low <- ggplot() +
  geom_point(data = test_low, aes(x = TS_3_1_1, y = FCH4), alpha = 0.3, color = "blue") +
  geom_line(data = test_low, aes(x = TS_3_1_1, y = predictions_low), color = "red") +
  labs(title = "Low Moisture Predictions (SWC ≤ 41.62%)",
       x = "Temperature (°C)",
       y = "Methane Flux") +
  theme_minimal()

# For high moisture conditions
plot_high <- ggplot() +
  geom_point(data = test_high, aes(x = TS_3_1_1, y = FCH4), alpha = 0.3, color = "green") +
  geom_line(data = test_high, aes(x = TS_3_1_1, y = predictions_high), color = "red") +
  labs(title = "High Moisture Predictions (SWC > 41.62%)",
       x = "Temperature (°C)",
       y = "Methane Flux") +
  theme_minimal()

# Display plots side by side
library(gridExtra)
grid.arrange(plot_low, plot_high, ncol = 2)
```
####Visualizing on 1:1
```{r}
# Combine predictions and actual values for both conditions
eval_low <- data.frame(
  predicted = predictions_low,
  actual = test_low$FCH4
)

eval_high <- data.frame(
  predicted = predictions_high,
  actual = test_high$FCH4
)

# Create evaluation plots
# For low moisture
eval_plot_low <- ggplot(eval_low, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.3, color = "blue") +
  geom_smooth(method = "lm", color = "red") +  # Add regression line
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +  # Add 1:1 line
  labs(title = "Model Evaluation - Low Moisture",
       x = "Observed Methane Flux",
       y = "Predicted Methane Flux") +
  theme_minimal()

# For high moisture
eval_plot_high <- ggplot(eval_high, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.3, color = "green") +
  geom_smooth(method = "lm", color = "red") +  # Add regression line
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +  # Add 1:1 line
  labs(title = "Model Evaluation - High Moisture",
       x = "Observed Methane Flux",
       y = "Predicted Methane Flux") +
  theme_minimal()

# Calculate and print evaluation metrics

# For low moisture
eval_model_low <- lm(predicted ~ actual, data = eval_low)
print("Low Moisture Model:")
print(paste("R² =", round(summary(eval_model_low)$r.squared, 3)))
print(paste("Slope =", round(coef(eval_model_low)[2], 3)))

# For high moisture
eval_model_high <- lm(predicted ~ actual, data = eval_high)
print("High Moisture Model:")
print(paste("R² =", round(summary(eval_model_high)$r.squared, 3)))
print(paste("Slope =", round(coef(eval_model_high)[2], 3)))

# low moisture 
eval_plot_low <- ggplot(eval_low, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.3, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(title = "Model Evaluation - Low Moisture",
       x = "Observed Methane Flux",
       y = "Predicted Methane Flux") +
  theme_minimal() +
  annotate("text", x = -20, y = 9,  # Adjusted position
           label = sprintf("R² = %.3f\nSlope = %.3f", 
                         summary(eval_model_low)$r.squared, 
                         coef(eval_model_low)[2]))

# high moisture 
eval_plot_high <- ggplot(eval_high, aes(x = actual, y = predicted)) +
  geom_point(alpha = 0.3, color = "blue") +
  geom_smooth(method = "lm", color = "red") +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
  labs(title = "Model Evaluation - High Moisture",
       x = "Observed Methane Flux",
       y = "Predicted Methane Flux") +
  theme_minimal() +
  annotate("text", x = -20, y = 9,  # Adjusted position
           label = sprintf("R² = %.3f\nSlope = %.3f", 
                         summary(eval_model_high)$r.squared, 
                         coef(eval_model_high)[2]))
# Display plots side by side
grid.arrange(eval_plot_low, eval_plot_high, ncol = 2)


#Results:
# Low Moisture Model:
# 
# R2 = 0.027 (only explains 2.7% of variation)
# Slope = 0.025 
# Strong tendency to over-predict low fluxes and under-predict high fluxes(?)
# 
# 
# High Moisture Model:
# 
# R2 = 0.050 (only explains 5% of variation)
# Slope = 0.054 


```

###Non-linear Model using SWC threshold

```{r}
# Create indicator variable for above/below threshold
# df$above_threshold <- as.numeric(df$SWC_3_1_1 > 41.62)
# model_nonlinear <- lm(FCH4 ~ TS_3_1_1 * SWC_3_1_1 * above_threshold, data = df)


# Create indicator variable for above/below threshold
train_df$above_threshold <- as.numeric(train_df$SWC_3_1_1 > 41.62)
test_df$above_threshold <- as.numeric(test_df$SWC_3_1_1 > 41.62)

# Fit non-linear model
model_nonlinear <- lm(FCH4 ~ TS_3_1_1 * SWC_3_1_1 * above_threshold, 
                     data = train_df)

# Make predictions
predictions_nl <- predict(model_nonlinear, newdata = test_df)

# Create evaluation plot
eval_nl <- data.frame(
    predicted = predictions_nl,
    actual = test_df$FCH4
)

# Plot
ggplot(eval_nl, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Non-linear Model Evaluation",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_nl$actual, na.rm = TRUE), 
             y = max(eval_nl$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_nl))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_nl))[2]),
             hjust = 0, vjust = 1)

#Results:
# The non-linear model shows some improvement over the piecewise model:
# 
# Non-linear model: R2 = 0.133 (explains 13.3% of variance)
# Previous models: R2 0.027 (low moisture) and 0.050 (high moisture)

#Still not a good fit 


```


#Temp-dependent Moisture Effect model - quadratic model 

```{r}
# Include quadratic terms to capture non-linear relationships

# Fit quadratic model
model_quad <- lm(FCH4 ~ TS_3_1_1 + I(TS_3_1_1^2) + 
                 SWC_3_1_1 + I(SWC_3_1_1^2) + 
                 TS_3_1_1:SWC_3_1_1, 
                 data = train_df)

# Make predictions
predictions_quad <- predict(model_quad, newdata = test_df)

# Create evaluation plot
eval_quad <- data.frame(
    predicted = predictions_quad,
    actual = test_df$FCH4
)

# Plot
ggplot(eval_quad, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") + #dashed 1:1 line 
    labs(title = "Quadratic Model Evaluation",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_quad$actual, na.rm = TRUE), 
             y = max(eval_quad$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_quad))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_quad))[2]),
             hjust = 0, vjust = 1)


#Results / comparing results from all models: 
# 
# Piecewise Linear:
# 
# Low moisture: R2 = 0.027, Slope = 0.025
# High moisture: R2 = 0.050, Slope = 0.054
# 
# 
# Non-linear with threshold:
# 
# R² = 0.133, Slope = 0.132
# 
# 
# Quadratic model:
# 
# R2 = 0.160, Slope = 0.152
# = best performance of the 3, but still not good 
# --> Still under-predicting high flux values (points fall below 1:1 line at high values)
# Over-predicting low flux values (points above 1:1 line at low values)


#examining the quadratic model more closely

# View model summary
summary(model_quad)


# Create prediction surface
temp_seq <- seq(min(df$TS_3_1_1, na.rm = TRUE), 
                max(df$TS_3_1_1, na.rm = TRUE), length.out = 50)
swc_seq <- seq(min(df$SWC_3_1_1, na.rm = TRUE), 
               max(df$SWC_3_1_1, na.rm = TRUE), length.out = 50)

# Create grid of predictor values
pred_grid <- expand.grid(TS_3_1_1 = temp_seq, SWC_3_1_1 = swc_seq)

# Get predictions
pred_grid$predicted <- predict(model_quad, newdata = pred_grid)

# Plot prediction surface
ggplot(pred_grid, aes(x = TS_3_1_1, y = SWC_3_1_1, fill = predicted)) +
  geom_tile() +
  scale_fill_viridis_c() +
  labs(title = "Predicted Methane Flux Across Temperature-Moisture Space",
       x = "Temperature (°C)",
       y = "Soil Water Content (%)",
       fill = "Predicted\nMethane Flux") +
  theme_minimal()

#Results:
# 
# R2 = 0.148 (explains 14.8% of variance)
# 
# Temperature-Moisture Interactions:
# The surface plot shows highest predicted methane flux at:
# 
# High temperatures (20°C) with high moisture (>40%)
# Very low temperatures (-10°C) with low moisture
# 
# 
#non-linear relationship**

# Coefficients show:
# Negative linear effects for both temperature (-1.15) and SWC (-0.36)
# Positive quadratic effects for both (0.056 for temp^2, 0.005 for SWC^2)
# Positive interaction effect (0.017)

```
#Random Forest re-training with swc and soil temp 

#### ERA5 data --> Trying to train RandomForest with just temp, SWC, and the temp and SWC interaction - not constrained 

```{r}
#not constraining data to threshold limits to limit outliers *** --> for that, see code chunk below 
library(randomForest)
# Create complete dataset --> RF can't handle missing data / NAs
rf_data_era = df_era2[complete.cases(df_era2$fch4),]

summary(is.na(rf_data_era$fch4))
summary(rf_data_era$fch4)

# Create interaction term --> explicit interaction term while keeping original terms 
rf_data_era$TS_SWC_interact <- rf_data_era$tsoil * rf_data_era$swc

# Split into train/test (80/20)
set.seed(123)
train_index <- sample(1:nrow(rf_data_era), 0.8 * nrow(rf_data_era))
rf_train_era <- rf_data_era[train_index, ]
rf_test_era <- rf_data_era[-train_index, ]

# Fit RF model with both original and interaction terms
library(randomForest)
rf_model_era <- randomForest(fch4 ~ tsoil + swc + TS_SWC_interact,
                        data = rf_train_era,
                        ntree = 500)


# Now make predictions
rf_pred_era <- predict(rf_model_era, newdata = rf_test_era)

# Create evaluation plot
eval_rf_era <- data.frame(
    predicted = rf_pred_era,
    actual = rf_test_era$fch4
)

# Create evaluation plot
ggplot(eval_rf_era, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction - ERA5",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_era$actual, na.rm = TRUE), 
             y = max(eval_rf_era$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf_era))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf_era))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_model_era)

#Results:
#R2 = 0.377, slope = 0.42
#tsoil slightly more important than interaction, which is slightly more important than swc alone 
```
####ERA5 - Training RF on predicting methane with just temp, SWC, and SWC*temp interaction --> constrained 

```{r}
#constrained fch4 to limits used in step2 of the processing process (little redundant here but was curious)
summary(df_era2$fch4) #min = -47, max = 93
plot(df_era2$date, df_era2$fch4) #plotting to check, and this still looks like a good range to cut out some outliers

# Create interaction term between era temp and era gapfilled swc (gapfilled SWC3 tussock) --> explicit interaction term while keeping original terms 
df_era2$TS_SWC_interact <- df_era2$tsoil * df_era2$swc

#Use only complete cases
cc = df_era2[complete.cases(df_era2$fch4),]
cc = subset(cc,cc$fch4 < 60)
cc = subset(cc,cc$fch4 > -25)

#create training dataset - 80% to train, 20% to test 
sample.ch4 = sample(c(TRUE, FALSE), nrow(cc), replace=TRUE, prob=c(0.8,0.2))
train.ch4  = cc[sample.ch4, ]
test.ch4   = cc[!sample.ch4, ]

#Make sure the training and testing datasets are representative / similar 
hist(cc$fch4)
hist(train.ch4$fch4)
hist(test.ch4$fch4)


# Fit RF model with both original and interaction terms - era dataset 
rf_model_fch4.era <- randomForest(fch4~ tsoil + swc + TS_SWC_interact,
                        data = train.ch4,
                        ntree = 500)


# Now make predictions
rf_pred_ch4 <- predict(rf_model_fch4.era, newdata = test.ch4)

# Create evaluation plot
eval_rf_ch4.era <- data.frame(
    predicted = rf_pred_ch4,
    actual = test.ch4$fch4
)

# Create evaluation plot
ggplot(eval_rf_ch4.era, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction_era",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_ch4.era$actual, na.rm = TRUE), 
             y = max(eval_rf_ch4.era$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf_ch4.era))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf_ch4.era))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_model_fch4.era)

#Results from non-constrained fch4 data: #R2 = 0.377, slope = 0.42 --> tsoil slightly more important than interaction, which is slighlty more important than swc alone 
#Results from constrained fch4 data:  R² = 0.351, Slope = 0.417 --> slightly worse than un-constrained data --> tsoil slighlty more important, followed by interact and swc alone 

```

#Random Forest re-training with all met variables and the swc:temp interaction effect 

####ERA5 data full model --> not constrained 

```{r}
#include all met variables and the swc:tsoil interaction effect 

rf_all_era <- randomForest(fch4 ~ tair + rh + rg + ws + wd + tsoil + 
                             vpd + swc + h + le + TS_SWC_interact ,
                             data = rf_train_era,
                             ntree = 500,
                             importance = TRUE)

# Now make predictions
rf_pred_era2 <- predict(rf_all_era, newdata = rf_test_era)

# Create evaluation plot
eval_rf_era2 <- data.frame(
    predicted = rf_pred_era2,
    actual = rf_test_era$fch4
)

# Create evaluation plot
ggplot(eval_rf_era2, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction - ERA5",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_era2$actual, na.rm = TRUE), 
             y = max(eval_rf_era2$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf_era2))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf_era2))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_all_era)

#Results
#R2 = 0.48, slope = 0.48
#wd and swc are most important 
```

####ERA5 data full RF model --> constrained 

```{r}
#include all met variables and the swc:tsoil interaction effect 

#for reference, since we already subsetted a constrained dataset in previous code chunks 
# cc = df_era2[complete.cases(df_era2$fch4),]
# cc = subset(cc,cc$fch4 < 60)
# cc = subset(cc,cc$fch4 > -25)

#create training dataset - 80% to train, 20% to test 
# sample.ch4 = sample(c(TRUE, FALSE), nrow(cc), replace=TRUE, prob=c(0.8,0.2))
# train.ch4  = cc[sample.ch4, ]
# test.ch4   = cc[!sample.ch4, ]


rf_all_era2 <- randomForest(fch4 ~ tair + rh + rg + ws + wd + tsoil + 
                             vpd + swc + h + le + TS_SWC_interact ,
                             data = train.ch4,
                             ntree = 500,
                             importance = TRUE)

# Now make predictions
rf_pred_era3 <- predict(rf_all_era2, newdata = test.ch4)

# Create evaluation plot
eval_rf_era3 <- data.frame(
    predicted = rf_pred_era3,
    actual = test.ch4$fch4
)

# Create evaluation plot
ggplot(eval_rf_era3, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction - ERA5",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_era3$actual, na.rm = TRUE), 
             y = max(eval_rf_era3$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf_era3))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf_era3))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_all_era2)

#Results:
#R2 = 0.50, slope = 0.50
#wd, swc, and ws are most important 

#predict on full dataset and add to df-era5
```
####ERA5 data full RF model TAKING OUT INTERACTION --> constrained 

```{r}
#include all met variables and the swc:tsoil interaction effect 

#for reference, since we already subsetted a constrained dataset in previous code chunks 
# cc = df_era2[complete.cases(df_era2$fch4),]
# cc = subset(cc,cc$fch4 < 60)
# cc = subset(cc,cc$fch4 > -25)

#create training dataset - 80% to train, 20% to test 
# sample.ch4 = sample(c(TRUE, FALSE), nrow(cc), replace=TRUE, prob=c(0.8,0.2))
# train.ch4  = cc[sample.ch4, ]
# test.ch4   = cc[!sample.ch4, ]


rf_all_era3 <- randomForest(fch4 ~ tair + rh + rg + ws + wd + tsoil + 
                             vpd + swc + h + le,
                             data = train.ch4,
                             ntree = 500,
                             importance = TRUE)

# Now make predictions
rf_pred_era4 <- predict(rf_all_era3, newdata = test.ch4)

# Create evaluation plot
eval_rf_era4 <- data.frame(
    predicted = rf_pred_era4,
    actual = test.ch4$fch4
)

# Create evaluation plot
ggplot(eval_rf_era4, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction - ERA5",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_era4$actual, na.rm = TRUE), 
             y = max(eval_rf_era4$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf_era4))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf_era4))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_all_era3)

#Results:
#R2 = 0.501, slope = 0.498
#swc and wd are most important 



# Looking at rf_all era comparison with and without swc:tsoil interaction term

# Without interaction:
# 
# R2 = 0.501, Slope = 0.498
# Variable importance shows SWC and wind direction as top predictors
# 
# With interaction:
# 
# R2 = 0.502, Slope = 0.504
# Very slight improvement
# Similar variable importance rankings
# 
# The difference is minimal (diff in R2 = 0.001), but it was recommended to keep the interaction term because:
# 
# Scientific Rationale: clear evidence of temperature-moisture interactions in earlier analysis
# The interaction represents a real physical process (moisture-dependent temperature effects on methanogenesis) --> Including the interaction term incorporates that effect 
# 
# Practical reasons: Even small improvements matter for prediction accuracy
# No real computational cost to including it
# Helps capture non-linear relationships we observed in our binned analyses --> shows the interdependence of these factors

```
#Adding full RF model with interaction and optimal ntree to df_era2 dataset
```{r}
####ERA5 data full RF model --> constrained 

#include all met variables and the swc:tsoil interaction effect 

#for reference, since we already subsetted a constrained dataset in previous code chunks 
# cc = df_era2[complete.cases(df_era2$fch4),]
# cc = subset(cc,cc$fch4 < 60)
# cc = subset(cc,cc$fch4 > -25)

orig = Sys.time()


rf_final <- randomForest(fch4 ~ tair + rh + rg + ws + wd + tsoil + 
                             vpd + swc + h + le + TS_SWC_interact ,
                             data = train.ch4,
                             ntree = 950,
                             importance = TRUE)

# Now make predictions
rf_pred<- predict(object= rf_final, newdata = test.ch4)

# Create evaluation plot
eval_rf_era4 <- data.frame(
    predicted = rf_pred,
    actual = test.ch4$fch4
)

# Create evaluation plot
ggplot(eval_rf_era4, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction - ERA5, ntree = 950",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_era4$actual, na.rm = TRUE), 
             y = max(eval_rf_era4$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf_era4))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf_era4))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_final)

Sys.time() - orig # ~16 min

rmse_rfch4_test<- sqrt(mean((eval_rf_era4$actual - eval_rf_era4$predicted)^2, na.rm = TRUE))
print(paste("RMSE test dataset: ntree = 950 with interact ", rmse_rfch4_test)) #"RMSE: 6.7283544641313"

#Results:
#R2 = 0.478. slope = 0.468


#predict on full dataset and add to df-era

rfch4 = predict(object=rf_final, newdata = df_era2)
df_era2$rfch4 = rfch4

#RMSE
rmse_rfch4<- sqrt(mean((df_era2$fch4 - df_era2$rfch4)^2, na.rm = TRUE))
print(paste("RMSE: ntree = 950 with interact ", rmse_rfch4)) #"RMSE: 4.58952154908953"

# Create evaluation plot
ggplot(df_era2, aes(x = fch4, y = rfch4)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction - ERA5, ntree = 950",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf_era4$actual, na.rm = TRUE), 
             y = max(eval_rf_era4$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(rfch4 ~ fch4, data = df_era2))$r.squared,
                           coef(lm(rfch4 ~ fch4, data = df_era2))[2]),
             hjust = 0, vjust = 1)


#create a RF gapfilled column

df_era2$rfch4_gf = ifelse(is.na(df_era2$fch4),df_era2$rfch4, df_era2$fch4)



#plot half-hourly FCH4 data with the gap-filled data to compare 
ggplot(data = df_era2)+
  geom_hline(yintercept = 0)+
  geom_point(aes(date, rfch4_gf,col='RF Gapfilled'))+
  geom_point(aes(date,fch4,col='Original'))+
    labs(
        y = expression(CH[4]~Flux~(nmolCH[4]~m^-2~y^-1)),
        x = "Time") +
  scale_color_manual(values=c('black','red'))+
  theme_bw()+
  #geom_vline(xintercept = as.POSIXct("2023-07-05"))+
  labs(title = "RF with interaction Methane Flux: Measured and Gap-filled Values")

```




#2019 Only 

#Training RF on just 2019 - ERA5 data --> not constrained 
```{r}
# Subset 2019 data
df_2019 <- df_era2[format(df_era2$date, "%Y") == "2019", ]
df_2019 = df_2019[complete.cases(df_2019$fch4),]

# Create train/test split for 2019
set.seed(123)
sample_2019 <- sample(c(TRUE, FALSE), nrow(df_2019), replace=TRUE, prob=c(0.8,0.2))
train_2019 <- df_2019[sample_2019, ]
test_2019 <- df_2019[!sample_2019, ]

# Fit RF model
rf_2019 <- randomForest(fch4 ~ tair + rh + rg + ws + wd + tsoil + 
                       vpd + swc + h + le + TS_SWC_interact,
                       data = train_2019,
                       ntree = 600)  # Using ~600 trees based on previous OOB analysis



# Now make predictions
rf_pred2019 <- predict(rf_2019, newdata = test_2019)


# Create evaluation plot
eval_rf2019 <- data.frame(
    predicted = rf_pred2019,
    actual = test_2019$fch4,
    date = test_2019$date    # Add the date from test dataset

)

# Create evaluation plot
ggplot(eval_rf2019, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction_2019",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf2019$actual, na.rm = TRUE), 
             y = max(eval_rf2019$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf2019))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf2019))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_2019)

#Results from using all of 2019:
#SWC is most important, but then followed closely by tsoil, then TS:SWC interaction --> comparatively, wd was usually 1 or 2, it has now dropped to 4th most important 
#Slope = 0.566; R2 = 0.599 --> better fit becuase it was trained and tested on just 2019*, but now we need to see if it extrapolates to the other years



```

####Seasonal delineations added to 2019 df
```{r}
#Add DOY to the valuation df 

# First create DOY from date
eval_rf2019$DOY <- as.numeric(format(eval_rf2019$date, "%j"))

# Then apply your seasonal delineations
eval_rf2019$season <- case_when(
    (eval_rf2019$DOY >= 246 & eval_rf2019$DOY <= 284) ~ 'Fall Senescence',
    (eval_rf2019$DOY >= 145 & eval_rf2019$DOY <= 245) ~ 'Growing Season',
    (eval_rf2019$DOY >= 285 | eval_rf2019$DOY <= 144) ~ 'Winter',
    TRUE ~ NA_character_
)

############################################################################

# Add seasonal delineations to the HH 2019 df

# First create DOY from date
df_2019$DOY <- as.numeric(format(df_2019$date, "%j"))


df_2019 <- df_2019 %>%
  mutate(
       season = case_when(
      (DOY >= 246 & DOY <= 284) ~ 'Fall Senescence',
      (DOY >= 145 & DOY <= 245) ~ 'Growing Season',
      (DOY >= 285 | DOY <= 144) ~ 'Winter',
      TRUE ~ NA_character_
    )
  )

#copied here for reference 
  # geom_vline(xintercept = as.POSIXct("2019-05-24"))+ #end of winter, DOY 144* 
  # geom_vline(xintercept =  as.POSIXct("2019-08-31"))+ #end of growing season,DOY 245* --> old: DOY 258 #9/15
  # geom_vline(xintercept =  as.POSIXct("2019-10-11")) + #end of Fall Senescence, DOY 284*


```


####2019 Residuals plot
```{r}
# Calculate residuals
eval_rf2019$residuals <- eval_rf2019$predicted - eval_rf2019$actual

# Add date information from test dataset
eval_rf2019$date <- test_2019$date

# Create residual plots
# 1. Basic residual plot
p1 <- ggplot(eval_rf2019, aes(x = actual, y = residuals)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(title = "Residuals vs Observed Methane Flux",
         x = "Observed Methane Flux",
         y = "Residuals") +
    theme_minimal()

# 2. Temporal pattern in residuals
p2 <- ggplot(eval_rf2019, aes(x = date, y = residuals)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
    labs(title = "Residuals Over Time",
         x = "Date",
         y = "Residuals") +
    theme_minimal()

# Box plot of residuals by season
p3 <- ggplot(eval_rf2019, aes(x = season, y = residuals)) +
    geom_boxplot() +
    labs(title = "Residuals by Season",
         x = "Season",
         y = "Residuals") +
    theme_minimal()

# Arrange plots
grid.arrange(p1, p2, p3, ncol = 2)

# Calculate summary statistics by season
season_stats <- eval_rf2019 %>%
    group_by(season) %>%
    summarise(
        mean_residual = mean(residuals, na.rm = TRUE),
        sd_residual = sd(residuals, na.rm = TRUE),
        n = n(),
        rmse = sqrt(mean(residuals^2, na.rm = TRUE))
    )

print(season_stats)

#Results, only based on test dataset**: 
#winter has lowest RMSE (6.34) and lowest mean residual (0.23), then growing season (7.96; residual = 0.49), then fall (8.46; residual = 0.83)
#based on figures:
#more variability in residuals during growing season, smaller residuals in the winter season (smaller residuals) --> this suggests model performs better for winter? **

```
####Seasonal Comparisons of RF performance 
```{r}
# Add residuals to eval_rf2019 if not already there
# eval_rf2019$residuals <- eval_rf2019$predicted - eval_rf2019$actual

# Create plot with facets by season
ggplot(eval_rf2019, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    facet_wrap(~season) +
    labs(title = "2019 Model Performance by Season",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal()

# Calculate statistics by season
season_metrics <- eval_rf2019 %>%
    group_by(season) %>%
    summarise(
        R2 = cor(predicted, actual, use = "complete.obs")^2,
        slope = coef(lm(predicted ~ actual))[2],
        p_value = summary(lm(predicted ~ actual))$coefficients[2,4],
        n = n()
    )

print(season_metrics)


#Results:
#Fall --> R2 = 0.317, slope = 0.37, p<0.001
#Growing --> R2 = 0.49, slope = 0.51, p<0.001
#Winter --> R2=0.55, slope = 0.58, p<0.011 --> has the most data points in this test dataset 

# Add statistics to plot
ggplot(eval_rf2019, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    facet_wrap(~season) +
    geom_text(data = season_metrics,
              aes(x = -Inf, y = Inf,
                  label = sprintf("R² = %.3f\nSlope = %.3f\np = %.3e\nn = %d",
                                R2, slope, p_value, n)),
              hjust = -0.1, vjust = 1.1) +
    labs(title = "2019 Model Performance by Season",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal()
```
####Applying 2019 model to other years --> maybe divide this out by season as well? 
```{r}

# Create dataset for all other years
other_years <- df_era2[format(df_era2$date, "%Y") != "2019", ]
other_years = other_years[complete.cases(other_years$fch4),] 

# Make predictions for other years using 2019 model
predictions_all_years <- predict(rf_2019, newdata = other_years)

# Create evaluation dataframe
eval_all <- data.frame(
    predicted = predictions_all_years,
    actual = other_years$fch4,
    date = other_years$date,
    year = format(other_years$date, "%Y")
)

# Add seasonal delineations --> need to adjust this by year ** 
eval_all$DOY <- as.numeric(format(eval_all$date, "%j"))
eval_all$season <- case_when(
    (eval_all$DOY >= 246 & eval_all$DOY <= 284) ~ 'Fall Senescence',
    (eval_all$DOY >= 145 & eval_all$DOY <= 245) ~ 'Growing Season',
    (eval_all$DOY >= 285 | eval_all$DOY <= 144) ~ 'Winter',
    TRUE ~ NA_character_
)

# Create evaluation plot
p1 <- ggplot(eval_all, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    facet_wrap(~year) +
    labs(title = "2019-trained RF Model Predictions for Other Years",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    theme(plot.title = element_text(size = 12))

# Calculate performance metrics by year
year_stats <- eval_all %>%
    group_by(year) %>%
    summarise(
        R2 = cor(predicted, actual, use = "complete.obs")^2,
        RMSE = sqrt(mean((predicted - actual)^2, na.rm = TRUE)),
        n = n()
    )

print(year_stats)

# Create seasonal performance plot
p2 <- ggplot(eval_all, aes(x = actual, y = predicted, color = season)) +
    geom_point(alpha = 0.3) +
    geom_smooth(method = "lm") +
    facet_wrap(~year) +
    labs(title = "Seasonal Performance by Year",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal()

grid.arrange(p1, p2, ncol = 1)

#Results   R2           RMSE   n
# 2017	0.03270917	10.735634	2571	
# 2018	0.05323178	9.954032	5174	
# 2020	0.05456234	9.250478	2150	
# 2021	0.05445196	8.868847	2179	
# 2022	0.05414603	8.745927	4351	
# 2023	0.12960697	12.483160	216	

#2019 RF model does not perform well on other years 

```

#ntree optimization for rf_all_era2 model (which includes the swc:temp interaction and fch4 constraints)

#OOB ntrees for Methane 

```{r}
#interaction term in ERA5 dataset, for reference: TS_SWC_interact

#for reference, since we already subsetted a constrained dataset in previous code chunks 
# cc = df_era2[complete.cases(df_era2$fch4),]
# cc = subset(cc,cc$fch4 < 60)
# cc = subset(cc,cc$fch4 > -25)

#create training dataset - 80% to train, 20% to test 
# sample.ch4 = sample(c(TRUE, FALSE), nrow(cc), replace=TRUE, prob=c(0.8,0.2))
# train.ch4  = cc[sample.ch4, ]
# test.ch4   = cc[!sample.ch4, ]

# Function to track OOB error versus number of trees with progress bar --> going to try up to 1k because that's what Jackie found was best in her YK paper 
oob_error_plot <- function(data, max_trees = 1000, step = 100) {
    trees <- seq(50, max_trees, by = step)
    oob_errors <- numeric(length(trees))
    
    # Create progress bar
    pb <- txtProgressBar(min = 0, max = length(trees), style = 3)
    
    for(i in seq_along(trees)) {
        rf_temp <- randomForest(fch4 ~ tair + rh + rg + ws + wd + tsoil + 
                              vpd + swc + h + le + TS_SWC_interact,
                              data = data,
                              ntree = trees[i])
        oob_errors[i] <- rf_temp$mse[trees[i]]
        
        # Update progress bar
        setTxtProgressBar(pb, i)
    }
    
    # Close progress bar
    close(pb)
    
    # Plot OOB error vs number of trees
    plot(trees, oob_errors, type = "l",
         xlab = "Number of Trees",
         ylab = "OOB Mean Squared Error",
         main = "OOB Error vs Number of Trees")
    
    # Add points to see exact values
    points(trees, oob_errors, pch = 16)
    
    # Return optimal number of trees and error data
    opt_trees <- trees[which.min(oob_errors)]
    return(list(optimal_trees = opt_trees, 
                errors = data.frame(trees = trees, oob = oob_errors)))
}

# Find optimal number of trees
opt_results <- oob_error_plot(train.ch4)
print(paste("Optimal number of trees:", opt_results$optimal_trees))

# Print OOB errors for each number of trees
print("OOB errors for each number of trees:")
print(opt_results$errors)

#REsults: "Optimal number of trees: 950"
# trees      oob
# 50	     46.29153			
# 150	     44.41954			
# 250	     44.35895			
# 350	      44.13764			
# 450	     44.08307			
# 550	     43.97322			
# 650	     44.06375			
# 750	     43.95684			
# 850	     43.94687			
# 950	     43.87470	
#improvement drops significantly after around 550/600 trees, so could likely use 550/600 trees just fine with little loss of accuracy

```

#Optimal number of trees for NEE?
####OOB for NEE
```{r}
set.seed(123)
cc_nee = df_era2[complete.cases(df_era2$nee),] #complete NEE data only 
cc_nee = subset(cc_nee,cc_nee$nee < 12 & cc_nee$nee > -14) 


#use 80% of data set as training set and 20% as test set
sample.nee = sample(c(TRUE, FALSE), nrow(cc_nee), replace=TRUE, prob=c(0.8,0.2))
train.nee  = cc_nee[sample.nee, ]
test.nee   = cc_nee[!sample.nee, ]

#Make sure the patterns here look similar so you know the training and testing datasets are representative of the overall dataset 
hist(cc_nee$nee)
hist(train.nee$nee)
hist(test.nee$nee)

library(randomForest)

# Function to track OOB error versus number of trees with progress bar --> going to try up to 1k because that's what Jackie found was best in her YK paper 
oob_error_plot_nee <- function(data, max_trees = 1000, step = 100) {
    trees <- seq(50, max_trees, by = step)
    oob_errors_nee <- numeric(length(trees))
    
    # Create progress bar
    pb <- txtProgressBar(min = 0, max = length(trees), style = 3)
    
    for(i in seq_along(trees)) {
        rf_nee <- randomForest(nee ~ tair + rh + rg + ws + wd + tsoil + 
                              vpd + swc + h + le,
                              data = data,
                              ntree = trees[i])
        oob_errors_nee[i] <- rf_nee$mse[trees[i]]
        
        # Update progress bar
        setTxtProgressBar(pb, i)
    }
    
    # Close progress bar
    close(pb)
    
    # Plot OOB error vs number of trees
    plot(trees, oob_errors_nee, type = "l",
         xlab = "Number of Trees",
         ylab = "OOB Mean Squared Error",
         main = "OOB Error vs Number of Trees for NEE (no temp swc interaction)")
    
    # Add points to see exact values
    points(trees, oob_errors_nee, pch = 16)
    
    # Return optimal number of trees and error data
    opt_trees_nee <- trees[which.min(oob_errors_nee)]
    return(list(optimal_trees_nee = opt_trees_nee, 
                errors = data.frame(trees = trees, oob = oob_errors_nee)))
}

# Find optimal number of trees
opt_results_nee <- oob_error_plot_nee(train.nee)
print(paste("Optimal number of trees:", opt_results_nee$optimal_trees_nee))

# Print OOB errors for each number of trees
print("OOB errors for each number of trees for NEE:")
print(opt_results_nee$errors)

#Results: 
#optimal number of trees at 850, but with minimal improvement from 550 (2.124 → 2.120) --> Could likely use 550-600 trees without significant loss in accuracy

# trees  oob
# 50	2.255787			
# 150	2.150538			
# 250	2.128528			
# 350	2.131406			
# 450	2.128552			
# 550	2.123629			
# 650	2.124292			
# 750	2.121626			
# 850	2.120393	****		
# 950	2.121901			


```



#### Measured data --> Trying to train RandomForest with just temp, SWC, and the temp and SWC interaction --> not constrained 
```{r}

# Create complete dataset --> RF can't handle missing data / NAs
rf_data <- na.omit(df[, c("FCH4", "TS_3_1_1", "SWC_3_1_1")])

# Create interaction term --> explicit interaction term while keeping original terms 
rf_data$TS_SWC_interact <- rf_data$TS_3_1_1 * rf_data$SWC_3_1_1

# Split into train/test (80/20)
set.seed(123)
train_index <- sample(1:nrow(rf_data), 0.8 * nrow(rf_data))
rf_train <- rf_data[train_index, ]
rf_test <- rf_data[-train_index, ]

# Fit RF model with both original and interaction terms
library(randomForest)
rf_model <- randomForest(FCH4 ~ TS_3_1_1 + SWC_3_1_1 + TS_SWC_interact,
                        data = rf_train,
                        ntree = 500)

# Create prediction dataset --> shouldn't need this anymore 
#rf_test$TS_SWC_interact <- rf_test$TS_3_1_1 * rf_test$SWC_3_1_1

# Now make predictions
rf_pred <- predict(rf_model, newdata = rf_test)

# Create evaluation plot
eval_rf <- data.frame(
    predicted = rf_pred,
    actual = rf_test$FCH4
)

# Create evaluation plot
ggplot(eval_rf, aes(x = actual, y = predicted)) +
    geom_point(alpha = 0.3, color = "blue") +
    geom_smooth(method = "lm", color = "red") +
    geom_abline(intercept = 0, slope = 1, linetype = "dashed") +
    labs(title = "Random Forest Model with Interaction",
         x = "Observed Methane Flux",
         y = "Predicted Methane Flux") +
    theme_minimal() +
    annotate("text", x = min(eval_rf$actual, na.rm = TRUE), 
             y = max(eval_rf$predicted, na.rm = TRUE),
             label = sprintf("R² = %.3f\nSlope = %.3f", 
                           summary(lm(predicted ~ actual, data = eval_rf))$r.squared,
                           coef(lm(predicted ~ actual, data = eval_rf))[2]),
             hjust = 0, vjust = 1)

# Look at variable importance
varImpPlot(rf_model)

#Results:

# Model Performance (using measured data**):
# 
# RF with interaction: R2 = 0.325, Slope = 0.350
# Quadratic model: R2 = 0.148, Slope = 0.152
# Non-linear threshold: R2 = 0.133, Slope = 0.132
# Piecewise linear: R2 = 0.027-0.050, Slope = 0.025-0.054
# 
# 
# Variable Importance:
# SWC and TS showing similar importance
# Interaction term slightly more important





```


#Other Empirical Models 

#Generalized Additive Models (GAMs)
```{r}
library(mgcv)
gam_model <- gam(ch4 ~ s(tsoil) + s(swc) + ti(tsoil, swc), data = train.ch4)
```


#Mixed effects model (with season as random effect --> maybe redo within each season?)
```{r}
library(lme4)
mixed_model <- lmer(fch4 ~ tsoil * swc + (1|season), data = train.ch4)
```


#Support Vector Regression (SVR) --> couldn't get this to work
```{r}
library(lme4)
library(e1071)
svr_model <- svm(fach4 ~ tsoil + swc, data = train.ch4)
```

#Gradient Boosting Machines 
```{r}
library(gbm)
gbm_model <- gbm(fch4 ~ tsoil + swc, data = train.ch4)
```


#Removing 2023 due to lack of seasons 
```{r}
# Check levels in training and test data
print(table(train.ch4$season))
print(table(test.ch4$season))

#Need to remove 2023, which doesn't have seasons assigned and the NAs are messing up the stats 
# Remove 2023 data
train.ch4 <- train.ch4[format(train.ch4$date, "%Y") != "2023", ]
test.ch4 <- test.ch4[format(test.ch4$date, "%Y") != "2023", ]

# Verify removal
print("Training data years:")
print(table(format(train.ch4$date, "%Y")))
print("Testing data years:")
print(table(format(test.ch4$date, "%Y")))

#confirm all NAs are gone 
sum(is.na(test.ch4$season))
```

#Extreme Gradient Boosting (XGB) & all above models for comparison 
```{r}
# load all necessary libraries
library(mgcv)        # for GAM
library(lme4)        # for mixed effects
library(e1071)       # for SVR
library(gbm)         # for GBM
library(xgboost)     # for XGBoost
library(caret)       # for model comparison

# GAM Model - Generalized Additive Models (GAMs)
gam_model <- gam(fch4 ~ s(tsoil) + s(swc) + ti(tsoil, swc), 
                 data = train.ch4)

# Mixed Effects Model (with season as random effect)
mixed_model <- lmer(fch4 ~ tsoil * swc + (1|season), 
                   data = train.ch4)
summary(mixed_model)

# SVR Model - Support Vector Regression (SVR) --> removing since it's not working correctly 
#svr_model <- svm(fch4 ~ tsoil + swc, 
                 #data = train.ch4)

# GBM Model - Gradient Boosting Machines 
gbm_model <- gbm(fch4 ~ tsoil + swc,
                 data = train.ch4,
                 distribution = "gaussian",
                 n.trees = 500)

# Prepare data for XGBoost
# XGBoost needs a specific format
train_matrix <- model.matrix(~ tsoil + swc, data = train.ch4)[,-1]
xgb_train <- xgb.DMatrix(data = train_matrix, 
                         label = train.ch4$fch4)

# XGBoost Model
xgb_model <- xgboost(data = xgb_train,
                     nrounds = 100,
                     objective = "reg:squarederror")


#Results of XGBoost - by end of training the RMSE went from 10.31 down to 6.35 

```

#Empirical model comparison stats 

```{r}

# function to make predictions and calculate R2 for each model 
calculate_metrics <- function(predicted, actual) {
    R2 = cor(predicted, actual, use = "complete.obs")^2
    RMSE = sqrt(mean((predicted - actual)^2, na.rm = TRUE))
    slope = coef(lm(predicted ~ actual))[2]
    return(c(R2 = R2, RMSE = RMSE, slope = slope))
}



# Create test matrix for XGBoost predictions
test_matrix <- model.matrix(~ tsoil + swc, data = test.ch4)[,-1]
xgb_test <- xgb.DMatrix(data = test_matrix)

# Get predictions from each model
gam_pred <- predict(gam_model, newdata = test.ch4)

mixed_pred <- predict(mixed_model, newdata = test.ch4)

#svr_pred <- predict(svr_model, newdata = test.ch4) --> taking out since it's not working correctly 

gbm_pred <- predict(gbm_model, newdata = test.ch4)

xgb_pred <- predict(xgb_model, newdata = xgb_test)

# Calculate metrics for each model
metrics_gam <- calculate_metrics(gam_pred, test.ch4$fch4)

metrics_mixed <- calculate_metrics(mixed_pred, test.ch4$fch4)

#metrics_svr <- calculate_metrics(svr_pred, test.ch4$fch4) --> having trouble getting this to work 

metrics_gbm <- calculate_metrics(gbm_pred, test.ch4$fch4)

metrics_xgb <- calculate_metrics(xgb_pred, test.ch4$fch4)

print(metrics_xgb)

# Create summary dataframe
model_comparison <- data.frame(
    Model = c("GAM", "Mixed Effects", #"SVR",
              "GBM", "XGBoost"),
    R2 = c(metrics_gam["R2"], metrics_mixed["R2"], 
           #metrics_svr["R2"],
           metrics_gbm["R2"], metrics_xgb["R2"]),
    RMSE = c(metrics_gam["RMSE"], metrics_mixed["RMSE"], 
             #metrics_svr["RMSE"], 
             metrics_gbm["RMSE"], metrics_xgb["RMSE"]),
    Slope = c(metrics_gam["slope"], metrics_mixed["slope"], 
              #metrics_svr["slope"], 
              metrics_gbm["slope"], metrics_xgb["slope"])
)

print(model_comparison) #--> didn't print slope


# Recalculate metrics with explicit slope calculation
gam_slope <- coef(lm(gam_pred ~ test.ch4$fch4))[2]
mixed_slope <- coef(lm(mixed_pred ~ test.ch4$fch4))[2]
gbm_slope <- coef(lm(gbm_pred ~ test.ch4$fch4))[2]
xgb_slope <- coef(lm(xgb_pred ~ test.ch4$fch4))[2]

# Create updated comparison
model_comparison <- data.frame(
    Model = c("GAM", "Mixed Effects", "GBM", "XGBoost"),
    R2 = c(0.194, 0.114, 0.212, 0.323),
    RMSE = c(8.20, 8.60, 8.12, 7.53),
    Slope = c(gam_slope, mixed_slope, gbm_slope, xgb_slope)
)

print(model_comparison)

# Comparing models now:

# XGBoost performs best:

# Highest R2 = 0.323
# Lowest RMSE = 7.53
#slope = 0.34
 
# GBM second best:

# R2 = 0.212
# RMSE = 8.12
#slope = 0.20
 
# GAM and Mixed Effects less effective:

# GAM: R2 = 0.194, RMSE = 8.20, slope = 0.2
# Mixed Effects: R2 = 0.114, RMSE = 8.60, slope = 0.12
 
# BUT, overall, the Random Forest model (fch4 constrained, temp:swc interaction, wd) was best  (R2 = 0.502) 

```

#trying to get SVR to work
```{r}
# Check the data step by step
# 1. Original data
print("Original test data dimensions:")
print(dim(test.ch4))
print("NAs in each column:")
print(colSums(is.na(test.ch4[c("fch4", "tsoil", "swc")])))

# 2. Create index of complete cases
complete_idx <- complete.cases(test.ch4[c("fch4", "tsoil", "swc")])
print("Number of complete cases:")
print(sum(complete_idx))

# 3. Create clean dataset
clean_data <- test.ch4[complete_idx, ]
print("Clean data dimensions:")
print(dim(clean_data))

# 4. Fit model to clean data only
svr_model_clean <- svm(fch4 ~ tsoil + swc, data = clean_data)
svr_pred_clean <- predict(svr_model_clean, newdata = clean_data)

print("Final lengths:")
print(paste("Predictions:", length(svr_pred_clean)))
print(paste("Actual values:", nrow(clean_data)))

#shows SVM isn't making predictions for all 5078 rows and that's causing problems 

```
#trying to get SVR to work 
```{r}
# First, let's see what the SVM model is actually using
test.ch4$pred_exists <- 1:nrow(test.ch4) %in% 1:length(svr_pred_new)

# Look at the data characteristics where we do/don't get predictions
summary_with_pred <- summary(test.ch4[test.ch4$pred_exists, c("tsoil", "swc", "fch4")])
summary_without_pred <- summary(test.ch4[!test.ch4$pred_exists, c("tsoil", "swc", "fch4")])

print("Summary of cases WITH predictions:")
print(summary_with_pred)
print("\nSummary of cases WITHOUT predictions:")
print(summary_without_pred)

# Check for any obvious patterns
print("\nNumber of cases with/without predictions by season:")
print(table(test.ch4$season, test.ch4$pred_exists))


# Create matched datasets using only the cases where we get predictions
test.ch4$row_num <- 1:nrow(test.ch4)
pred_rows <- test.ch4$row_num[test.ch4$pred_exists]

# Calculate metrics using only matching cases
metrics_svr <- calculate_metrics(svr_pred_new, 
                               test.ch4$fch4[pred_rows])
print(metrics_svr)

#For some reason SVR isn't giving a complete list of predictions, it's producing only 4487 predictions even though there are 5078 rows...couldn't figure out why this was the case

#Results for the predictions we did get: 
#R2 = 0.01; RMSE = 9.65, slope = 0.038 --> not a good predictor, based on what is working...
```
#XGBoost tuning with Claude 
```{r}
orig = Sys.time() #to see how long this takes 

# Set up a grid of parameters to try
param_grid <- expand.grid(
    max_depth = c(3, 6, 9),              # Tree depth - controls how deep each tree can grow
    eta = c(0.01, 0.1, 0.3),             # Learning rate - lower values = slower learning but sometimes better results 
    nrounds = c(100, 500, 1000),         # Number of trees
    gamma = c(0, 0.1, 0.2),              # Minimum loss reduction
    subsample = c(0.5, 0.75, 1.0),       # Subsample ratio of training data - what fraction of data to use for each tree
    colsample_bytree = c(0.6, 0.8, 1.0)  # Subsample ratio of columns - what fraction of variables to consider for each tree 
)

# Function to evaluate XGBoost with different parameters
evaluate_params <- function(params) {
    # Prepare data
    train_matrix <- model.matrix(~ tsoil + swc, data = train.ch4)[,-1]
    test_matrix <- model.matrix(~ tsoil + swc, data = test.ch4)[,-1]
    dtrain <- xgb.DMatrix(data = train_matrix, label = train.ch4$fch4)
    dtest <- xgb.DMatrix(data = test_matrix, label = test.ch4$fch4)
    
    # Train model
    model <- xgboost(data = dtrain,
                    max_depth = params$max_depth, #how deep each tree can be
                    eta = params$eta,             #learning rate 
                    nrounds = params$nrounds,     #number of trees
                    gamma = params$gamma,         #split threshold
                    subsample = params$subsample, #data sampling
                    colsample_bytree = params$colsample_bytree, #variable sampling 
                    objective = "reg:squarederror", #for regression problems 
                    verbose = 0) #suppresses progress message, use "1" to show updates 
    
    # Make predictions
    pred <- predict(model, dtest)
    
    # Calculate metrics
    rmse <- sqrt(mean((pred - test.ch4$fch4)^2))
    r2 <- cor(pred, test.ch4$fch4)^2
    
    return(c(rmse = rmse, r2 = r2))
}

# Try first few parameter combinations 
results <- data.frame()
for(i in 1:10) {  # Start with just 10 combinations --> combinations of the param_grid set up, which has 3 options for eta, max_depth, nrounds, etc. 
    params <- param_grid[i,]
    metrics <- evaluate_params(params)
    results <- rbind(results, 
                    data.frame(params, 
                             RMSE = metrics["rmse"],
                             R2 = metrics["r2"]))
}

# Sort by RMSE
results_sorted <- results[order(results$RMSE),]
print(head(results_sorted))

Sys.time() - orig #to see how long this takes --> 25 seconds, sweet 

#Results
#best performance (lowest RMSE, 7.93) on top row, showing max depth of 6, eta of 0.10, nrounds = 100, gamma = 0, subsample = 0.5, colsample_bytree = 0.6, R2 of 0.246  --> still not as good as the RF model 


```
#Tuning XGBoost round 2 
```{r}
orig = Sys.time()

# Create a more focused parameter grid based on the results in the code chunk above 
focused_param_grid <- expand.grid(
    max_depth = c(5, 6, 7),              # Center around 6
    eta = c(0.05, 0.10, 0.15),           # Focus near 0.10
    nrounds = c(100, 200, 300),          # Test if more rounds help
    gamma = c(0, 0.05, 0.1),             # Try small values
    subsample = c(0.4, 0.5, 0.6),        # Center around 0.5
    colsample_bytree = c(0.5, 0.6, 0.7)  # Center around 0.6
)

# Use the same evaluation function but try more combinations
results <- data.frame()
for(i in 1:30) {  # Try 30 combinations
    params <- focused_param_grid[i,]
    metrics <- evaluate_params(params)
    results <- rbind(results, 
                    data.frame(params, 
                             RMSE = metrics["rmse"],
                             R2 = metrics["r2"]))
}

# Sort and show top 5 results
results_sorted <- results[order(results$RMSE),]
print(head(results_sorted, 5))

Sys.time() - orig # --> about 2.5 min 

#Results:
#best results on top row, max depth = 5, eta = 0.10, nrounds = 200, gamma = 0, subsample = 0.4, colsample_bytree = 0.5, R2 of 0.247, RMSE = 7.9  --> randomForest still performs better 
```
#Tuning XGBoost round 3
```{r}
orig = Sys.time()
#much more focused, based on the previous 2 models 
# Final focused parameter grid
final_param_grid <- expand.grid(
    max_depth = c(4, 5, 6),              # Really tight around 5
    eta = c(0.08, 0.10, 0.12),           # Very close to 0.10
    nrounds = c(175, 200, 225),          # Centered on 200
    gamma = c(0, 0.01, 0.02),            # Very small gamma values
    subsample = c(0.35, 0.40, 0.45),     # Tight around 0.40
    colsample_bytree = c(0.45, 0.50, 0.55) # Tight around 0.50
)

# Try more combinations since we're in a promising area
results <- data.frame()
for(i in 1:50) {  # Increased to 50 combinations
    params <- final_param_grid[i,]
    metrics <- evaluate_params(params)
    results <- rbind(results, 
                    data.frame(params, 
                             RMSE = metrics["rmse"],
                             R2 = metrics["r2"]))
}

# Sort and show top 5 results
results_sorted <- results[order(results$RMSE),]
print(head(results_sorted, 5))

Sys.time() - orig # about 2min 

#Results:
#best performing model's R2 is still just 0.248 (RMSE = 7.92) --> first iteration of the XGBoost actually performed best, with R2 = 0.3 & RMSE of 7.5 --> otherwise, RF model still performs much better 
```

#Plotting out the results of first XGBoost 

####XGBoost on test dataset

```{r}
# Prepare data for XGBoost (same as in training, using test.ch4 data)
test_matrix <- model.matrix(~ tsoil + swc, data = test.ch4)[,-1]  # Same features as in training
xgb_test <- xgb.DMatrix(data = test_matrix)

# Make predictions using the trained XGBoost model
pred_fch4 <- predict(xgb_model, newdata = xgb_test)

#add pred_fch4 to test.ch4 dataset 
test.ch4$pred_fch4 <- pred_fch4

# Actual measured methane flux (fch4) from the test dataset
actual_fch4 <- test.ch4$fch4

#RMSE
rmse <- sqrt(mean((pred_fch4 - actual_fch4)^2))
cat("RMSE:", rmse, "\n")
#RMSE = 7.662884 

# R2
ss_total <- sum((actual_fch4 - mean(actual_fch4))^2)
ss_residual <- sum((actual_fch4 - pred_fch4)^2)
r_squared <- 1 - (ss_residual / ss_total)
cat("R-squared:", r_squared, "\n")

# plot to compare the predicted vs. actual values
library(ggplot2)
comparison_df <- data.frame(Actual = actual_fch4, Predicted = pred_fch4)

ggplot(comparison_df, aes(x = Actual, y = Predicted)) +
  geom_point() + 
  geom_abline(slope = 1, intercept = 0, color = "red") +  # Line of perfect agreement
  labs(title = "Actual vs. Predicted Methane Flux - test dataset",
       x = "Actual fCH4",
       y = "Predicted fCH4") +
  geom_smooth(method = 'lm')+
  theme_bw()+
  annotate("text", size = 4, x = -5, y = 40, label = "R2 = 0.32, slope = 0.34, RMSE = 7.66", font = "black")

#R2 = 0.322; RMSE = 7.66

summary(lm(comparison_df$Predicted ~ comparison_df$Actual))
#Results:
#Residual standard error: 7.66 on 5080 degrees of freedom
#R2 = 0.32; slope = 0.339; p<0.001



# Plot to visualize the gap-filling
ggplot(test.ch4, aes(x = date)) +
  # Plot gap-filled values in red, slightly transparent
  geom_point(aes(y = pred_fch4), color = "red", alpha = 0.5) +
  # Plot measured values in black, on top
  geom_point(aes(y = fch4), color = "black", na.rm = TRUE) +
  labs(title = "Test dataset: Methane Flux: Measured and Gap-filled Values",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  # Add legend
  geom_segment(aes(x = min(date), xend = min(date), y = max(pred_fch4, na.rm=TRUE), 
                   yend = max(pred_fch4, na.rm=TRUE), color = "Measured"), 
               show.legend = TRUE) +
  geom_segment(aes(x = min(date), xend = min(date), y = max(pred_fch4, na.rm=TRUE), 
                   yend = max(pred_fch4, na.rm=TRUE), color = "Gap-filled"), 
               show.legend = TRUE) +
  scale_color_manual(values = c("Measured" = "black", "Gap-filled" = "red")) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
 



```
####XGBoost on full complete cases dataset
```{r}
# First, make sure all necessary data is complete
cc <- df_era2[complete.cases(df_era2$fch4, df_era2$tsoil, df_era2$swc), ]

# Create matrix for prediction
full_matrix <- model.matrix(~ tsoil + swc, data = cc)[,-1]  # Remove intercept column

# Use your already trained model (xgb_model) to make predictions
pred_fch4 <- predict(xgb_model, full_matrix)

# Get actual values
actual_fch4 <- cc$fch4

# Calculate metrics
rmse <- sqrt(mean((pred_fch4 - actual_fch4)^2))
cat("RMSE:", rmse, "\n") #RMSE = 7.01

# Calculate R2 --> here results say R2 = 0.465
ss_total <- sum((actual_fch4 - mean(actual_fch4))^2)
ss_residual <- sum((actual_fch4 - pred_fch4)^2)
r_squared <- 1 - (ss_residual / ss_total)
cat("R-squared:", r_squared, "\n")

# Create a dataframe for plotting
plot_data <- data.frame(
  actual_fch4 = actual_fch4,
  pred_fch4 = pred_fch4
)

# Create plot
ggplot(plot_data, aes(x = actual_fch4, y = pred_fch4)) +
  geom_point(alpha = 0.5) + 
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(method = 'lm')+
  labs(title = "Complete cases: Actual vs. Predicted Methane Flux",
       x = expression(paste("Actual CH"[4], " Flux")),
       y = expression(paste("Predicted CH"[4], " Flux"))) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
   annotate("text", size = 5, x = -30, y = 50, label = "R2 = 0.47, slope = 0.41", color = "black")+
  annotate("text", size = 5, x = -30, y = 45, label = "RMSE = 7.01", color = "black")

# Linear model summary
summary(lm(pred_fch4 ~ actual_fch4))
#Results: R2 = 0.475, slope = 0.41, p<0.001


# add predictions to the cc dataset
cc$pred_fch4 <- pred_fch4

# Create a time series plot
ggplot(cc, aes(x = date)) +
  geom_point(aes(y = fch4, color = "Measured"), alpha = 0.7) +
  geom_point(aes(y = pred_fch4, color = "Predicted"), alpha = 0.7) +
  scale_color_manual(values = c("Measured" = "black", "Predicted" = "red")) +
  labs(title = "Complete cases: Measured vs Predicted Methane Flux Over Time",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  theme(
    #legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) 
 

```

#### XGBoost predictions on df_era2 - full dataset 
```{r}
# Get predictions from original model for full dataset
original_predictions <- predict(xgb_model, full_matrix_all_years)

# Create comparison dataframe for original model
comparison_df_orig <- data.frame(
    measured = df_era2$fch4[measured_indices_all],
    predicted = original_predictions[measured_indices_all]
)

# Calculate statistics
rmse_orig <- sqrt(mean((comparison_df_orig$predicted - comparison_df_orig$measured)^2))
r_squared_orig <- 1 - sum((comparison_df_orig$measured - comparison_df_orig$predicted)^2) /
                     sum((comparison_df_orig$measured - mean(comparison_df_orig$measured))^2)
# Calculate slope
lm_fit <- lm(predicted ~ measured, data = comparison_df_orig)
slope <- coef(lm_fit)[2]

# Create statistics text
stats_text <- sprintf("R² = %.3f\nRMSE = %.3f\nSlope = %.3f",
                     r_squared_orig, rmse_orig, slope)

# Create the 1:1 plot
ggplot(comparison_df_orig, aes(x = measured, y = predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +  # 1:1 line
  geom_smooth(method = "lm")+
  labs(title = "Measured vs Predicted Methane Flux (Original Model)",
       x = expression(paste("Measured CH"[4], " Flux")),
       y = expression(paste("Predicted CH"[4], " Flux"))) +
  # Add text annotations for statistics
  annotate("text", x = min(comparison_df_orig$measured),
           y = max(comparison_df_orig$predicted),
           label = stats_text,
           hjust = 0, vjust = 1,
           size = 4) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  # Make plot square and ensure axes have same limits
  coord_fixed(ratio = 1) +
  scale_x_continuous(limits = function(x) c(min(x), max(x))) +
  scale_y_continuous(limits = function(x) c(min(x), max(x)))

summary(lm(comparison_df$predicted ~ comparison_df$measured))

```


###XGBoost gapfilling 
```{r}
#Now see how XGBoost performs for full dataset

# Create matrix for the entire dataset (df_era2) using only tsoil and swc
full_matrix <- model.matrix(~ tsoil + swc, data = df_era2)[,-1]

# Make predictions for the entire dataset using your trained model
all_predictions <- predict(xgb_model, full_matrix)

# Create a new column for gap-filled fch4
df_era2$fch4_gapfilled <- df_era2$fch4  # Copy measured values first

# Replace NAs with predicted values
df_era2$fch4_gapfilled[is.na(df_era2$fch4)] <- all_predictions[is.na(df_era2$fch4)]

# how many gaps were filled
cat("Number of gaps filled:", sum(is.na(df_era2$fch4)), "\n")
#Result: 91231 

# Plot to visualize the gap-filling
ggplot(df_era2, aes(x = date)) +
  # Plot gap-filled values in red, slightly transparent
  geom_point(aes(y = fch4_gapfilled), color = "red", alpha = 0.5) +
  # Plot measured values in black, on top
  geom_point(aes(y = fch4), color = "black", na.rm = TRUE) +
  labs(title = "Methane Flux: Measured and Gap-filled Values",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  # Add legend
  geom_segment(aes(x = min(date), xend = min(date), y = max(fch4_gapfilled, na.rm=TRUE), 
                   yend = max(fch4_gapfilled, na.rm=TRUE), color = "Measured"), 
               show.legend = TRUE) +
  geom_segment(aes(x = min(date), xend = min(date), y = max(fch4_gapfilled, na.rm=TRUE), 
                   yend = max(fch4_gapfilled, na.rm=TRUE), color = "Gap-filled"), 
               show.legend = TRUE) +
  scale_color_manual(values = c("Measured" = "black", "Gap-filled" = "red")) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

```

# XGBoost with interaction effect - training and testing 


```{r}
# 1. set up training matrix for XGBoost
train_matrix_interact <- model.matrix(~ tsoil + swc + TS_SWC_interact, data = train.ch4)[,-1]
xgb_train_interact <- xgb.DMatrix(data = train_matrix_interact, 
                                 label = train.ch4$fch4)

# Train XGBoost Model with interaction
xgb_model_interact <- xgboost(data = xgb_train_interact,
                             nrounds = 100,
                             objective = "reg:squarederror")

# 2. Test the model on test dataset
test_matrix_interact <- model.matrix(~ tsoil + swc + TS_SWC_interact, data = test.ch4)[,-1]
test_predictions <- predict(xgb_model_interact, test_matrix_interact)

#add test predictions to train.ch4 dataset
test.ch4$pred_fch4_interact <- test_predictions

# Calculate performance metrics on test set
rmse_test <- sqrt(mean((test_predictions - test.ch4$fch4)^2))
r_squared_test <- 1 - sum((test.ch4$fch4 - test_predictions)^2) / 
                    sum((test.ch4$fch4 - mean(test.ch4$fch4))^2)
lm_fit_test <- lm(test_predictions ~ test.ch4$fch4)
slope_test <- coef(lm_fit_test)[2]

# Create 1:1 plot for test set performance
ggplot(data.frame(measured = test.ch4$fch4, predicted = test_predictions), 
       aes(x = measured, y = predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(method = "lm")+
  labs(title = "Test Set: Measured vs Predicted Methane Flux",
       subtitle = "Model with Interaction Term",
       x = expression(paste("Measured CH"[4], " Flux")),
       y = expression(paste("Predicted CH"[4], " Flux"))) +
  annotate("text", x = min(test.ch4$fch4), 
           y = max(test_predictions),
           label = sprintf("R² = %.3f\nRMSE = %.3f\nSlope = %.3f", 
                         r_squared_test, rmse_test, slope_test),
           hjust = 0, vjust = 1,
           size = 4) +
  theme_bw() +
  coord_fixed(ratio = 1)


summary(lm(test.ch4$fch4 ~ test.ch4$pred_fch4_interact))
#slope = 0.34, R2 = 0.323


# 3. If test performance is satisfactory, then use model on full dataset
if(r_squared_test > 0.3) {  # You can set your own threshold
  # Create matrix for entire dataset
  full_matrix_interact <- model.matrix(~ tsoil + swc + TS_SWC_interact, data = df_era2)[,-1]
  
  # Make predictions
  all_predictions <- predict(xgb_model_interact, full_matrix_interact)
  
  # Create gap-filled column
  df_era2$fch4_gapfilled_interact <- df_era2$fch4
  df_era2$fch4_gapfilled_interact[is.na(df_era2$fch4)] <- all_predictions[is.na(df_era2$fch4)]
}


```
#XGBoost Interaction on full dataset 
```{r}
# Calculate performance metrics where we have measured values in full dataset 
measured_indices <- !is.na(df_era2$fch4)
comparison_df_interact <- data.frame(
    measured = df_era2$fch4[measured_indices],
    predicted = interact_predictions[measured_indices]
)

# Calculate statistics
rmse_interact <- sqrt(mean((comparison_df_interact$predicted - comparison_df_interact$measured)^2))
r_squared_interact <- 1 - sum((comparison_df_interact$measured - comparison_df_interact$predicted)^2) / 
                        sum((comparison_df_interact$measured - mean(comparison_df_interact$measured))^2)
# Calculate slope
lm_fit_interact <- lm(predicted ~ measured, data = comparison_df_interact)
slope_interact <- coef(lm_fit_interact)[2]

# Create 1:1 plot
ggplot(comparison_df_interact, aes(x = measured, y = predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  geom_smooth(method = "lm")+
  labs(title = "Measured vs Predicted Methane Flux (Model with Interaction)",
       x = expression(paste("Measured CH"[4], " Flux")),
       y = expression(paste("Predicted CH"[4], " Flux"))) +
  annotate("text", x = min(comparison_df_interact$measured), 
           y = max(comparison_df_interact$predicted),
           label = sprintf("R² = %.3f\nRMSE = %.3f\nSlope = %.3f", 
                         r_squared_interact, rmse_interact, slope_interact),
           hjust = 0, vjust = 1,
           size = 4) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  coord_fixed(ratio = 1) +
  scale_x_continuous(limits = function(x) c(min(x), max(x))) +
  scale_y_continuous(limits = function(x) c(min(x), max(x)))

# Create gap-filled column using interaction model
df_era2$fch4_gapfilled_interact <- df_era2$fch4
df_era2$fch4_gapfilled_interact[is.na(df_era2$fch4)] <- interact_predictions[is.na(df_era2$fch4)]

# Time series plot
ggplot(df_era2, aes(x = date)) +
  geom_point(aes(y = fch4_gapfilled_interact), color = "red", alpha = 0.5) +
  geom_point(aes(y = fch4), color = "black", na.rm = TRUE) +
  labs(title = "Methane Flux: Measured and Gap-filled Values (Interaction Model)",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  geom_segment(aes(x = min(date), xend = min(date), 
                   y = max(fch4_gapfilled_interact, na.rm=TRUE), 
                   yend = max(fch4_gapfilled_interact, na.rm=TRUE), 
                   color = "Measured"), 
               show.legend = TRUE) +
  geom_segment(aes(x = min(date), xend = min(date), 
                   y = max(fch4_gapfilled_interact, na.rm=TRUE), 
                   yend = max(fch4_gapfilled_interact, na.rm=TRUE), 
                   color = "Gap-filled"), 
               show.legend = TRUE) +
  scale_color_manual(values = c("Measured" = "black", "Gap-filled" = "red")) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )
```


#Save exploratory methane model dataset for buedgets in new script
```{r}
#saving with adj RF model, XGBoost model....
write.csv(x = df_era2,file = 'C:/Users/kkent/Documents/Council Data/Council BASE gapfilling/council_HH_alt_methane_models.csv',quote = F,row.names = F)
```



#VarIDent in mixed effects models 
```{r}
library(nlme)

#dataset with complete cases
model_data <- df_era2 %>%
  filter(!is.na(fch4), !is.na(tsoil), !is.na(swc), !is.na(season))#%>%
  # Scale numeric predictors for better model convergence
  # mutate(tsoil_scaled = scale(tsoil),
  #        swc_scaled = scale(swc))

# Fit mixed effects model with varying variances by season
me_model <- lme(fch4 ~ tsoil * swc, #tsoil_scaled, swc_scaled 
                data = model_data,
                weights = varIdent(form = ~1|season),
                random = ~1|year)

# Look at model summary
summary(me_model)

# Check residuals
plot(me_model)

# Compare variances by season
print(intervals(me_model))

# Visualize the relationship with seasonal differences
ggplot(model_data, aes(x = tsoil, y = fch4, color = season)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  facet_wrap(~season) +
  theme_bw() +
  labs(title = "Methane Flux vs Soil Temperature by Season",
       x = "Soil Temperature (°C)",
       y = expression(paste("CH"[4], " Flux")))

# Visualize the relationship with seasonal differences
ggplot(model_data, aes(x = swc, y = fch4, color = season)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "lm") +
  facet_wrap(~season) +
  theme_bw() +
  labs(title = "Methane Flux vs SWC by Season",
       x = "SWC %",
       y = expression(paste("CH"[4], " Flux")))
```


#LME with varIDent in winter specifically 
```{r}
# Create winter-only dataset
winter_data <- model_data %>%
  filter(season == "Winter")

# Fit model to winter data only
winter_me_model <- lme(fch4 ~ tsoil * swc,
                      data = winter_data,
                      weights = varIdent(form = ~1|year),  # Allow different variances by year
                      random = ~1|year)

# Make predictions and assess performance
winter_predictions <- predict(winter_me_model, winter_data)
winter_measured <- winter_data$fch4

# Calculate performance metrics
winter_rmse <- sqrt(mean((winter_predictions - winter_measured)^2))
winter_r2 <- 1 - sum((winter_measured - winter_predictions)^2) / 
                 sum((winter_measured - mean(winter_measured))^2)

# Visualize predictions vs measured for winter
ggplot(data.frame(measured = winter_measured, 
                 predicted = winter_predictions), 
       aes(x = measured, y = predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Winter Methane Flux: Mixed Effects Model Predictions",
       x = "Measured CH4 Flux",
       y = "Predicted CH4 Flux") +
  theme_bw()

# Compare with winter predictions from XGBoost
winter_xgb_predictions <- all_predictions[df_era2$season == "Winter" & 
                                        !is.na(df_era2$fch4)]
winter_xgb_measured <- df_era2$fch4[df_era2$season == "Winter" & 
                                   !is.na(df_era2$fch4)]

winter_xgb_rmse <- sqrt(mean((winter_xgb_predictions - winter_xgb_measured)^2))
```

#TO DO - RE-RUN and annotate the results 

```{r}
# including air temperature and its interaction
winter_me_model2 <- lme(fch4 ~ tsoil * swc + tair,
                       data = winter_data,
                       weights = varIdent(form = ~1|year),
                       random = ~1|year)

#  non-linear relationship with soil temperature
winter_me_model3 <- lme(fch4 ~ I(tsoil^2) + tsoil + swc + I(tsoil^2):swc,
                       data = winter_data,
                       weights = varIdent(form = ~1|year),
                       random = ~1|year)

# Look at summary
summary(winter_me_model3)

# Make predictions and assess performance
winter_predictions3 <- predict(winter_me_model3, winter_data)
winter_measured <- winter_data$fch4

# Calculate performance metrics
winter_rmse3 <- sqrt(mean((winter_predictions3 - winter_measured)^2))
winter_r2_3 <- 1 - sum((winter_measured - winter_predictions3)^2) / 
                 sum((winter_measured - mean(winter_measured))^2)

# Visualize predictions
ggplot(data.frame(measured = winter_measured, 
                 predicted = winter_predictions3), 
       aes(x = measured, y = predicted)) +
  geom_point(alpha = 0.5) +
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Winter Methane Flux: Non-linear Mixed Effects Model",
       x = "Measured CH4 Flux",
       y = "Predicted CH4 Flux") +
  theme_bw()
```




#TO DO: use test dataset on this before testing on whole dataset 

####XGBoost trained just on 2019 
```{r}
# First, let's create a 2019 dataset
df_2019 <- df_era2 %>%
  filter(year(date) == 2019)

# Create training data from 2019 (complete cases only)
train_2019 <- df_2019[complete.cases(df_2019$fch4, df_2019$tsoil, df_2019$swc), ]

# Prepare data for XGBoost training
train_matrix_2019 <- model.matrix(~ tsoil + swc, data = train_2019)[,-1]
xgb_train_2019 <- xgb.DMatrix(data = train_matrix_2019, 
                             label = train_2019$fch4)

# Train XGBoost Model on 2019 data
xgb_model_2019 <- xgboost(data = xgb_train_2019,
                         nrounds = 100,
                         objective = "reg:squarederror")

# Create matrix for entire 2019 dataset to make predictions
full_matrix_2019 <- model.matrix(~ tsoil + swc, data = df_2019)[,-1]

# Make predictions for all of 2019
all_predictions_2019 <- predict(xgb_model_2019, full_matrix_2019)

# Create gap-filled column for 2019
df_2019$fch4_gapfilled <- df_2019$fch4
df_2019$fch4_gapfilled[is.na(df_2019$fch4)] <- all_predictions_2019[is.na(df_2019$fch4)]

# Print summary of gap-filling
cat("Number of gaps filled in 2019:", sum(is.na(df_2019$fch4)), "\n")

# Create visualization
ggplot(df_2019, aes(x = date)) +
  geom_line(aes(y = fch4_gapfilled), color = "red", alpha = 0.5) +
  geom_line(aes(y = fch4), color = "black", na.rm = TRUE) +
  labs(title = "2019 Methane Flux: Measured and Gap-filled Values",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  geom_segment(aes(x = min(date), xend = min(date), 
                   y = max(fch4_gapfilled, na.rm=TRUE), 
                   yend = max(fch4_gapfilled, na.rm=TRUE), 
                   color = "Measured"), 
               show.legend = TRUE) +
  geom_segment(aes(x = min(date), xend = min(date), 
                   y = max(fch4_gapfilled, na.rm=TRUE), 
                   yend = max(fch4_gapfilled, na.rm=TRUE), 
                   color = "Gap-filled"), 
               show.legend = TRUE) +
  scale_color_manual(values = c("Measured" = "black", "Gap-filled" = "red")) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

# Let's also check model performance on measured values
measured_indices <- !is.na(df_2019$fch4)
actual_fch4 <- df_2019$fch4[measured_indices]
pred_fch4 <- all_predictions_2019[measured_indices]

# Calculate metrics
rmse <- sqrt(mean((pred_fch4 - actual_fch4)^2))
r_squared <- 1 - sum((actual_fch4 - pred_fch4)^2) / sum((actual_fch4 - mean(actual_fch4))^2)
#Results:
# RMSE: 5.975 
# R-squared: 0.717 

cat("\nModel Performance on 2019 Data:\n")
cat("RMSE:", round(rmse, 3), "\n")
cat("R-squared:", round(r_squared, 3), "\n")

# Linear model summary
summary(lm(pred_fch4 ~ actual_fch4))
#Results: R2 = 0.72, slope = 0.63, p<0.001

```


#XGBoost 2019 predictions on all years
```{r}
# Create matrix for the entire dataset
full_matrix_all_years <- model.matrix(~ tsoil + swc, data = df_era2)[,-1]

# Use 2019-trained model to predict all years
all_years_predictions <- predict(xgb_model_2019, full_matrix_all_years)

# Create gap-filled column in full dataset
df_era2$fch4_gapfilled_2019model <- df_era2$fch4  # Keep measured values
df_era2$fch4_gapfilled_2019model[is.na(df_era2$fch4)] <- all_years_predictions[is.na(df_era2$fch4)]

# Print summary of gap-filling
cat("Number of gaps filled across all years:", sum(is.na(df_era2$fch4)), "\n")
#Result: 91231 

# Create visualization
ggplot(df_era2, aes(x = date)) +
  geom_line(aes(y = fch4_gapfilled_2019model), color = "red", alpha = 0.5) +
  geom_line(aes(y = fch4), color = "black", na.rm = TRUE) +
  labs(title = "Methane Flux: Measured and Gap-filled Values (2019 Model)",
       subtitle = "Model trained on 2019 data only",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  geom_segment(aes(x = min(date), xend = min(date), 
                   y = max(fch4_gapfilled_2019model, na.rm=TRUE), 
                   yend = max(fch4_gapfilled_2019model, na.rm=TRUE), 
                   color = "Measured"), 
               show.legend = TRUE) +
  geom_segment(aes(x = min(date), xend = min(date), 
                   y = max(fch4_gapfilled_2019model, na.rm=TRUE), 
                   yend = max(fch4_gapfilled_2019model, na.rm=TRUE), 
                   color = "Gap-filled"), 
               show.legend = TRUE) +
  scale_color_manual(values = c("Measured" = "black", "Gap-filled" = "red")) +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )

# Calculate performance metrics for all non-NA measured values
measured_indices_all <- !is.na(df_era2$fch4)
actual_fch4_all <- df_era2$fch4[measured_indices_all]
pred_fch4_all <- all_years_predictions[measured_indices_all]

rmse_all <- sqrt(mean((pred_fch4_all - actual_fch4_all)^2))
r_squared_all <- 1 - sum((actual_fch4_all - pred_fch4_all)^2) / 
                    sum((actual_fch4_all - mean(actual_fch4_all))^2)

cat("\nModel Performance on All Years:\n")
cat("RMSE:", round(rmse_all, 3), "\n")
cat("R-squared:", round(r_squared_all, 3), "\n")

#Result: RMSE = 9, R2 = 0.12 --> so no good for extrapolating across all years 

```






```{r}
# Create dataframe for plotting where we have measured values
comparison_df <- data.frame(
  measured = df_era2$fch4[measured_indices_all],
  predicted = all_years_predictions[measured_indices_all]
)

# Calculate statistics for annotation
rmse_text <- sprintf("RMSE = %.3f", rmse_all)
r2_text <- sprintf("R² = %.3f", r_squared_all)

# Create the 1:1 plot with statistics
ggplot(comparison_df, aes(x = measured, y = predicted)) +
  geom_point(alpha = 0.5) +  # Points with some transparency
  geom_abline(slope = 1, intercept = 0, color = "red", linetype = "dashed") +  # 1:1 line
  labs(title = "Measured vs Predicted Methane Flux (2019 Model)",
       x = expression(paste("Measured CH"[4], " Flux")),
       y = expression(paste("Predicted CH"[4], " Flux"))) +
  # Add text annotations for statistics
  annotate("text", x = min(comparison_df$measured), 
           y = max(comparison_df$predicted), 
           label = paste(r2_text, rmse_text, sep = "\n"), 
           hjust = 0, vjust = 1,
           size = 4) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  ) +
  # Make plot square and ensure axes have same limits
  coord_fixed(ratio = 1) +
  scale_x_continuous(limits = function(x) c(min(x), max(x))) +
  scale_y_continuous(limits = function(x) c(min(x), max(x)))
```






#XGBoost seasonal predictions 

```{r}
# Add season-specific colors and plot
ggplot(cc, aes(x = date)) +
  geom_line(aes(y = fch4, color = "Measured")) +
  geom_line(aes(y = pred_fch4, color = "Predicted")) +
  facet_wrap(~season, scales = "free_x") +
  scale_color_manual(values = c("Measured" = "black", "Predicted" = "red")) +
  labs(title = "Measured vs Predicted Methane Flux by Season",
       x = "Date",
       y = expression(paste("CH"[4], " Flux")),
       color = "") +
  theme_bw() +
  theme(
    legend.position = "bottom",
    plot.title = element_text(size = 14, face = "bold"),
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10)
  )


```


#OOB ntree for SWC in RF

#Optimal number of trees for SWC (SWC3)

```{r}

orig = Sys.time()#starting timer

set.seed(123)
cc_swc = df_era2[complete.cases(df_era2$swc),] #complete swc data only 

#use 80% of data set as training set and 20% as test set
sample.swc = sample(c(TRUE, FALSE), nrow(cc_swc), replace=TRUE, prob=c(0.8,0.2))
train.swc  = cc_swc[sample.swc, ]
test.swc   = cc_swc[!sample.swc, ]

#Make sure the patterns here look similar so you know the training and testing datasets are representative of the overall dataset 
hist(cc_swc$swc)
hist(train.swc$swc)
hist(test.swc$swc)

library(randomForest)

# Function to track OOB error versus number of trees with progress bar 
oob_error_plot_swc <- function(data, max_trees = 1000, step = 100) {
    trees <- seq(100, max_trees, by = step)
    oob_errors_swc <- numeric(length(trees))
    
    # Create progress bar
    pb <- txtProgressBar(min = 0, max = length(trees), style = 3)

   
    for(i in seq_along(trees)) {
        rf_swc <- randomForest(swc ~ tair + rh + rg + ws + wd + tsoil + 
                              vpd + h + le,
                              data = data,
                              ntree = trees[i])
        oob_errors_swc[i] <- rf_swc$mse[trees[i]]
        
        # Update progress bar
        setTxtProgressBar(pb, i)
    }
    
    # Close progress bar
    close(pb)
    
    # Plot OOB error vs number of trees
    plot(trees, oob_errors_swc, type = "l",
         xlab = "Number of Trees",
         ylab = "OOB Mean Squared Error",
         main = "OOB Error vs Number of Trees for SWC (SWC3)")
    
    # Add points to see exact values
    points(trees, oob_errors_swc, pch = 16)
    
    # Return optimal number of trees and error data
    opt_trees_swc <- trees[which.min(oob_errors_swc)]
    return(list(optimal_trees_swc = opt_trees_swc, 
                errors = data.frame(trees = trees, oob = oob_errors_swc)))
}

# Find optimal number of trees
opt_results_swc <- oob_error_plot_swc(train.swc)
print(paste("Optimal number of trees:", opt_results_swc$optimal_trees_swc))

# Print OOB errors for each number of trees
print("OOB errors for each number of trees for swc:")
print(opt_results_swc$errors)

#Results: optimal number of trees is 800*
# trees oob
# 100	14.03046			
# 200	13.52641			
# 300	13.43767			
# 400	13.33447			
# 500	13.40129			
# 600	13.34920			
# 700	13.31430			
# 800	13.23051			
# 900	13.31164			
# 1000	13.28281	


Sys.time() - orig #stop timer 


```










